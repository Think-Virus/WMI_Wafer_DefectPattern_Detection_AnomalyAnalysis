{"cells":[{"cell_type":"markdown","metadata":{"id":"UIqvq9cFUjPb"},"source":["# Open-set Wafer Map Triage (WM-811K)\n","\n","- **MVP-1(완료)**: Known 분류 + OOD(Unknown 탐지, MSP/Energy) 평가  \n","- **MVP-2(진행중)**: 트리아지(UMAP 시각화 + Top-K 유사사례 검색)\n","\n","> 핵심: Unknown을 “Unknown”으로 거부(reject)하고, 이후 판단을 돕는 트리아지 워크플로우"]},{"cell_type":"markdown","metadata":{"id":"ETatusOj_t7G"},"source":["## 0. 환경 설정\n","- Google Drive 마운트, 경로/시드 설정"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19317,"status":"ok","timestamp":1768103403116,"user":{"displayName":"Myunggyun Choi (think_virus)","userId":"16622592930277680639"},"user_tz":-540},"id":"Jr1KElMF_th2","outputId":"888c9661-61f2-473a-c46d-82b1cca1ff86"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","source":["한글 폰트 깨지지 않게 설정"],"metadata":{"id":"ott66_q1WPMv"}},{"cell_type":"code","source":["import os, pathlib\n","os.environ[\"MPLCONFIGDIR\"] = \"/tmp/matplotlib\"\n","pathlib.Path(os.environ[\"MPLCONFIGDIR\"]).mkdir(parents=True, exist_ok=True)\n","\n","!apt-get -qq update\n","!apt-get -qq -y install fonts-nanum fonts-noto-cjk\n","!fc-cache -fv\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","\n","font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n","fm.fontManager.addfont(font_path)\n","plt.rcParams[\"font.family\"] = fm.FontProperties(fname=font_path).get_name()\n","plt.rcParams[\"axes.unicode_minus\"] = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSAm4XpDWOqA","outputId":"5ad9ad3d-640b-408f-ca24-a53a37d6a758"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}]},{"cell_type":"markdown","source":["모델 저장 및 로드를 위해 미리 선언하는 셀"],"metadata":{"id":"l4N5Tpyy68w7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0372b366"},"outputs":[],"source":["import os, json\n","from datetime import datetime\n","import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","INPUT_MODE = \"polar4\"  # <-- 과거 모델 분석 시 \"repeat3\", \"coords4\"로 바꾸면 됨\n","RANDOM_STATE = 42\n","CKPT_DIR = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/checkpoints\"\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","def _safe(s: str) -> str:\n","    return (\n","        str(s).replace(\" \", \"\")\n","        .replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n","        .replace(\",\", \"-\").replace(\"[\", \"\").replace(\"]\", \"\")\n","        .replace(\"'\", \"\").replace('\"', \"\")\n","    )\n","\n","def _infer_in_chans_from_state_dict(sd):\n","    if \"conv1.weight\" in sd:\n","        return int(sd[\"conv1.weight\"].shape[1])\n","    return 3\n","\n","def _infer_input_mode(in_chans: int):\n","    if in_chans == 4:\n","        return INPUT_MODE #\"coords4\"\n","    if in_chans == 3:\n","        return \"repeat3\"\n","    return f\"in{in_chans}\"\n","\n","def build_resnet18(num_classes: int, in_chans: int = 3):\n","    model = models.resnet18(weights=None)\n","    if in_chans != 3:\n","        model.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    return model\n","\n","def save_mvp_checkpoint(\n","    model,\n","    class_to_idx,\n","    unknown_classes,\n","    resize=64,\n","    arch=\"resnet18\",\n","    optimizer=None,\n","    metrics=None,\n","    tag=None,\n","    extra=None,\n","):\n","    in_chans = int(model.conv1.in_channels) if hasattr(model, \"conv1\") else None\n","    input_mode = _infer_input_mode(in_chans if in_chans is not None else 3)\n","\n","    ckpt = {\n","        \"arch\": arch,\n","        \"resize\": int(resize),\n","        \"unknown_classes\": list(unknown_classes),\n","        \"class_to_idx\": dict(class_to_idx),\n","        \"model_in_chans\": in_chans,\n","        \"input_mode\": input_mode,\n","        \"metrics\": metrics or {},\n","        \"extra\": extra or {},\n","        \"model_state_dict\": model.state_dict(),\n","    }\n","    if optimizer is not None:\n","        ckpt[\"optimizer_state_dict\"] = optimizer.state_dict()\n","\n","    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    tag_s = _safe(tag) if tag else \"ckpt\"\n","    fname = f\"{ts}_{arch}_R{resize}_{input_mode}_K{len(class_to_idx)}_{tag_s}.pt\"\n","    path = os.path.join(CKPT_DIR, fname)\n","    torch.save(ckpt, path)\n","    print(\"✅ Saved:\", path)\n","    return path\n","\n","def load_mvp_checkpoint_auto(path, device=\"cpu\", strict=False):\n","    ckpt = torch.load(path, map_location=device)\n","\n","    class_to_idx = ckpt[\"class_to_idx\"]\n","    known_classes = [None] * len(class_to_idx)\n","    for cls, idx in class_to_idx.items():\n","        known_classes[idx] = cls\n","\n","    sd = ckpt[\"model_state_dict\"]\n","    in_chans = ckpt.get(\"model_in_chans\")\n","    if in_chans is None:\n","        in_chans = _infer_in_chans_from_state_dict(sd)\n","\n","    input_mode = ckpt.get(\"input_mode\") or _infer_input_mode(in_chans)\n","    resize = int(ckpt.get(\"resize\", 64))\n","\n","    arch = ckpt.get(\"arch\", \"resnet18\")\n","    if arch != \"resnet18\":\n","        raise ValueError(f\"Unsupported arch: {arch}\")\n","\n","    model = build_resnet18(num_classes=len(known_classes), in_chans=in_chans)\n","    missing, unexpected = model.load_state_dict(sd, strict=strict)\n","\n","    model = model.to(device).eval()\n","\n","    cfg = {\n","        \"arch\": arch,\n","        \"resize\": resize,\n","        \"in_chans\": in_chans,\n","        \"input_mode\": input_mode,\n","        \"unknown_classes\": ckpt.get(\"unknown_classes\", []),\n","    }\n","\n","    print(\"✅ Loaded:\", path)\n","    print(\" - cfg:\", cfg)\n","    if missing:\n","        print(\" - missing keys:\", missing[:10], \"...\" if len(missing) > 10 else \"\")\n","    if unexpected:\n","        print(\" - unexpected keys:\", unexpected[:10], \"...\" if len(unexpected) > 10 else \"\")\n","\n","    return model, ckpt, known_classes, class_to_idx, cfg"]},{"cell_type":"markdown","metadata":{"id":"yqVRucdizMuf"},"source":["## 1. 데이터 로드 및 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1NhVam2_Fi4"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/data/LSWMD.pkl\")\n","print(df.shape)\n","print(df[\"failureType\"].head())      # 보통 list 형태거나 빈 list\n","print(df[\"trianTestLabel\"].head())   # 기존 train/test 표기가 있을 수 있음(우리는 재분할 권장)"]},{"cell_type":"markdown","metadata":{"id":"fjrCpVOUzPJ5"},"source":["### 1.1 데이터 구조 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMLpGPzlIZCi"},"outputs":[],"source":["print(df.columns)\n","print(df[[\"waferMap\",\"failureType\",\"trianTestLabel\"]].head(3))\n","\n","# waferMap 한 개의 형태 확인\n","wm0 = df[\"waferMap\"].iloc[0]\n","print(type(wm0), getattr(wm0, \"shape\", None))"]},{"cell_type":"markdown","metadata":{"id":"a-5bybsCzeXj"},"source":["### 1.2 라벨 전처리 (failureType → label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xLjOHq7zZ4t"},"outputs":[],"source":["import numpy as np\n","\n","def get_label(x):\n","    if isinstance(x, (list, tuple, np.ndarray)):\n","        return str(x[0][0]) if len(x) > 0 else None\n","    if isinstance(x, str) and x.strip() != \"\":\n","        return x\n","    return None\n","\n","df[\"label\"] = df[\"failureType\"].apply(get_label)\n","\n","print(df[\"label\"].value_counts(dropna=False).head(15))\n","print(\"labeled count:\", df[\"label\"].notna().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeuCIcGvyt8b"},"outputs":[],"source":["print(type(df.iloc[0][\"label\"]))"]},{"cell_type":"markdown","metadata":{"id":"eg4POGB90AVA"},"source":["## 2. Open-set 평가 설계 (클래스 홀드아웃)\n","- Donut과 Scratch를 Unknown(홀드아웃)으로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoVXY6tzzgtM"},"outputs":[],"source":["UNKNOWN_CLASSES = [\"Donut\", \"Scratch\"]\n","EXCLUDE_CLASSES = [\"none\"]\n","\n","labeled = df[df[\"label\"].notna()].copy()\n","labeled = labeled[~labeled[\"label\"].isin(EXCLUDE_CLASSES)].copy()\n","\n","known_df = labeled[~labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","unknown_df = labeled[labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","\n","print(\"labeled:\", len(labeled))\n","print(\"known:\", len(known_df))\n","print(\"unknown:\", len(unknown_df))\n","print(\"known classes:\", sorted(known_df[\"label\"].unique()))\n","print(\"unknown classes:\", sorted(unknown_df[\"label\"].unique()))"]},{"cell_type":"markdown","metadata":{"id":"ETa1JYOssN93"},"source":["## 3. 클래스 이해 및 시각화"]},{"cell_type":"markdown","metadata":{"id":"UCkHAU1bsClI"},"source":["### 3.1 클래스 정의 + 컬러 의미\n","\n","\n","- **Center**: 웨이퍼 **중심(가운데)**에 불량이 몰려 있는 패턴 (가운데 뭉침)\n","- **Donut**: 중심은 비교적 깨끗하고, 그 주변에 **동심원(도넛 링)**처럼 불량이 분포 (원형 띠)\n","- **Edge-Loc (Edge-Local)**: 웨이퍼 **가장자리의 특정 구간**에만 불량이 몰린 패턴 (테두리 한쪽만)\n","- **Edge-Ring**: 웨이퍼 **테두리 전체를 따라 고리(링)**처럼 불량이 나타나는 패턴 (둘레 전체 띠)\n","- **Loc (Local)**: 웨이퍼 내부에서 **중심/테두리가 아닌 임의 위치**에 불량이 뭉친 패턴 (안쪽 어딘가 덩어리)\n","- **Random**: 웨이퍼 전체에 불량이 **듬성듬성, 비교적 고르게 흩어진** 패턴 (여기저기 점)\n","- **Scratch**: **직선/곡선 형태로 길게 이어진** 불량 패턴 (긁힌 자국처럼 선/호)\n","- **Near-full**: 웨이퍼 **거의 전체가 불량으로 채워진** 패턴 (대부분 불량)\n","- **none**: 뚜렷한 결함 패턴이 없거나 결함이 거의 없는 상태 (패턴 없음)\n","---\n","- 보라(가장 어두운 색) = 작은 값 (보통 0) → 웨이퍼 바깥/배경\n","- 파랑(중간 값) = 중간 값 (보통 1) → 정상 die (pass)\n","- 노랑(가장 밝은 색) = 큰 값 (보통 2) → 불량 die (fail)"]},{"cell_type":"markdown","metadata":{"id":"hUVRxPR4hPij"},"source":["### 3.2 클래스별 대표 1장 그리드로 보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gukBRnNsG2m","collapsed":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","labels = sorted(labeled[\"label\"].unique())\n","n = len(labels)\n","\n","cols = 4\n","rows = (n + cols - 1) // cols\n","\n","plt.figure(figsize=(4*cols, 4*rows))\n","for i, lab in enumerate(labels):\n","    wm = labeled[labeled[\"label\"] == lab][\"waferMap\"].iloc[0]  # 첫 샘플\n","    ax = plt.subplot(rows, cols, i+1)\n","    ax.imshow(wm, interpolation=\"nearest\")\n","    ax.set_title(lab)\n","    ax.axis(\"off\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Krj0gzWYsV94"},"source":["### 3.3 특정 Failure Type 랜덤 샘플 보기"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"uUnhzrRLsa0M"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def show_samples(label, n=8, seed=RANDOM_STATE):\n","    sub = labeled[labeled[\"label\"] == label]\n","    if len(sub) == 0:\n","        print(\"No samples for:\", label)\n","        return\n","    sub = sub.sample(n=min(n, len(sub)), random_state=seed)\n","\n","    cols = 4\n","    rows = (len(sub) + cols - 1) // cols\n","    plt.figure(figsize=(4*cols, 4*rows))\n","    for i, wm in enumerate(sub[\"waferMap\"].tolist()):\n","        ax = plt.subplot(rows, cols, i+1)\n","        ax.imshow(wm, interpolation=\"nearest\")\n","        ax.axis(\"off\")\n","    plt.suptitle(f\"{label} (n={len(sub)})\", y=1.02, fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시\n","for label in [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Random\", \"Scratch\", \"Near-full\", \"none\"]:\n","    show_samples(label, n=8, seed=0)"]},{"cell_type":"markdown","metadata":{"id":"EvmhBLFXmgyd"},"source":["## 4. 데이터 분할 (train/val/test_known/test_unknown)\n","\n","- train = 70%\n","- val = 15%\n","- test_known = 15%\n","- test_unknown = unknown_df 전부\n","\n","이 비율은 머신러닝에서 아주 흔한 기본값\n","\n","- train을 충분히 크게 가져가야 학습이 잘 되고\n","- val/test도 너무 작으면 지표가 흔들리니까 적당히 확보하는 균형"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kPjFBtWz7f8"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, temp_df = train_test_split(\n","    known_df, test_size=0.3, random_state=RANDOM_STATE, stratify=known_df[\"label\"] # stratify는 각 split마다 라벨 비율이 원래 데이터랑 비슷하게 유지되도록 나눠주는 옵션\n",")\n","val_df, test_known_df = train_test_split(\n","    temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[\"label\"]\n",")\n","\n","test_unknown_df = unknown_df.copy()\n","\n","print(\"train:\", len(train_df), \"val:\", len(val_df),\n","      \"test_known:\", len(test_known_df), \"test_unknown:\", len(test_unknown_df))"]},{"cell_type":"markdown","metadata":{"id":"rTQ0Plp_mpkJ"},"source":["## 5. Dataset/DataLoader 구성 (전처리/증강)\n","\n","\n","*   waferMap을 64×64로 resize\n","*   1채널을 3채널로 복제해서 ResNet에 넣기 (가장 쉬운 방식)\n","*   회전/반전 증강은 train에만"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDQQDaKPmpBM"},"outputs":[],"source":["import math\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","# ✅ class_to_idx는 \"현재 train_df에서 새로 만들지 말고\"\n","#    분석하려는 ckpt에서 로드한 class_to_idx를 쓰는 게 원칙.\n","#    (단, 지금 학습하는 모드면 아래처럼 train_df 기반 생성 OK)\n","known_classes = sorted(train_df[\"label\"].unique())\n","class_to_idx = {c:i for i,c in enumerate(known_classes)}\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","print(class_to_idx)\n","\n","def _make_polar_grid_and_pos(resize: int, device=\"cpu\", dtype=torch.float32):\n","    \"\"\"\n","    output: (polar_grid[1,H,W,2], pos[3,H,W])\n","    - polar_grid: grid_sample용 (x,y) in [-1,1]\n","    - pos: [r, sin(theta), cos(theta)] 채널\n","    \"\"\"\n","    H = W = resize\n","    r = torch.linspace(0.0, 1.0, H, device=device, dtype=dtype)                 # (H,)\n","    theta = torch.linspace(-math.pi, math.pi, W, device=device, dtype=dtype)     # (W,)\n","\n","    rr = r[:, None].expand(H, W)             # (H,W)\n","    tt = theta[None, :].expand(H, W)         # (H,W)\n","\n","    xx = rr * torch.cos(tt)                  # (H,W)\n","    yy = rr * torch.sin(tt)                  # (H,W)\n","\n","    grid = torch.stack([xx, yy], dim=-1)     # (H,W,2)\n","    grid = grid.unsqueeze(0)                 # (1,H,W,2)  grid_sample expects N,H,W,2\n","\n","    pos = torch.stack([rr, torch.sin(tt), torch.cos(tt)], dim=0)  # (3,H,W)\n","    return grid, pos\n","\n","class WaferMapDataset(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64, input_mode=\"coords4\", return_idx=False):\n","        self.df = df.reset_index(drop=True)\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = int(resize)\n","        self.input_mode = input_mode\n","        self.return_idx = return_idx\n","\n","        # polar4 모드일 때만 polar grid/pos 채널 생성\n","        if self.input_mode == \"polar4\":\n","            self.polar_grid, self.polar_pos = _make_polar_grid_and_pos(self.resize)\n","\n","        # coords4 모드일 때만 좌표 채널 생성\n","        if self.input_mode == \"coords4\":\n","            g = torch.linspace(-1, 1, self.resize)\n","            try:\n","                yy, xx = torch.meshgrid(g, g, indexing=\"ij\")\n","            except TypeError:\n","                yy, xx = torch.meshgrid(g, g)\n","            rr = torch.sqrt(xx**2 + yy**2)\n","            self.coords = torch.stack([xx, yy, rr], dim=0).float()  # (3,R,R)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        # x: (C,H,W)\n","        if self.input_mode == \"polar4\":\n","            # 회전 불변성: theta축 circular shift (rotation == shift)\n","            if torch.rand(()) < 0.9:\n","                shift = int(torch.randint(0, self.resize, ()).item())\n","                x = torch.roll(x, shifts=shift, dims=-1)\n","            # 좌우 반사(선택): theta reverse\n","            if torch.rand(()) < 0.5:\n","                x = torch.flip(x, dims=[-1])\n","            return x\n","\n","        # (기존 coords4/repeat3 쪽 augment가 있으면 여기에 유지)\n","        # 최소 안전 버전: 아무것도 안 함\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        # waferMap -> (1,H,W) float\n","        wm = torch.as_tensor(row[\"waferMap\"], dtype=torch.float32)  # (h,w)\n","        wm = wm.unsqueeze(0).unsqueeze(0)                           # (1,1,h,w)\n","\n","        # resize (원래 discrete 값이면 nearest 권장)\n","        if wm.shape[-1] != self.resize or wm.shape[-2] != self.resize:\n","            wm = F.interpolate(wm, size=(self.resize, self.resize), mode=\"nearest\")\n","        wm = wm.squeeze(0)  # (1,R,R)\n","\n","        # 입력 모드별 채널 구성\n","        if self.input_mode == \"polar4\":\n","          # ✅ (중요) waferMap은 사실상 이산값이므로 먼저 정수화/마스크화\n","          wm_int = wm.round()  # (1,R,R)  값이 0/1/2로 유지되게\n","          defect = (wm_int == 2).float()  # 결함만 1, 나머지 0  -> (1,R,R)\n","\n","          # ✅ (중요) bilinear로 섞이면 선/점 패턴이 흐려짐 → nearest\n","          polar_defect = F.grid_sample(\n","              defect.unsqueeze(0),         # (1,1,R,R)\n","              self.polar_grid,             # (1,R,R,2)\n","              mode=\"nearest\",\n","              padding_mode=\"zeros\",\n","              align_corners=True,\n","          ).squeeze(0)                     # (1,R,R)\n","\n","          # 입력: [결함마스크(1) + (r,sinθ,cosθ)(3)] = 4채널\n","          x = torch.cat([polar_defect, self.polar_pos], dim=0)  # (4,R,R)\n","\n","        elif self.input_mode == \"coords4\":\n","            x = wm                                   # (1,R,R)\n","            x = torch.cat([x, self.coords], dim=0)   # (4,R,R)\n","\n","        elif self.input_mode == \"repeat3\":\n","            x = wm.repeat(3, 1, 1)                   # (3,R,R)\n","\n","        else:\n","            raise ValueError(f\"Unknown input_mode: {self.input_mode}\")\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        # label\n","        if self.class_to_idx is None:\n","            return (x, idx) if self.return_idx else x\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return (x, y, idx) if self.return_idx else (x, y)\n","\n","\n","# ✅ 여기서 INPUT_MODE를 모델 cfg에 맞춰 바꿔 끼울 수 있어야 함\n","# (학습 중이면 coords4로 고정해도 되지만, '과거 ckpt 분석'까지 하려면 아래처럼 변수화)\n","RESIZE = 64\n","\n","train_loader = DataLoader(\n","    WaferMapDataset(train_df, class_to_idx, True, 64, INPUT_MODE),\n","    batch_size=128, shuffle=True, num_workers=2\n",")\n","val_loader = DataLoader(\n","    WaferMapDataset(val_df, class_to_idx, False, 64, INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","test_known_loader = DataLoader(\n","    WaferMapDataset(test_known_df, class_to_idx, False, 64, INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","test_unknown_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64, input_mode=INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")"]},{"cell_type":"markdown","metadata":{"id":"BvA0Nu_WoDyh"},"source":["## 6. Known 분류기 학습 (ResNet18 베이스라인)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cb3m6QkbmjoC"},"outputs":[],"source":["import torchvision.models as models\n","import torch.nn as nn\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = models.resnet18(weights=None)\n","model.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","model.fc = nn.Linear(model.fc.in_features, len(known_classes))\n","model = model.to(device)\n","\n","opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","\n","def run_epoch(loader, train=True, return_preds=False):\n","    model.train(train)\n","    total_loss, correct, total = 0.0, 0, 0\n","    ys, ps = [], []\n","\n","    for x, y in tqdm(loader, disable=not train):\n","        x, y = x.to(device), y.to(device)\n","        logits = model(x)\n","        loss = criterion(logits, y)\n","\n","        if train:\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","        total_loss += loss.item() * x.size(0)\n","        pred = logits.argmax(dim=1)\n","        correct += (pred == y).sum().item()\n","        total += x.size(0)\n","\n","        if return_preds:\n","            ys.append(y.detach().cpu().numpy())\n","            ps.append(pred.detach().cpu().numpy())\n","\n","    if return_preds:\n","        import numpy as np\n","        y_true = np.concatenate(ys)\n","        y_pred = np.concatenate(ps)\n","        return total_loss/total, correct/total, y_true, y_pred\n","\n","    return total_loss/total, correct/total\n","\n","best_val_macro = -1.0\n","best_path = None\n","\n","EPOCHS = 5\n","for epoch in range(1, EPOCHS + 1):\n","    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n","    va_loss, va_acc, yv, pv = run_epoch(val_loader, train=False, return_preds=True)\n","\n","    va_macro = f1_score(yv, pv, average=\"macro\")\n","    print(f\"Epoch {epoch} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n","          f\"val loss {va_loss:.4f} acc {va_acc:.4f} macroF1 {va_macro:.4f}\")\n","\n","    # (선택) best 저장\n","    if va_macro > best_val_macro:\n","        best_val_macro = va_macro\n","        best_path = save_mvp_checkpoint(\n","            model=model,\n","            class_to_idx=class_to_idx,\n","            unknown_classes=UNKNOWN_CLASSES,\n","            resize=64,\n","            arch=\"resnet18\",\n","            optimizer=opt,\n","            metrics={\"epoch\": epoch, \"val_acc\": va_acc, \"val_macro_f1\": va_macro},\n","            tag=f\"best_e{epoch:02d}\"\n","        )\n","\n","# (필수) 학습 끝나면 last 저장\n","last_path = save_mvp_checkpoint(\n","    model=model,\n","    class_to_idx=class_to_idx,\n","    unknown_classes=UNKNOWN_CLASSES,\n","    resize=64,\n","    arch=\"resnet18\",\n","    optimizer=opt,\n","    metrics={\"epoch\": EPOCHS, \"val_acc\": va_acc, \"val_macro_f1\": best_val_macro},\n","    tag=f\"last_e{EPOCHS:02d}\"\n",")\n","\n","print(\"✅ Saved best:\", best_path)\n","print(\"✅ Saved last:\", last_path)"]},{"cell_type":"markdown","metadata":{"id":"ewbcL6n4rW_R"},"source":["## 7. Known 성능 평가 (macro-F1 중심)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzNNV_XwoF7r"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report\n","import torch.nn.functional as F\n","\n","@torch.no_grad()\n","def predict_known(loader):\n","    model.eval()\n","    ys, ps = [], []\n","    for x, y in loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        pred = logits.argmax(dim=1).cpu().numpy()\n","        ys.append(np.array(y))\n","        ps.append(pred)\n","    y_true = np.concatenate(ys)\n","    y_pred = np.concatenate(ps)\n","    return y_true, y_pred\n","\n","y_true, y_pred = predict_known(test_known_loader)\n","print(\"macro-F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n","print(classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(len(known_classes))]))"]},{"cell_type":"markdown","metadata":{"id":"sDWy2TZP0fJP"},"source":["### 7.1 confusion matrix + “Loc이 어디로 새는지 / Random이 누구를 잡아먹는지 확인\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iB4vMeT0sJo"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from sklearn.metrics import confusion_matrix\n","\n","labels = known_classes  # [\"Center\", \"Edge-Loc\", ...] (이미 정렬돼 있음)\n","n = len(labels)\n","\n","# 1) Confusion matrix (raw + row-normalized)\n","cm = confusion_matrix(y_true, y_pred, labels=list(range(n)))\n","cm_row = cm / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n","\n","plt.figure(figsize=(8, 6))\n","plt.imshow(cm_row, vmin=0, vmax=1)\n","plt.xticks(range(n), labels, rotation=45, ha=\"right\")\n","plt.yticks(range(n), labels)\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix (row-normalized)\")\n","plt.colorbar(fraction=0.046, pad=0.04)\n","plt.tight_layout()\n","plt.show()\n","\n","# 2) 클래스별로 '가장 많이 틀리는 방향' Top-k 출력\n","def top_confusions(cm, labels, k=3):\n","    for i, lab in enumerate(labels):\n","        row = cm[i].copy()\n","        row[i] = 0\n","        total = cm[i].sum()\n","        if total == 0:\n","            continue\n","        top = np.argsort(row)[::-1][:k]\n","        print(f\"\\nTrue {lab} (n={total})\")\n","        for j in top:\n","            if row[j] == 0:\n","                continue\n","            print(f\"  -> Pred {labels[j]}: {row[j]} ({row[j]/total:.1%})\")\n","\n","top_confusions(cm, labels, k=3)\n","\n","# 3) Loc(재현율 낮음) / Random(precision 낮음) 집중 분석\n","loc_idx = class_to_idx[\"Loc\"]\n","rand_idx = class_to_idx[\"Random\"]\n","\n","# Loc 미탐: True=Loc인데 Pred!=Loc\n","loc_miss = np.where((y_true == loc_idx) & (y_pred != loc_idx))[0]\n","print(\"\\n[Loc misses]\")\n","print(\"  count:\", len(loc_miss), \"/\", int((y_true == loc_idx).sum()), f\"= {len(loc_miss)/max(1,(y_true==loc_idx).sum()):.1%}\")\n","\n","miss_to = y_pred[loc_miss]\n","vals, cnts = np.unique(miss_to, return_counts=True)\n","for v, c in sorted(zip(vals, cnts), key=lambda x: -x[1]):\n","    print(f\"  Loc -> {idx_to_class[int(v)]}: {c} ({c/len(loc_miss):.1%})\")\n","\n","# Random 오탐: Pred=Random인데 True!=Random\n","rand_fp = np.where((y_pred == rand_idx) & (y_true != rand_idx))[0]\n","print(\"\\n[Random false positives]\")\n","print(\"  count:\", len(rand_fp), \"/\", int((y_pred == rand_idx).sum()), f\"= {len(rand_fp)/max(1,(y_pred==rand_idx).sum()):.1%}\")\n","\n","fp_from = y_true[rand_fp]\n","vals, cnts = np.unique(fp_from, return_counts=True)\n","for v, c in sorted(zip(vals, cnts), key=lambda x: -x[1]):\n","    print(f\"  True {idx_to_class[int(v)]} -> Random: {c} ({c/len(rand_fp):.1%})\")\n","\n","# 4) 실제 웨이퍼맵으로 눈으로 확인 (Loc miss / Random FP)\n","test_known_df_r = test_known_df.reset_index(drop=True).copy()\n","\n","def show_cases(idxs, title=\"\", n_show=12, cols=4):\n","    idxs = list(idxs)[:n_show]\n","    if len(idxs) == 0:\n","        print(title, \": (none)\")\n","        return\n","    rows = math.ceil(len(idxs)/cols)\n","    plt.figure(figsize=(4*cols, 4*rows))\n","    for i, idx in enumerate(idxs):\n","        row = test_known_df_r.iloc[int(idx)]\n","        wm = row[\"waferMap\"]\n","        true_lab = row[\"label\"]\n","        pred_lab = idx_to_class[int(y_pred[int(idx)])]\n","        ax = plt.subplot(rows, cols, i+1)\n","        ax.imshow(wm, interpolation=\"nearest\")\n","        ax.set_title(f\"T:{true_lab}\\nP:{pred_lab}\", fontsize=10)\n","        ax.axis(\"off\")\n","    plt.suptitle(title, y=1.02, fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","show_cases(loc_miss, title=\"Loc misclassified (True=Loc, Pred!=Loc)\", n_show=12)\n","show_cases(rand_fp, title=\"Random false positives (Pred=Random, True!=Random)\", n_show=12)"]},{"cell_type":"markdown","source":["### 7.1 Random threshold 스윕"],"metadata":{"id":"1z2o1ci8ZFR2"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n","\n","# ===== 0) model / device 확보 (너 노트북 스타일 그대로) =====\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = loaded_model if \"loaded_model\" in globals() else model\n","model = model.to(device).eval()\n","\n","assert \"Random\" in class_to_idx, \"known_classes에 'Random'이 없어. (Random 임계값 스윕 불가)\"\n","rand_idx = class_to_idx[\"Random\"]\n","\n","# ===== 1) 확률(probs), argmax 예측, 정답 얻기 =====\n","@torch.no_grad()\n","def get_probs_and_preds(model, loader, device):\n","    model.eval()\n","    all_probs, all_pred, all_true = [], [], []\n","    for x, y in loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        probs = torch.softmax(logits, dim=1)\n","        all_probs.append(probs.cpu().numpy())\n","        all_pred.append(probs.argmax(dim=1).cpu().numpy())\n","        all_true.append(np.array(y))\n","    probs = np.concatenate(all_probs, axis=0)\n","    y_pred = np.concatenate(all_pred, axis=0)\n","    y_true = np.concatenate(all_true, axis=0)\n","    return probs, y_pred, y_true\n","\n","def apply_random_threshold(probs, y_pred_argmax, rand_idx, t_rand: float):\n","    \"\"\"\n","    argmax가 Random인데 Random 확률이 t_rand 미만이면 2등 클래스로 보냄\n","    \"\"\"\n","    y2 = y_pred_argmax.copy()\n","    rand_mask = (y_pred_argmax == rand_idx) & (probs[:, rand_idx] < t_rand)\n","    if rand_mask.any():\n","        second = np.argsort(probs[rand_mask], axis=1)[:, -2]\n","        y2[rand_mask] = second\n","    return y2, int(rand_mask.sum())\n","\n","def plot_cm_row_norm(y_true, y_pred, labels):\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n","    cm_row = cm / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm_row, vmin=0, vmax=1)\n","    plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n","    plt.yticks(range(len(labels)), labels)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    plt.title(\"Confusion Matrix (row-normalized)\")\n","    plt.colorbar(fraction=0.046, pad=0.04)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ===== 2) VAL에서 t_rand 스윕 =====\n","probs_val, pred_val, y_val = get_probs_and_preds(model, val_loader, device)\n","\n","base_macro = f1_score(y_val, pred_val, average=\"macro\")\n","base_acc = accuracy_score(y_val, pred_val)\n","\n","ts = np.arange(0.50, 0.91, 0.05)  # 필요하면 0.02 간격 등으로 촘촘히 바꿔도 됨\n","rows = []\n","for t in ts:\n","    pred_val2, moved = apply_random_threshold(probs_val, pred_val, rand_idx, float(t))\n","    rows.append({\n","        \"t_rand\": float(t),\n","        \"moved_from_random\": moved,\n","        \"val_acc\": float(accuracy_score(y_val, pred_val2)),\n","        \"val_macro_f1\": float(f1_score(y_val, pred_val2, average=\"macro\")),\n","        \"val_macro_f1_gain\": float(f1_score(y_val, pred_val2, average=\"macro\") - base_macro),\n","    })\n","\n","sweep_df = pd.DataFrame(rows).sort_values(\"val_macro_f1\", ascending=False).reset_index(drop=True)\n","\n","print(f\"[VAL baseline] acc={base_acc:.4f}, macroF1={base_macro:.4f}\")\n","display(sweep_df.head(10))\n","\n","best_t = float(sweep_df.loc[0, \"t_rand\"])\n","print(\"\\n✅ best_t (by val macro-F1):\", best_t)\n","\n","# ===== 3) TEST_KNOWN에 best_t 적용 (전/후 리포트) =====\n","probs_test, pred_test, y_test = get_probs_and_preds(model, test_known_loader, device)\n","\n","print(\"\\n[TEST baseline]\")\n","print(\"macro-F1:\", f1_score(y_test, pred_test, average=\"macro\"))\n","print(classification_report(y_test, pred_test, target_names=[idx_to_class[i] for i in range(len(known_classes))]))\n","\n","pred_test2, moved = apply_random_threshold(probs_test, pred_test, rand_idx, best_t)\n","\n","print(\"\\n[TEST after Random-threshold]\")\n","print(\"moved_from_random:\", moved)\n","print(\"macro-F1:\", f1_score(y_test, pred_test2, average=\"macro\"))\n","print(classification_report(y_test, pred_test2, target_names=[idx_to_class[i] for i in range(len(known_classes))]))\n","\n","# (선택) after CM도 같이 보기\n","plot_cm_row_norm(y_test, pred_test2, [idx_to_class[i] for i in range(len(known_classes))])"],"metadata":{"id":"n0tfSkiwZm5q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jum0FDZJrfWD"},"source":["## 8. OOD(Unknown 탐지) 평가: MSP vs Energy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4FMGusPrUAS"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, average_precision_score\n","\n","@torch.no_grad()\n","def collect_scores(loader, known=True, T=1.0):\n","    model.eval()\n","    msp_list, energy_list = [], []\n","    for batch in loader:\n","        x = batch[0] if known else batch\n","        x = x.to(device)\n","\n","        logits = model(x) / T\n","        prob = torch.softmax(logits, dim=1)\n","        msp = prob.max(dim=1).values                   # 높을수록 known\n","        energy = -T * torch.logsumexp(logits, dim=1)   # 보통 -energy가 높을수록 known로 사용\n","\n","        msp_list.append(msp.cpu().numpy())\n","        energy_list.append(energy.cpu().numpy())\n","\n","    return np.concatenate(msp_list), np.concatenate(energy_list)\n","\n","msp_k, en_k = collect_scores(test_known_loader, known=True)\n","msp_u, en_u = collect_scores(test_unknown_loader, known=False)\n","\n","y = np.concatenate([np.ones_like(msp_k), np.zeros_like(msp_u)])  # known=1, unknown=0\n","\n","score_msp = np.concatenate([msp_k, msp_u])\n","score_energy = np.concatenate([-en_k, -en_u])  # -energy를 known 점수로\n","\n","print(\"AUROC MSP   :\", roc_auc_score(y, score_msp))\n","print(\"AUPR  MSP   :\", average_precision_score(y, score_msp))\n","print(\"AUROC Energy:\", roc_auc_score(y, score_energy))\n","print(\"AUPR  Energy:\", average_precision_score(y, score_energy))"]},{"cell_type":"markdown","metadata":{"id":"9ef8a256"},"source":["## 9. 체크포인트 로드\n","\n","\n","저장된 `state_dict`를 불러와 새로운 모델 인스턴스에 로드합니다. 이때, 모델의 아키텍처는 저장할 때와 동일하게 정의되어 있어야 합니다."]},{"cell_type":"markdown","source":["저장은 필요하면 아래 코드 실행"],"metadata":{"id":"SNw-DIlk5mSw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaKk1QccAxeS"},"outputs":[],"source":["ckpt_path = save_mvp_checkpoint(model, class_to_idx, UNKNOWN_CLASSES, resize=64, arch=\"resnet18\", optimizer=None)"]},{"cell_type":"markdown","source":["### Checkpoint만 로드"],"metadata":{"id":"hg8nN0uX37mW"}},{"cell_type":"code","source":["import os, glob\n","import torch\n","import torch.nn as nn\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","CKPT_PATH = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/checkpoints/20260110_105958_resnet18_R64_polar4_K6_best_e04.pt\"\n","\n","# CKPT_PATH 지정 안 했으면 최신 ckpt 자동 선택\n","if \"CKPT_PATH\" not in globals() or CKPT_PATH is None:\n","    ckpts = sorted(glob.glob(os.path.join(CKPT_DIR, \"*.pt\")))\n","    if len(ckpts) == 0:\n","        raise FileNotFoundError(\"No checkpoints found in CKPT_DIR\")\n","    CKPT_PATH = ckpts[-1]\n","\n","# 로드(자동 cfg 포함)\n","model, ckpt, known_classes_model, class_to_idx_model, MODEL_CFG = load_mvp_checkpoint_auto(CKPT_PATH, device=device)\n","\n","# 분석용 공통 변수명으로 세팅(이미 있으면 덮어씀)\n","class_to_idx = class_to_idx_model\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","\n","known_classes = [None]*len(class_to_idx)\n","for c,i in class_to_idx.items():\n","    known_classes[i] = c\n","\n","print(\"analysis classes:\", known_classes)\n","\n","print(\"READY ✅ (ckpt loaded)\")\n","print(\" - CKPT_PATH:\", CKPT_PATH)\n","print(\" - MODEL_CFG:\", MODEL_CFG)"],"metadata":{"id":"I0BdyQta4A_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 데이터/라벨/스플릿"],"metadata":{"id":"zUrrIim04AUl"}},{"cell_type":"code","source":["print(ckpt.get(\"unknown_classes\"))\n","print(known_classes)"],"metadata":{"id":"rf4xrb5hT4uE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/data/LSWMD.pkl\"\n","\n","UNKNOWN_CLASSES = ckpt.get(\"unknown_classes\", [\"Donut\", \"Scratch\"])\n","EXCLUDE_CLASSES = [] if (\"none\" in ckpt.get(\"class_to_idx\", {})) else [\"none\"]\n","print(\"UNKNOWN_CLASSES:\", UNKNOWN_CLASSES)\n","print(\"EXCLUDE_CLASSES:\", EXCLUDE_CLASSES)\n","\n","def _to_label(x):\n","    if x is None:\n","        return None\n","    if isinstance(x, float) and np.isnan(x):\n","        return None\n","\n","    # ndarray/list/tuple 안의 첫 원소를 scalar string까지 벗김\n","    for _ in range(5):\n","        if isinstance(x, np.ndarray):\n","            if x.size == 0:\n","                return None\n","            x = x.ravel()[0]\n","            continue\n","        if isinstance(x, (list, tuple)):\n","            if len(x) == 0:\n","                return None\n","            x = x[0]\n","            continue\n","        break\n","\n","    if isinstance(x, np.generic):\n","        x = x.item()\n","\n","    if isinstance(x, str):\n","        x = x.strip()\n","        return x if x != \"\" else None\n","\n","    return str(x)\n","\n","# df 로드/label 생성 (skip)\n","if \"df\" not in globals() or df is None:\n","    print(\"Download origin data\")\n","    df = pd.read_pickle(DATA_PATH)\n","\n","if \"label\" not in df.columns:\n","    df[\"label\"] = df[\"failureType\"].apply(_to_label)\n","\n","# splits 생성 (skip)\n","need_split = not all(k in globals() for k in [\"train_df\",\"val_df\",\"test_known_df\",\"test_unknown_df\"])\n","if need_split:\n","    labeled = df[df[\"label\"].notna()].copy()\n","    labeled = labeled[~labeled[\"label\"].isin(EXCLUDE_CLASSES)].copy()\n","\n","    known_all = labeled[~labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","    unknown_df = labeled[labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","\n","    # stratify fallback\n","    try:\n","        train_df, temp_df = train_test_split(\n","            known_all, test_size=0.3, random_state=RANDOM_STATE, stratify=known_all[\"label\"]\n","        )\n","        val_df, test_known_df = train_test_split(\n","            temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[\"label\"]\n","        )\n","    except ValueError as e:\n","        print(\"[Warn] Stratified split failed -> fallback:\", e)\n","        train_df, temp_df = train_test_split(known_all, test_size=0.3, random_state=RANDOM_STATE, shuffle=True)\n","        val_df, test_known_df = train_test_split(temp_df, test_size=0.5, random_state=RANDOM_STATE, shuffle=True)\n","\n","    test_unknown_df = unknown_df.copy()\n","\n","print(\"READY ✅ (data/split)\")\n","print(\" - train/val/test_known/test_unknown:\", len(train_df), len(val_df), len(test_known_df), len(test_unknown_df))"],"metadata":{"id":"y7eeMsYX4UAx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCR7aztMgr-T"},"source":["## 10. 트리아지(MVP-2): 임베딩 기반 유사사례/시각화"]},{"cell_type":"markdown","metadata":{"id":"d0NANDMyhTAv"},"source":["### 10.1 트리아지용 Dataset (이미지 + 라벨 + row index)"]},{"cell_type":"markdown","source":["[5. Dataset/DataLoader 구성 (전처리/증강)](https://colab.research.google.com/drive/1gs1u8PboIWySUJ-siTfmclQ26GcwqYCu#scrollTo=MDQQDaKPmpBM&line=4&uniqifier=1)에 학습된 모델을 불러와서 진행할 경우 정리된 class 호출 후, 진행"],"metadata":{"id":"t6LYKYvdTAk-"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","def _make_polar_grid_and_pos(resize: int, device=\"cpu\", dtype=torch.float32):\n","    \"\"\"\n","    output: (polar_grid[1,H,W,2], pos[3,H,W])\n","    - polar_grid: grid_sample용 (x,y) in [-1,1]\n","    - pos: [r, sin(theta), cos(theta)] 채널\n","    \"\"\"\n","    H = W = resize\n","    r = torch.linspace(0.0, 1.0, H, device=device, dtype=dtype)                 # (H,)\n","    theta = torch.linspace(-math.pi, math.pi, W, device=device, dtype=dtype)     # (W,)\n","\n","    rr = r[:, None].expand(H, W)             # (H,W)\n","    tt = theta[None, :].expand(H, W)         # (H,W)\n","\n","    xx = rr * torch.cos(tt)                  # (H,W)\n","    yy = rr * torch.sin(tt)                  # (H,W)\n","\n","    grid = torch.stack([xx, yy], dim=-1)     # (H,W,2)\n","    grid = grid.unsqueeze(0)                 # (1,H,W,2)  grid_sample expects N,H,W,2\n","\n","    pos = torch.stack([rr, torch.sin(tt), torch.cos(tt)], dim=0)  # (3,H,W)\n","    return grid, pos\n","\n","class WaferMapDataset(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64, input_mode=\"coords4\", return_idx=False):\n","        self.df = df.reset_index(drop=True)\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = int(resize)\n","        self.input_mode = input_mode\n","        self.return_idx = return_idx\n","\n","        # polar4 모드일 때만 polar grid/pos 채널 생성\n","        if self.input_mode == \"polar4\":\n","            self.polar_grid, self.polar_pos = _make_polar_grid_and_pos(self.resize)\n","\n","        # coords4 모드일 때만 좌표 채널 생성\n","        if self.input_mode == \"coords4\":\n","            g = torch.linspace(-1, 1, self.resize)\n","            try:\n","                yy, xx = torch.meshgrid(g, g, indexing=\"ij\")\n","            except TypeError:\n","                yy, xx = torch.meshgrid(g, g)\n","            rr = torch.sqrt(xx**2 + yy**2)\n","            self.coords = torch.stack([xx, yy, rr], dim=0).float()  # (3,R,R)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        # x: (C,H,W)\n","        if self.input_mode == \"polar4\":\n","            # 회전 불변성: theta축 circular shift (rotation == shift)\n","            if torch.rand(()) < 0.9:\n","                shift = int(torch.randint(0, self.resize, ()).item())\n","                x = torch.roll(x, shifts=shift, dims=-1)\n","            # 좌우 반사(선택): theta reverse\n","            if torch.rand(()) < 0.5:\n","                x = torch.flip(x, dims=[-1])\n","            return x\n","\n","        # (기존 coords4/repeat3 쪽 augment가 있으면 여기에 유지)\n","        # 최소 안전 버전: 아무것도 안 함\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        # waferMap -> (1,H,W) float\n","        wm = torch.as_tensor(row[\"waferMap\"], dtype=torch.float32)  # (h,w)\n","        wm = wm.unsqueeze(0).unsqueeze(0)                           # (1,1,h,w)\n","\n","        # resize (원래 discrete 값이면 nearest 권장)\n","        if wm.shape[-1] != self.resize or wm.shape[-2] != self.resize:\n","            wm = F.interpolate(wm, size=(self.resize, self.resize), mode=\"nearest\")\n","        wm = wm.squeeze(0)  # (1,R,R)\n","\n","        # 입력 모드별 채널 구성\n","        if self.input_mode == \"polar4\":\n","          # ✅ (중요) waferMap은 사실상 이산값이므로 먼저 정수화/마스크화\n","          wm_int = wm.round()  # (1,R,R)  값이 0/1/2로 유지되게\n","          defect = (wm_int == 2).float()  # 결함만 1, 나머지 0  -> (1,R,R)\n","\n","          # ✅ (중요) bilinear로 섞이면 선/점 패턴이 흐려짐 → nearest\n","          polar_defect = F.grid_sample(\n","              defect.unsqueeze(0),         # (1,1,R,R)\n","              self.polar_grid,             # (1,R,R,2)\n","              mode=\"nearest\",\n","              padding_mode=\"zeros\",\n","              align_corners=True,\n","          ).squeeze(0)                     # (1,R,R)\n","\n","          # 입력: [결함마스크(1) + (r,sinθ,cosθ)(3)] = 4채널\n","          x = torch.cat([polar_defect, self.polar_pos], dim=0)  # (4,R,R)\n","\n","        elif self.input_mode == \"coords4\":\n","            x = wm                                   # (1,R,R)\n","            x = torch.cat([x, self.coords], dim=0)   # (4,R,R)\n","\n","        elif self.input_mode == \"repeat3\":\n","            x = wm.repeat(3, 1, 1)                   # (3,R,R)\n","\n","        else:\n","            raise ValueError(f\"Unknown input_mode: {self.input_mode}\")\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        # label\n","        if self.class_to_idx is None:\n","            return (x, idx) if self.return_idx else x\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return (x, y, idx) if self.return_idx else (x, y)"],"metadata":{"id":"l-ZLxVsGS1mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","from torch.utils.data import DataLoader\n","import torch\n","\n","# -------------------------\n","# ✅ RESIZE / INPUT_MODE fallback\n","# -------------------------\n","DEFAULT_RESIZE = 64  # 네 기본값\n","\n","# RESIZE\n","if \"MODEL_CFG\" in globals() and isinstance(MODEL_CFG, dict) and (\"resize\" in MODEL_CFG):\n","    RESIZE = int(MODEL_CFG[\"resize\"])\n","elif \"RESIZE\" in globals():\n","    RESIZE = int(RESIZE)\n","else:\n","    RESIZE = DEFAULT_RESIZE\n","\n","# model 잡기 (loaded_model 우선)\n","model_use = loaded_model if \"loaded_model\" in globals() else model\n","\n","# INPUT_MODE\n","if \"MODEL_CFG\" in globals() and isinstance(MODEL_CFG, dict) and (\"input_mode\" in MODEL_CFG):\n","    INPUT_MODE = MODEL_CFG[\"input_mode\"]\n","else:\n","    # ✅ 모델 conv1 채널로 자동 결정\n","    in_ch = model_use.conv1.in_channels if hasattr(model_use, \"conv1\") else 3\n","    INPUT_MODE = \"coords4\" if in_ch == 4 else \"repeat3\"\n","\n","def _filter_by_mapping(df_, class_to_idx):\n","    return df_[df_[\"label\"].isin(class_to_idx.keys())].copy()\n","\n","# 이미 있으면 skip (설정이 바뀌면 다시 만들기 위해 cfg 저장)\n","if \"__LOADERS_CFG__\" not in globals():\n","    __LOADERS_CFG__ = None\n","\n","cfg_now = (RESIZE, INPUT_MODE, tuple(sorted(class_to_idx.keys())))\n","if __LOADERS_CFG__ != cfg_now:\n","    train_loader = DataLoader(\n","        WaferMapDataset(_filter_by_mapping(train_df, class_to_idx), class_to_idx, True, RESIZE, INPUT_MODE),\n","        batch_size=128, shuffle=True, num_workers=2\n","    )\n","    val_loader = DataLoader(\n","        WaferMapDataset(_filter_by_mapping(val_df, class_to_idx), class_to_idx, False, RESIZE, INPUT_MODE),\n","        batch_size=256, shuffle=False, num_workers=2\n","    )\n","    test_known_loader = DataLoader(\n","        WaferMapDataset(_filter_by_mapping(test_known_df, class_to_idx), class_to_idx, False, RESIZE, INPUT_MODE),\n","        batch_size=256, shuffle=False, num_workers=2\n","    )\n","    __LOADERS_CFG__ = cfg_now\n","else:\n","    print(\"Skip loaders: same __LOADERS_CFG__\")\n","\n","print(\"READY ✅ (loaders)\")\n","print(\" - RESIZE:\", RESIZE, \"| INPUT_MODE:\", INPUT_MODE)\n","print(\" - model conv1 in_ch:\", getattr(model_use.conv1, \"in_channels\", \"N/A\") if hasattr(model_use, \"conv1\") else \"N/A\")"],"metadata":{"id":"Yf7nmIB05eRJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3szZwQwg3YH"},"source":["### 10.2 레퍼런스(known) 풀 샘플링"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uN5aESipg6EC"},"outputs":[],"source":["# ✅ 추천: reference에서는 none을 줄이거나 제외\n","MAX_PER_CLASS = 1500\n","MAX_NONE = 2000\n","\n","ref_parts = []\n","for c in known_classes:\n","    sub = train_df[train_df[\"label\"] == c]\n","    if c == \"none\":\n","        sub = sub.sample(n=min(len(sub), MAX_NONE), random_state=RANDOM_STATE)\n","    else:\n","        sub = sub.sample(n=min(len(sub), MAX_PER_CLASS), random_state=RANDOM_STATE)\n","    ref_parts.append(sub)\n","\n","ref_df = pd.concat(ref_parts).sample(frac=1.0, random_state=RANDOM_STATE).reset_index(drop=True)\n","print(\"ref_df size:\", len(ref_df))\n","print(ref_df[\"label\"].value_counts().head())"]},{"cell_type":"markdown","metadata":{"id":"iKotJqQ8hmus"},"source":["### 10.3 임베딩 추출 모델 (fc 직전 특징)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0A6_865Nho8o"},"outputs":[],"source":["import torch.nn as nn\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# model은 너가 학습한 모델(또는 loaded_model) 사용\n","model = loaded_model if \"loaded_model\" in globals() else model\n","model = model.to(device).eval()\n","\n","# fc 제거 → 임베딩 추출기\n","embed_model = nn.Sequential(*list(model.children())[:-1]).to(device).eval()\n","\n","@torch.no_grad()\n","def collect_embeddings_ref(loader):\n","    embs, labels, idxs = [], [], []\n","    for x, y, idx in loader:\n","        x = x.to(device)\n","        e = embed_model(x).squeeze(-1).squeeze(-1)  # (N,512,1,1) -> (N,512)\n","        embs.append(e.cpu())\n","        labels.append(torch.tensor(y))\n","        idxs.append(torch.tensor(idx))\n","    return torch.cat(embs, 0).numpy(), torch.cat(labels, 0).numpy(), torch.cat(idxs, 0).numpy()\n","\n","@torch.no_grad()\n","def collect_embeddings_unknown(loader):\n","    embs, idxs = [], []\n","    for x, idx in loader:\n","        x = x.to(device)\n","        e = embed_model(x).squeeze(-1).squeeze(-1)\n","        embs.append(e.cpu())\n","        idxs.append(torch.tensor(idx))\n","    return torch.cat(embs, 0).numpy(), torch.cat(idxs, 0).numpy()"]},{"cell_type":"markdown","metadata":{"id":"F4UgUGpBhruv"},"source":["### 10.4 임베딩 추출 (ref/unknown)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDpeeC4egy9s"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","# ✅ 모델 입력 채널에 맞춰 자동으로 결정\n","INPUT_MODE = \"polar4\" # 과거 모드 \"coords4\" if model.conv1.in_channels == 4 else \"repeat3\"\n","print(\"INPUT_MODE for loaders:\", INPUT_MODE)\n","\n","# reference(known)\n","ref_loader = DataLoader(\n","    WaferMapDataset(ref_df, class_to_idx=class_to_idx, is_train=False, resize=RESIZE,\n","                    input_mode=INPUT_MODE, return_idx=True),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","# unknown(test_unknown_df)\n","unk_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=RESIZE,\n","                    input_mode=INPUT_MODE, return_idx=True),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","# embed_model은 현재 model에서 다시 생성(안전)\n","import torch.nn as nn\n","embed_model = nn.Sequential(*list(model.children())[:-1]).to(device).eval()\n","\n","ref_emb, ref_y, ref_local_idx = collect_embeddings_ref(ref_loader)\n","unk_emb, unk_local_idx = collect_embeddings_unknown(unk_loader)\n","\n","print(\"ref_emb:\", ref_emb.shape, \"unk_emb:\", unk_emb.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"gyPJJR5Ci6bk"},"source":["### 10.5 Unknown → 유사사례 Top-K 검색 (코사인 유사도)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmoNPrpqhvA8"},"outputs":[],"source":["import numpy as np\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","ref_n = l2norm(ref_emb)\n","unk_n = l2norm(unk_emb)\n","\n","# Top-K retrieval\n","K = 5\n","# (unk x ref) similarity가 커질 수 있으니 unk를 배치로 처리\n","def topk_retrieval(unk_n, ref_n, k=5, chunk=512):\n","    topk_idx_all, topk_sim_all = [], []\n","    ref_t = torch.tensor(ref_n, dtype=torch.float32)\n","    for i in range(0, len(unk_n), chunk):\n","        u = torch.tensor(unk_n[i:i+chunk], dtype=torch.float32)\n","        sim = u @ ref_t.T  # cosine similarity\n","        topk_sim, topk_idx = torch.topk(sim, k=k, dim=1)\n","        topk_idx_all.append(topk_idx.numpy())\n","        topk_sim_all.append(topk_sim.numpy())\n","    return np.vstack(topk_idx_all), np.vstack(topk_sim_all)\n","\n","topk_idx, topk_sim = topk_retrieval(unk_n, ref_n, k=K, chunk=512)\n","print(topk_idx.shape, topk_sim.shape)  # (num_unknown, K)"]},{"cell_type":"markdown","metadata":{"id":"l2AgTxlci--V"},"source":["### 10.6 Top-K 결과 시각화 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5E5hzrmGi8tT"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def show_triage_case(unk_i, K=5):\n","    # unknown 샘플\n","    unk_row = test_unknown_df.iloc[int(unk_local_idx[unk_i])]\n","    unk_wm = unk_row[\"waferMap\"]\n","\n","    # ref 샘플들\n","    ref_indices = topk_idx[unk_i][:K]\n","    ref_sims = topk_sim[unk_i][:K]\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    # unknown\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_wm)\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rloc = int(ref_local_idx[ref_indices[j]])  # ref_df의 로컬 인덱스\n","        rrow = ref_df.iloc[rloc]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={ref_sims[j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시로 3개만 보기\n","for i in [0, 1, 2]:\n","    show_triage_case(i, K=5)"]},{"cell_type":"markdown","metadata":{"id":"mm2w_a0ejGSW"},"source":["### 10.7 2D 시각화 (UMAP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0_s_zQ9jDMb"},"outputs":[],"source":["!pip -q install umap-learn\n","\n","import umap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 시각화는 너무 많으면 느리니 샘플링\n","N_REF_VIS = min(5000, len(ref_emb))\n","N_UNK_VIS = min(2000, len(unk_emb))\n","\n","rng = np.random.RandomState(RANDOM_STATE)\n","ref_vis_idx = rng.choice(len(ref_emb), size=N_REF_VIS, replace=False)\n","unk_vis_idx = rng.choice(len(unk_emb), size=N_UNK_VIS, replace=False)\n","\n","X_vis = np.vstack([ref_emb[ref_vis_idx], unk_emb[unk_vis_idx]])\n","y_vis = np.concatenate([ref_y[ref_vis_idx], -1*np.ones(N_UNK_VIS, dtype=int)])  # unknown=-1\n","\n","reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=RANDOM_STATE)\n","Z = reducer.fit_transform(X_vis)\n","\n","plt.figure(figsize=(8,6))\n","\n","# ✅ unknown 먼저\n","mask_unk = (y_vis == -1)\n","plt.scatter(Z[mask_unk, 0], Z[mask_unk, 1], s=6, label=\"Unknown\", alpha=0.9)\n","\n","# ✅ known 클래스별 범례\n","for k in sorted(np.unique(y_vis)):\n","    if k == -1:\n","        continue\n","    mask = (y_vis == k)\n","    name = idx_to_class.get(int(k), f\"Class {int(k)}\")  # idx_to_class 없으면 숫자 표시\n","    plt.scatter(Z[mask, 0], Z[mask, 1], s=6, label=name, alpha=0.9)\n","\n","plt.title(\"Embedding 2D (UMAP): known vs unknown\")\n","plt.legend(markerscale=3, bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IaJdjzCljI2r"},"outputs":[],"source":["import numpy as np\n","print(\"known points:\", np.sum(y_vis != -1))\n","print(\"unknown points:\", np.sum(y_vis == -1))\n","print(\"unique labels (incl -1):\", np.unique(y_vis)[:20])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CW0Byy4Pjze8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","known_mask = (y_vis != -1)\n","unk_mask = (y_vis == -1)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[known_mask,0], Z[known_mask,1], s=6, alpha=0.25, label=\"known\")\n","plt.scatter(Z[unk_mask,0],   Z[unk_mask,1],   s=8, alpha=0.9,  label=\"unknown\")\n","plt.title(\"Embedding 2D (UMAP): known (gray) vs unknown (red)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FE-r0fP0j1FG"},"outputs":[],"source":["import umap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","Xn = l2norm(X_vis)  # 코사인에 맞게 정규화(권장)\n","\n","reducer = umap.UMAP(metric=\"cosine\", n_neighbors=15, min_dist=0.1, random_state=RANDOM_STATE)\n","Z = reducer.fit_transform(Xn)\n","\n","known_mask = (y_vis != -1)\n","unk_mask = (y_vis == -1)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[known_mask,0], Z[known_mask,1], s=6, alpha=0.25, color=\"gray\", label=\"known\")\n","plt.scatter(Z[unk_mask,0],   Z[unk_mask,1],   s=10, alpha=0.9,  color=\"red\",  label=\"unknown\")\n","plt.title(\"Embedding 2D (UMAP-cosine): known (gray) vs unknown (red)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"OhBoRb5SvPTy"},"source":["### 10.8 Top-K 트리아지 데모"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPPPgafAj29L"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","ref_n = l2norm(ref_emb).astype(np.float32)\n","unk_n = l2norm(unk_emb).astype(np.float32)\n","\n","def topk_retrieval(unk_n, ref_n, k=5, chunk=512):\n","    topk_idx_all, topk_sim_all = [], []\n","    ref_t = torch.tensor(ref_n)  # (Nref, D)\n","    for i in range(0, len(unk_n), chunk):\n","        u = torch.tensor(unk_n[i:i+chunk])   # (chunk, D)\n","        sim = u @ ref_t.T                    # (chunk, Nref)\n","        topk_sim, topk_idx = torch.topk(sim, k=k, dim=1)\n","        topk_idx_all.append(topk_idx.numpy())\n","        topk_sim_all.append(topk_sim.numpy())\n","    return np.vstack(topk_idx_all), np.vstack(topk_sim_all)\n","\n","K = 5\n","topk_idx, topk_sim = topk_retrieval(unk_n, ref_n, k=K, chunk=512)\n","print(topk_idx.shape, topk_sim.shape)  # (N_unknown, K)"]},{"cell_type":"markdown","source":["#### 10.8-A Loc-family subclustering + Cluster-restricted Top-K"],"metadata":{"id":"BDHRXaT2_PjU"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.cluster import MiniBatchKMeans\n","\n","# Loc만 쓰고 싶으면 [\"Loc\"]\n","# Loc+Edge-Loc을 \"같은 계열\"로 묶고 싶으면 아래처럼\n","LOCAL_LABELS = [\"Loc\", \"Edge-Loc\"]\n","LOCAL_IDS = [class_to_idx[x] for x in LOCAL_LABELS if x in class_to_idx]\n","print(\"LOCAL_LABELS:\", LOCAL_LABELS, \"LOCAL_IDS:\", LOCAL_IDS)\n","\n","# ref_emb/ref_n/ref_y 기준으로 Local-family만 필터\n","local_mask = np.isin(ref_y, LOCAL_IDS)\n","local_ref_emb_idx = np.where(local_mask)[0]     # ref_emb/ref_n 상의 인덱스\n","local_ref_n = ref_n[local_mask]                 # normalized embeddings\n","\n","print(\"local_ref_n:\", local_ref_n.shape)\n","\n","# 클러스터 개수(8~16 권장)\n","K_LOC = 12\n","kmeans = MiniBatchKMeans(n_clusters=K_LOC, random_state=0, batch_size=2048, n_init=\"auto\")\n","local_cluster = kmeans.fit_predict(local_ref_n)\n","\n","centroids = kmeans.cluster_centers_\n","centroids = centroids / (np.linalg.norm(centroids, axis=1, keepdims=True) + 1e-12)\n","\n","cluster_to_pos = {c: np.where(local_cluster == c)[0] for c in range(K_LOC)}\n","print(\"cluster sizes:\", {c: len(v) for c, v in cluster_to_pos.items()})\n","\n","def local_cluster_topk(unk_i, k=5):\n","    \"\"\"\n","    unk_i: unk_n 기준 인덱스\n","    return:\n","      c_id: 선택된 클러스터 id\n","      ref_idx: ref_emb/ref_n 기준 topk ref 인덱스들 (k,)\n","      sims: cosine similarity (k,)\n","    \"\"\"\n","    u = unk_n[unk_i]\n","    c_id = int((centroids @ u).argmax())\n","\n","    pos = cluster_to_pos[c_id]          # local_ref_n에서의 위치들\n","    sims = local_ref_n[pos] @ u         # cluster 내부 similarity\n","\n","    top = np.argsort(-sims)[:k]\n","    ref_idx = local_ref_emb_idx[pos[top]]  # ref_emb/ref_n 기준 인덱스로 변환\n","    return c_id, ref_idx, sims[top]\n","\n","def local_cluster_topk_multi(unk_i, k=5, topC=3):\n","    \"\"\"\n","    centroid 상위 topC개 클러스터를 풀링해서 Top-K 검색\n","    return:\n","      top_cs: 선택된 클러스터 id 리스트\n","      ref_idx: ref_emb 기준 topk 인덱스 (k,)\n","      sims: cosine sim (k,)\n","    \"\"\"\n","    u = unk_n[unk_i]\n","    sim_c = centroids @ u\n","    top_cs = np.argsort(-sim_c)[:topC].tolist()\n","\n","    pos_all = np.concatenate([cluster_to_pos[c] for c in top_cs])\n","    sims = local_ref_n[pos_all] @ u\n","    top = np.argsort(-sims)[:k]\n","\n","    ref_idx = local_ref_emb_idx[pos_all[top]]\n","    return top_cs, ref_idx, sims[top]"],"metadata":{"id":"X3bDmA3w_NYh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-B 평가 지표: \"Scratch-like Loc hit-rate\""],"metadata":{"id":"RMcHyAm8T7HB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from collections import Counter\n","\n","\n","def line_score(wm):\n","    \"\"\"\n","    waferMap에서 '선(스크래치)스러움'을 대략 점수화.\n","    - foreground 픽셀 좌표의 PCA 이방성(eccentricity) 기반\n","    - 픽셀 수가 너무 적으면 0\n","    \"\"\"\n","    a = np.asarray(wm)\n","    coords = np.argwhere(a > 0)\n","    n = coords.shape[0]\n","    if n < 20:\n","        return 0.0\n","\n","    coords = coords.astype(np.float32)\n","    coords -= coords.mean(axis=0, keepdims=True)\n","    cov = (coords.T @ coords) / (n + 1e-12)      # 2x2\n","    eig = np.linalg.eigvalsh(cov)               # 오름차순\n","    eig = np.sort(eig)[::-1]                    # 내림차순\n","\n","    if eig[0] < 1e-6:\n","        return 0.0\n","\n","    ecc = 1.0 - (eig[1] / (eig[0] + 1e-12))     # 0~1 (선형일수록 1에 가까움)\n","    return float(ecc * np.log1p(n))             # 픽셀 수로 가중(너무 작은 잡음 억제)\n","\n","def unk_true_label(unk_i):\n","    # unk_i(임베딩 인덱스) -> test_unknown_df row -> label\n","    row = test_unknown_df.iloc[int(unk_local_idx[unk_i])]\n","    return row[\"label\"] if \"label\" in row else None\n","\n","# 1) Local-family(Loc/Edge-Loc) ref들 중 \"스크래치성 높은\" ref를 만들기\n","scores = []\n","for ref_i in local_ref_emb_idx:\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    scores.append(line_score(wm))\n","\n","scores = np.array(scores)\n","PCT = 90  # 상위 10%를 scratch-like로 간주 (원하면 85~95로 조절)\n","thr = np.percentile(scores, PCT)\n","\n","scratch_like_ref_idx = set(local_ref_emb_idx[scores >= thr].tolist())\n","print(f\"[scratch-like ref] LOCAL_LABELS={LOCAL_LABELS}, count={len(scratch_like_ref_idx)}/{len(local_ref_emb_idx)} (>=P{PCT})\")\n","\n","# 2) Scratch unknown 인덱스 모으기\n","scratch_unk_i = [i for i in range(len(unk_local_idx)) if unk_true_label(i) == \"Scratch\"]\n","print(\"[scratch unknowns]:\", len(scratch_unk_i))\n","\n","if len(scratch_unk_i) == 0:\n","    print(\"⚠️ Scratch unknown이 0개야. (test_unknown_df['label']에 'Scratch'가 있는지 확인해줘.)\")\n","\n","def hit_stats(unk_indices, K=5, use_local=False):\n","    hit_any, hit_frac, top1_sim = [], [], []\n","    for i in unk_indices:\n","        if use_local:\n","            _, ridx, sims = local_cluster_topk(i, k=K)     # Option A\n","            sims = np.asarray(sims)\n","        else:\n","            ridx = topk_idx[i][:K]                         # Global\n","            sims = np.asarray(topk_sim[i][:K])\n","\n","        hits = np.array([1 if int(r) in scratch_like_ref_idx else 0 for r in ridx], dtype=np.float32)\n","        hit_any.append(float(hits.max()))\n","        hit_frac.append(float(hits.mean()))\n","        top1_sim.append(float(sims[0]))\n","\n","    return np.mean(hit_any), np.mean(hit_frac), np.mean(top1_sim)\n","\n","K = 5\n","g_any, g_frac, g_sim = hit_stats(scratch_unk_i, K=K, use_local=False)\n","l_any, l_frac, l_sim = hit_stats(scratch_unk_i, K=K, use_local=True)\n","\n","df = pd.DataFrame({\n","    \"retrieval\": [\"Global Top-K\", \"LocalCluster Top-K\"],\n","    f\"hit@{K} (any)\": [g_any, l_any],\n","    f\"hit@{K} (frac)\": [g_frac, l_frac],\n","    \"top1_sim (avg)\": [g_sim, l_sim],\n","})\n","display(df)\n","\n","# 3) (추가 관찰) Scratch unknown들이 어느 클러스터로 몰리는지\n","if len(scratch_unk_i) > 0:\n","    cids = [int(local_cluster_topk(i, k=1)[0]) for i in scratch_unk_i]\n","    print(\"[Scratch -> cluster distribution]:\", Counter(cids))\n"],"metadata":{"id":"ppBettl_UBrg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-C line-rerank 준비 + rerank 함수"],"metadata":{"id":"akKzuqeFXYos"}},{"cell_type":"code","source":["import numpy as np\n","\n","# ---- (1) line feature ----\n","def line_feat(wm):\n","    a = np.asarray(wm)\n","    coords = np.argwhere(a > 0)\n","    n = coords.shape[0]\n","    if n < 20:\n","        return np.array([0,0,0,0,0], dtype=np.float32)\n","\n","    coords = coords.astype(np.float32)\n","    coords -= coords.mean(axis=0, keepdims=True)\n","    cov = (coords.T @ coords) / (n + 1e-12)\n","\n","    eigvals, eigvecs = np.linalg.eigh(cov)     # eigvals 오름차순\n","    order = np.argsort(eigvals)[::-1]\n","    eigvals = eigvals[order]\n","    v = eigvecs[:, order[0]]                   # 주축 방향\n","\n","    # 선형성/길이/폭/비율\n","    ecc = 1.0 - (eigvals[1] / (eigvals[0] + 1e-12))\n","    length = np.sqrt(eigvals[0] + 1e-12)\n","    width  = np.sqrt(eigvals[1] + 1e-12)\n","    ratio = length / (width + 1e-6)\n","\n","    # 방향(π 대칭) -> cos(2θ), sin(2θ)\n","    theta = np.arctan2(v[0], v[1])\n","    c2, s2 = np.cos(2*theta), np.sin(2*theta)\n","\n","    return np.array([ecc, np.log1p(n), ratio, c2, s2], dtype=np.float32)\n","\n","# ---- (2) local-family ref feature precompute (1회) ----\n","local_ref_feat = []\n","for ref_i in local_ref_emb_idx:\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    local_ref_feat.append(line_feat(wm))\n","local_ref_feat = np.stack(local_ref_feat)  # (M, 5)\n","\n","mu = local_ref_feat.mean(axis=0, keepdims=True)\n","sd = local_ref_feat.std(axis=0, keepdims=True) + 1e-6\n","local_ref_feat_z = (local_ref_feat - mu) / sd\n","\n","# ref_emb 인덱스 -> local_ref_feat_z row 매핑\n","refidx_to_localpos = {int(ref_i): p for p, ref_i in enumerate(local_ref_emb_idx)}\n","\n","# ---- (3) candidate builder: local-family 전체에서 Top-M (임베딩 기준) ----\n","def local_family_topM(unk_i, M=500):\n","    u = unk_n[unk_i]\n","    sims = local_ref_n @ u               # (M_local,)\n","    top = np.argsort(-sims)[:M]\n","    ref_idx = local_ref_emb_idx[top]     # ref_emb 기준\n","    return ref_idx, sims[top]\n","\n","# ---- (4) rerank ----\n","def rerank_by_line(unk_i, cand_ref_idx, cand_emb_sim, lam=0.25, K=5):\n","    \"\"\"\n","    cand_ref_idx: ref_emb 기준 후보 인덱스\n","    cand_emb_sim: 후보의 embedding cosine sim\n","    lam: line feature 가중치\n","    \"\"\"\n","    # unk feature\n","    unk_wm = test_unknown_df.iloc[int(unk_local_idx[unk_i])][\"waferMap\"]\n","    uf = (line_feat(unk_wm)[None, :] - mu) / sd  # (1,5)\n","\n","    # 후보 feature\n","    pos = np.array([refidx_to_localpos[int(r)] for r in cand_ref_idx], dtype=np.int64)\n","    rf = local_ref_feat_z[pos]  # (M,5)\n","\n","    # feature distance -> similarity\n","    d = np.linalg.norm(rf - uf, axis=1)\n","    feat_sim = np.exp(-(d**2) / 2.0)     # sigma~1 가정\n","\n","    score = cand_emb_sim + lam * feat_sim\n","    top = np.argsort(-score)[:K]\n","    return cand_ref_idx[top], cand_emb_sim[top], feat_sim[top]\n","\n","def rerank_topK(unk_i, M=500, K=5, lam=0.25):\n","    cand_ref_idx, cand_sim = local_family_topM(unk_i, M=M)\n","    return rerank_by_line(unk_i, cand_ref_idx, cand_sim, lam=lam, K=K)"],"metadata":{"id":"2wregoYkXaf2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-D: thin-scratch λ(0.1~0.5) 스윕"],"metadata":{"id":"FUVw4jKTZA3a"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# --- thin scratch subset 만들기 (Scratch 중 line_score 상위 20%) ---\n","unk_scores = []\n","scratch_idx = []\n","for i in range(len(unk_local_idx)):\n","    row = test_unknown_df.iloc[int(unk_local_idx[i])]\n","    if row.get(\"label\") == \"Scratch\":\n","        s = line_score(row[\"waferMap\"])\n","        unk_scores.append(s)\n","        scratch_idx.append(i)\n","\n","unk_scores = np.array(unk_scores)\n","if len(scratch_idx) == 0:\n","    print(\"⚠️ Scratch unknown이 0개. test_unknown_df['label'] 확인 필요.\")\n","else:\n","    thr = np.percentile(unk_scores, 80)  # 상위 20% = thin/strong-line 가정\n","    thin_idx = [scratch_idx[j] for j in range(len(scratch_idx)) if unk_scores[j] >= thr]\n","    print(\"Scratch:\", len(scratch_idx), \"| thin scratch:\", len(thin_idx), \"| threshold:\", thr)\n","\n","def hit_any_from_refidx(ref_idx, K=5):\n","    return float(any(int(r) in scratch_like_ref_idx for r in ref_idx[:K]))\n","\n","def eval_hit_any(indices, K=5, mode=\"global\", topC=3, lam=0.25, M=500):\n","    hits = []\n","    for i in indices:\n","        if mode == \"global\":\n","            ref_idx = topk_idx[i][:K]\n","        elif mode == \"local_multi\":\n","            _, ref_idx, _ = local_cluster_topk_multi(i, k=K, topC=topC)\n","        elif mode == \"rerank\":\n","            ref_idx, _, _ = rerank_topK(i, M=M, K=K, lam=lam)\n","        else:\n","            raise ValueError(mode)\n","        hits.append(hit_any_from_refidx(ref_idx, K=K))\n","    return float(np.mean(hits)) if len(hits) else 0.0\n","\n","K = 5\n","base_global = eval_hit_any(thin_idx, K=K, mode=\"global\")\n","base_local3  = eval_hit_any(thin_idx, K=K, mode=\"local_multi\", topC=3)\n","\n","lams = [0.1, 0.2, 0.3, 0.4, 0.5]\n","rows = []\n","for lam in lams:\n","    h = eval_hit_any(thin_idx, K=K, mode=\"rerank\", lam=lam, M=500)\n","    rows.append({\"lam\": lam, f\"thin_hit@{K}\": h})\n","\n","df_lam = pd.DataFrame(rows)\n","best = df_lam.iloc[df_lam[f\"thin_hit@{K}\"].argmax()]\n","display(df_lam)\n","\n","print(f\"[thin scratch hit@{K}] global={base_global:.4f} | local_multi(topC=3)={base_local3:.4f}\")\n","print(f\"[best rerank] lam={best['lam']}  thin_hit@{K}={best[f'thin_hit@{K}']:.4f}\")"],"metadata":{"id":"LqgoVjzzZDPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# local_ref_feat(또는 line_score)로 가장 \"선스러운\" ref를 직접 시각화\n","# 지금은 네가 이미 가진 line_score를 ref에 적용해서 quick check\n","\n","ref_scores = []\n","for ref_i in local_ref_emb_idx:\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    ref_scores.append(line_score(wm))\n","ref_scores = np.array(ref_scores)\n","\n","top = np.argsort(-ref_scores)[:32]\n","top_ref = local_ref_emb_idx[top]\n","\n","plt.figure(figsize=(16,4))\n","for j, ref_i in enumerate(top_ref):\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    plt.subplot(2,16,j+1)\n","    plt.imshow(wm); plt.axis(\"off\")\n","plt.suptitle(\"Top 32 local-family refs by line_score\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"7TwZQzRPc711"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-E “연속성 기반 scratchness”로 Top32 다시 뽑아보기"],"metadata":{"id":"Dkzzp-EIppLP"}},{"cell_type":"code","source":["from scipy.ndimage import label\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def scratchness_cc(wm):\n","    a = (np.asarray(wm) > 0).astype(np.uint8)\n","    lab, ncomp = label(a)\n","    if ncomp == 0:\n","        return 0.0\n","\n","    best = 0.0\n","    for c in range(1, ncomp+1):\n","        coords = np.argwhere(lab == c)\n","        if coords.shape[0] < 10:\n","            continue\n","        ys, xs = coords[:,0], coords[:,1]\n","        h = ys.max() - ys.min() + 1\n","        w = xs.max() - xs.min() + 1\n","        ar = max(h, w) / (min(h, w) + 1e-6)     # 길고 얇을수록↑\n","        size = coords.shape[0]\n","        score = np.log1p(size) * ar\n","        best = max(best, score)\n","\n","    return float(best)\n","\n","ref_scores2 = []\n","for ref_i in local_ref_emb_idx:\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    ref_scores2.append(scratchness_cc(wm))\n","ref_scores2 = np.array(ref_scores2)\n","\n","top = np.argsort(-ref_scores2)[:32]\n","top_ref = local_ref_emb_idx[top]\n","\n","plt.figure(figsize=(16,4))\n","for j, ref_i in enumerate(top_ref):\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    plt.subplot(2,16,j+1)\n","    plt.imshow(wm); plt.axis(\"off\")\n","plt.suptitle(\"Top 32 local-family refs by scratchness_cc (connected-component)\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"nz7HXj92p0PP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-F Unknown Scratch들에서 Top32를 같은 점수로 뽑아보기"],"metadata":{"id":"xHGaq-ecuIPw"}},{"cell_type":"code","source":["# Scratch unknown 중에서 top32를 line_score로 뽑아보기\n","scores = []\n","idxs = []\n","for i in range(len(unk_local_idx)):\n","    row = test_unknown_df.iloc[int(unk_local_idx[i])]\n","    if row.get(\"label\") == \"Scratch\":\n","        scores.append(line_score(row[\"waferMap\"]))\n","        idxs.append(i)\n","scores = np.array(scores)\n","\n","top = np.argsort(-scores)[:32]\n","top_unk = [idxs[t] for t in top]\n","\n","plt.figure(figsize=(16,4))\n","for j, ui in enumerate(top_unk):\n","    wm = test_unknown_df.iloc[int(unk_local_idx[ui])][\"waferMap\"]\n","    plt.subplot(2,16,j+1)\n","    plt.imshow(wm); plt.axis(\"off\")\n","plt.suptitle(\"Top 32 Scratch unknowns by line_score\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"4__F5aYEuH9p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-G scratchness_cc에 “끊긴 선” 보정(간단 dilation) 넣고 다시 Top32"],"metadata":{"id":"r55rYcnNuVVb"}},{"cell_type":"code","source":["from scipy.ndimage import binary_dilation, label\n","import numpy as np\n","\n","def scratchness_cc_dilated(wm, it=1):\n","    a = (np.asarray(wm) > 0)\n","    a = binary_dilation(a, iterations=it)  # 끊긴 선 연결 보정\n","    lab, ncomp = label(a.astype(np.uint8))\n","    if ncomp == 0: return 0.0\n","\n","    best = 0.0\n","    for c in range(1, ncomp+1):\n","        coords = np.argwhere(lab == c)\n","        if coords.shape[0] < 10:\n","            continue\n","        ys, xs = coords[:,0], coords[:,1]\n","        h = ys.max()-ys.min()+1\n","        w = xs.max()-xs.min()+1\n","        ar = max(h,w)/(min(h,w)+1e-6)\n","        best = max(best, np.log1p(coords.shape[0]) * ar)\n","    return float(best)\n","\n","ref_scores2 = []\n","for ref_i in local_ref_emb_idx:\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    ref_scores2.append(scratchness_cc(wm))\n","ref_scores2 = np.array(ref_scores2)\n","\n","top = np.argsort(-ref_scores2)[:32]\n","top_ref = local_ref_emb_idx[top]\n","\n","plt.figure(figsize=(16,4))\n","for j, ref_i in enumerate(top_ref):\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    plt.subplot(2,16,j+1)\n","    plt.imshow(wm); plt.axis(\"off\")\n","plt.suptitle(\"Top 32 local-family refs by scratchness_cc (connected-component)\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"gQ-vvyERuVxv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-H Global Top-K에서 Loc 이외 라벨이 얼마나 나오는지 확인"],"metadata":{"id":"58EBfbfVvfJC"}},{"cell_type":"code","source":["from collections import Counter\n","\n","idx_to_class = {v:k for k,v in class_to_idx.items()}\n","\n","scratch_unk = []\n","for i in range(len(unk_local_idx)):\n","    row = test_unknown_df.iloc[int(unk_local_idx[i])]\n","    if row.get(\"label\") == \"Scratch\":\n","        scratch_unk.append(i)\n","\n","# Global Top-1 라벨 분포\n","top1_ref = topk_idx[scratch_unk, 0]\n","top1_lab = [idx_to_class[int(ref_y[r])] for r in top1_ref]\n","print(\"Global Top-1 label dist:\", Counter(top1_lab))\n","\n","# Global Top-5에서 Loc-family 밖이 등장하는 비율\n","local_set = set([\"Loc\", \"Edge-Loc\"])\n","out_cnt = 0\n","tot = 0\n","for i in scratch_unk:\n","    labs = [idx_to_class[int(ref_y[r])] for r in topk_idx[i, :5]]\n","    out_cnt += sum([l not in local_set for l in labs])\n","    tot += 5\n","print(\"Global Top-5 non-local ratio:\", out_cnt / tot)"],"metadata":{"id":"FcGflc8Avi5M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-I Loc과 Scretch가 얼마나 유사성을 보이는지 확인"],"metadata":{"id":"wDXjATiRv-Hn"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from collections import Counter\n","\n","idx_to_class = {v:k for k,v in class_to_idx.items()}\n","\n","def ref_label(ref_i):\n","    return idx_to_class[int(ref_y[ref_i])]\n","\n","# Scratch unknown index 리스트가 이미 있으면 그걸 쓰고,\n","# 없으면 아래처럼 다시 생성\n","try:\n","    scratch_unk\n","except NameError:\n","    scratch_unk = []\n","    for i in range(len(unk_local_idx)):\n","        row = test_unknown_df.iloc[int(unk_local_idx[i])]\n","        if row.get(\"label\") == \"Scratch\":\n","            scratch_unk.append(i)\n","\n","scratch_unk = np.array(scratch_unk, dtype=int)\n","\n","top1_ref = topk_idx[scratch_unk, 0]\n","top1_sim = topk_sim[scratch_unk, 0]\n","top1_lab = np.array([ref_label(r) for r in top1_ref])\n","\n","# 1) Loc로 찍힌 케이스만\n","mask_loc = (top1_lab == \"Loc\")\n","loc_sim = top1_sim[mask_loc]\n","\n","def summarize(x):\n","    return pd.Series({\n","        \"n\": len(x),\n","        \"mean\": float(np.mean(x)) if len(x) else np.nan,\n","        \"std\": float(np.std(x)) if len(x) else np.nan,\n","        \"min\": float(np.min(x)) if len(x) else np.nan,\n","        \"p5\":  float(np.percentile(x, 5)) if len(x) else np.nan,\n","        \"p25\": float(np.percentile(x, 25)) if len(x) else np.nan,\n","        \"p50\": float(np.percentile(x, 50)) if len(x) else np.nan,\n","        \"p75\": float(np.percentile(x, 75)) if len(x) else np.nan,\n","        \"p95\": float(np.percentile(x, 95)) if len(x) else np.nan,\n","        \"max\": float(np.max(x)) if len(x) else np.nan,\n","    })\n","\n","print(\"Top-1 label dist (Scratch unknowns):\", Counter(top1_lab))\n","print(\"\\n[Top1 cosine sim summary]\")\n","print(\"Loc:\\n\", summarize(loc_sim))\n","print(\"\\nNon-Loc:\\n\", summarize(top1_sim[~mask_loc]))\n","\n","# 2) “확신도” 확인: Top1-Top2 마진(값이 작으면 애매)\n","margin12 = topk_sim[scratch_unk, 0] - topk_sim[scratch_unk, 1]\n","print(\"\\n[Top1-Top2 margin summary]\")\n","print(\"Loc:\\n\", summarize(margin12[mask_loc]))\n","print(\"\\nNon-Loc:\\n\", summarize(margin12[~mask_loc]))\n","\n","# 3) Loc로 찍힌 것 중에서, sim 낮은/마진 낮은 애들(=애매 케이스) 인덱스 뽑기\n","k_show = 10\n","worst_sim_idx = scratch_unk[mask_loc][np.argsort(loc_sim)[:k_show]]\n","worst_margin_idx = scratch_unk[mask_loc][np.argsort(margin12[mask_loc])[:k_show]]\n","\n","print(\"\\nWorst sim (Loc top1) unk indices:\", worst_sim_idx.tolist())\n","print(\"Worst margin (Loc top1) unk indices:\", worst_margin_idx.tolist())"],"metadata":{"id":"3UDpDE2WwH7_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-J “진짜로 임베딩이 다 비슷해진 상태인지” 바로 확인하는 2가지 체크"],"metadata":{"id":"DHt155cjw01F"}},{"cell_type":"code","source":["# 체크 A) ref-ref 랜덤 cosine 분포 보기 (제일 중요)\n","\n","import numpy as np\n","import pandas as pd\n","\n","def summarize(x):\n","    return pd.Series({\n","        \"n\": len(x),\n","        \"mean\": float(np.mean(x)),\n","        \"std\": float(np.std(x)),\n","        \"min\": float(np.min(x)),\n","        \"p5\":  float(np.percentile(x, 5)),\n","        \"p50\": float(np.percentile(x, 50)),\n","        \"p95\": float(np.percentile(x, 95)),\n","        \"max\": float(np.max(x)),\n","    })\n","\n","# ref_n: (N_ref, D) L2-normalized 라고 가정\n","N = ref_n.shape[0]\n","m = 20000\n","i = np.random.randint(0, N, size=m)\n","j = np.random.randint(0, N, size=m)\n","mask = (i != j)\n","i, j = i[mask], j[mask]\n","\n","rr = np.sum(ref_n[i] * ref_n[j], axis=1)  # cosine\n","print(\"[random ref-ref cosine summary]\")\n","print(summarize(rr))"],"metadata":{"id":"p7A8qxHRw4Dl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ref-ref cosine 분포는 “완전 붕괴(cone collapse)”는 아님\n","\n","median(p50) ≈ 0.52, mean ≈ 0.58 → 전체적으로는 다양해.\n","\n","근데 p95가 0.9747, max가 0.9999 → 아주 비슷한 것들끼리는 정말 0.98~1.0 근처로 몰리긴 함."],"metadata":{"id":"h1q94G_Lw9Qo"}},{"cell_type":"code","source":["# “허브(hub)”가 있는지 보기\n","\n","from collections import Counter\n","c = Counter(topk_idx[scratch_unk, 0].tolist())\n","print(\"Top-1 ref hub top10:\", c.most_common(10))"],"metadata":{"id":"vqkZs3y8xBpu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["hub는 존재하지만 “심각한 수준”은 아직 아님\n","\n","Top-1 ref hub top10에서 최다도 20회/1193개 ≈ 1.7% 수준이라,\n","\n","완전 허브 지옥(특정 ref가 수십~수백 회)까지는 아님.\n","\n","다만 “일부 ref로 빨리는 경향”은 있으니 검색 안정화를 위해 보정은 가치 있음."],"metadata":{"id":"VSQWKF9ix5hl"}},{"cell_type":"markdown","source":["#### 10.8-K “유사 사례 없음”을 코드로 판별하도록 설정"],"metadata":{"id":"ZfwgM5iVyESW"}},{"cell_type":"code","source":["# Loc-family ref들의 line_score 계산\n","local_ref_line = []\n","for ref_i in local_ref_emb_idx:\n","    rloc = int(ref_local_idx[ref_i])\n","    wm = ref_df.iloc[rloc][\"waferMap\"]\n","    local_ref_line.append(line_score(wm))\n","local_ref_line = np.array(local_ref_line)\n","\n","# \"선형 ref\" 기준: 상위 1%~5% 등 (너가 조절)\n","LINE_REF_THR = np.percentile(local_ref_line, 99)  # 예: 상위 1%\n","is_line_ref = (local_ref_line >= LINE_REF_THR)\n","\n","print(\"LINE_REF_THR:\", LINE_REF_THR, \"line-like refs:\", int(is_line_ref.sum()), \"/\", len(is_line_ref))"],"metadata":{"id":"_UVa9dUfyOb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["THIN_Q_THR = np.percentile([line_score(test_unknown_df.iloc[int(unk_local_idx[i])][\"waferMap\"])\n","                            for i in scratch_unk], 80)  # 기존 thin 정의처럼 80퍼 이상\n","\n","def has_line_like_match_in_local_topk(unk_i, K=50):\n","    # local-family 내에서 embedding topK\n","    sims = local_ref_n @ unk_n[unk_i]\n","    top = np.argsort(-sims)[:K]\n","    # topK 안에 선형 ref가 하나라도 있나?\n","    return bool(np.any(is_line_ref[top]))\n","\n","no_match = []\n","for ui in scratch_unk:\n","    wm = test_unknown_df.iloc[int(unk_local_idx[ui])][\"waferMap\"]\n","    q_line = line_score(wm)\n","    if q_line >= THIN_Q_THR:  # thin scratch query만\n","        if not has_line_like_match_in_local_topk(ui, K=50):\n","            no_match.append(ui)\n","\n","print(f\"thin scratch queries: {sum([line_score(test_unknown_df.iloc[int(unk_local_idx[ui])]['waferMap']) >= THIN_Q_THR for ui in scratch_unk])}\")\n","print(f\"NO MATCH (no line-like ref in local top50): {len(no_match)}\")\n","print(\"example indices:\", no_match[:10])"],"metadata":{"id":"AKhoEMhkyQIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-L NO MATCH 샘플 모아서 저장/시각화 코드"],"metadata":{"id":"kiH3TzI_yzg4"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# -----------------------------\n","# 0) 안전장치: 매핑 함수(없으면 여기서 정의)\n","# -----------------------------\n","def _unk_row_by_embidx(unk_i):\n","    return test_unknown_df.iloc[int(unk_local_idx[int(unk_i)])]\n","\n","def _ref_row_by_embidx(ref_i):\n","    return ref_df.iloc[int(ref_local_idx[int(ref_i)])]\n","\n","# -----------------------------\n","# 1) 폴더 준비\n","# -----------------------------\n","OUT_IMG_DIR = \"assets/no_match_thin_scratch\"\n","OUT_REPORT_DIR = \"reports\"\n","os.makedirs(OUT_IMG_DIR, exist_ok=True)\n","os.makedirs(OUT_REPORT_DIR, exist_ok=True)\n","\n","# -----------------------------\n","# 2) (필요시) local_ref_line / is_line_ref가 없다면 계산\n","#    - 너는 이미 계산했으니 보통은 skip될 거야\n","# -----------------------------\n","if \"local_ref_line\" not in globals():\n","    local_ref_line = []\n","    for ref_i in local_ref_emb_idx:\n","        wm = _ref_row_by_embidx(ref_i)[\"waferMap\"]\n","        local_ref_line.append(line_score(wm))\n","    local_ref_line = np.array(local_ref_line)\n","\n","if \"is_line_ref\" not in globals():\n","    LINE_REF_THR = np.percentile(local_ref_line, 99)  # 기본: 상위 1%\n","    is_line_ref = (local_ref_line >= LINE_REF_THR)\n","\n","# line-like ref의 local-pos 목록 (local_ref_n 기준 인덱스)\n","line_pos = np.where(is_line_ref)[0]\n","assert len(line_pos) > 0, \"line-like ref가 0개야. LINE_REF_THR 또는 line_score 정의를 확인해줘.\"\n","\n","# -----------------------------\n","# 3) 핵심: NO MATCH 샘플별 요약 + 이미지 저장\n","# -----------------------------\n","def save_no_match_case(unk_i, K=5):\n","    \"\"\"\n","    NO MATCH 샘플 하나에 대해\n","    - Row1: Local top-K (대부분 비선형)\n","    - Row2: line-like ref(43개) 중에서 가장 가까운 top-K\n","    그리고 best line-like rank(전체 local 중 몇 등인지)도 기록\n","    \"\"\"\n","    unk_row = _unk_row_by_embidx(unk_i)\n","    uwm = unk_row[\"waferMap\"]\n","    q_line = float(line_score(uwm))\n","\n","    # local sims (M_local=3000 정도라 full sort 부담 없음)\n","    sims = local_ref_n @ unk_n[int(unk_i)]\n","    order = np.argsort(-sims)  # local-pos 기준 내림차순\n","\n","    # local topK\n","    top_pos = order[:K]\n","    top_ref = local_ref_emb_idx[top_pos]      # ref_emb 인덱스\n","    top_sim = sims[top_pos]\n","    top_ls  = local_ref_line[top_pos]\n","\n","    # line-like topK (line_pos에서만)\n","    line_sims = sims[line_pos]\n","    line_order = np.argsort(-line_sims)[:K]\n","    best_line_pos = line_pos[line_order]\n","    best_line_ref = local_ref_emb_idx[best_line_pos]\n","    best_line_sim = sims[best_line_pos]\n","    best_line_ls  = local_ref_line[best_line_pos]\n","\n","    # best line-like rank in full local list\n","    # (NO MATCH는 top50에 없으므로 보통 51등 이상)\n","    rank_line = None\n","    for r, p in enumerate(order):\n","        if is_line_ref[p]:\n","            rank_line = r + 1\n","            break\n","\n","    # ---- Plot (2 rows x (K+1) cols) ----\n","    plt.figure(figsize=(3*(K+1), 6))\n","\n","    # Row 1: Local Top-K\n","    plt.subplot(2, K+1, 1)\n","    plt.imshow(uwm); plt.axis(\"off\")\n","    plt.title(f\"UNK {int(unk_i)}\\nq_line={q_line:.2f}\")\n","\n","    for j in range(K):\n","        rrow = _ref_row_by_embidx(int(top_ref[j]))\n","        plt.subplot(2, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"Local#{j+1}\\ncos={top_sim[j]:.3f}\\nls={top_ls[j]:.2f}\", fontsize=9)\n","\n","    # Row 2: Best line-like refs\n","    plt.subplot(2, K+1, (K+1)+1)\n","    plt.imshow(uwm); plt.axis(\"off\")\n","    plt.title(f\"Line-like refs\\n(best rank={rank_line})\", fontsize=10)\n","\n","    for j in range(K):\n","        rrow = _ref_row_by_embidx(int(best_line_ref[j]))\n","        plt.subplot(2, K+1, (K+1)+j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"Line#{j+1}\\ncos={best_line_sim[j]:.3f}\\nls={best_line_ls[j]:.2f}\", fontsize=9)\n","\n","    plt.suptitle(\"NO MATCH case: no line-like ref in Local Top-50\", y=1.02, fontsize=12)\n","    plt.tight_layout()\n","\n","    img_path = os.path.join(OUT_IMG_DIR, f\"unk{int(unk_i):04d}_nomatch.png\")\n","    plt.savefig(img_path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","\n","    # summary row\n","    return {\n","        \"unk_i\": int(unk_i),\n","        \"true_label\": str(unk_row.get(\"label\", \"unknown\")),\n","        \"q_line_score\": q_line,\n","        \"best_local_sim\": float(top_sim[0]),\n","        \"best_line_like_sim\": float(best_line_sim[0]),\n","        \"best_line_like_rank_in_local\": int(rank_line) if rank_line is not None else None,\n","        \"line_like_ref_count\": int(len(line_pos)),\n","        \"note\": \"NO_MATCH_LOCAL_TOP50\",\n","        \"img_path\": img_path,\n","    }\n","\n","# 정렬: q_line_score 높은 순으로(더 '얇은 선' 느낌이 강한 것부터)\n","no_match_sorted = sorted([int(x) for x in no_match], key=lambda i: line_score(_unk_row_by_embidx(i)[\"waferMap\"]), reverse=True)\n","\n","rows = []\n","for i in no_match_sorted:\n","    rows.append(save_no_match_case(i, K=5))\n","\n","df_nm = pd.DataFrame(rows)\n","\n","# 저장물\n","csv_path = os.path.join(OUT_REPORT_DIR, \"no_match_thin_scratch.csv\")\n","txt_path = os.path.join(OUT_REPORT_DIR, \"no_match_thin_scratch_indices.txt\")\n","df_nm.to_csv(csv_path, index=False)\n","\n","with open(txt_path, \"w\") as f:\n","    for i in no_match_sorted:\n","        f.write(f\"{i}\\n\")\n","\n","print(\"Saved:\")\n","print(\" -\", csv_path)\n","print(\" -\", txt_path)\n","print(\" - images in\", OUT_IMG_DIR)\n","display(df_nm.head(10))"],"metadata":{"id":"KGiTJf4JyzCK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.8-M MATCH / NO MATCH 둘 다 분리 + 리포트 + 이미지 저장"],"metadata":{"id":"ExMeDKcJ0sZw"}},{"cell_type":"code","source":["import os, numpy as np, pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# -----------------------------\n","# 0) 헬퍼: dataframe row 가져오기\n","# -----------------------------\n","def _unk_row(unk_i):\n","    return test_unknown_df.iloc[int(unk_local_idx[int(unk_i)])]\n","\n","def _ref_row(ref_i):\n","    return ref_df.iloc[int(ref_local_idx[int(ref_i)])]\n","\n","# -----------------------------\n","# 1) 폴더\n","# -----------------------------\n","OUT_BASE = \"assets/thin_scratch_match_nomatch\"\n","DIR_MATCH = os.path.join(OUT_BASE, \"match\")\n","DIR_NOMATCH = os.path.join(OUT_BASE, \"nomatch\")\n","os.makedirs(DIR_MATCH, exist_ok=True)\n","os.makedirs(DIR_NOMATCH, exist_ok=True)\n","os.makedirs(\"reports\", exist_ok=True)\n","\n","# -----------------------------\n","# 2) line-like ref pool / line_pos 준비 (이미 있으면 그대로)\n","# -----------------------------\n","line_pos = np.where(is_line_ref)[0]\n","assert len(line_pos) > 0, \"line-like ref가 0개야. LINE_REF_THR 또는 line_score 정의를 확인해줘.\"\n","\n","# -----------------------------\n","# 3) thin scratch queries에서 MATCH / NO MATCH 다시 계산\n","#    - 조건: Local Top-50 안에 line-like ref가 1개라도 있으면 MATCH\n","# -----------------------------\n","def local_line_like_stats(unk_i, topN=50):\n","    sims = local_ref_n @ unk_n[int(unk_i)]\n","    order = np.argsort(-sims)\n","    top_pos = order[:topN]\n","    hit_pos = top_pos[is_line_ref[top_pos]]  # local-pos 중 line-like인 것들\n","    return sims, order, top_pos, hit_pos\n","\n","thin_unk = []\n","for ui in scratch_unk:\n","    wm = _unk_row(ui)[\"waferMap\"]\n","    if float(line_score(wm)) >= THIN_Q_THR:\n","        thin_unk.append(int(ui))\n","thin_unk = np.array(thin_unk, dtype=int)\n","\n","match = []\n","nomatch = []\n","\n","for ui in thin_unk:\n","    _, _, _, hit_pos = local_line_like_stats(ui, topN=50)\n","    if len(hit_pos) > 0:\n","        match.append(int(ui))\n","    else:\n","        nomatch.append(int(ui))\n","\n","print(\"thin scratch queries:\", len(thin_unk))\n","print(\"MATCH (has line-like in local top50):\", len(match))\n","print(\"NO MATCH:\", len(nomatch))\n","print(\"match example:\", match[:10])\n","print(\"nomatch example:\", nomatch[:10])\n","\n","# -----------------------------\n","# 4) 케이스 저장 함수 (MATCH/NO MATCH 공용)\n","#    - Row1: Local Top-5 (line-like면 ★ 표시)\n","#    - Row2: line-like pool(43개) Top-5 + best line-like rank\n","# -----------------------------\n","def save_case(unk_i, out_dir, K=5):\n","    unk_row = _unk_row(unk_i)\n","    uwm = unk_row[\"waferMap\"]\n","    q_line = float(line_score(uwm))\n","\n","    sims, order, _, hit_pos50 = local_line_like_stats(unk_i, topN=50)\n","\n","    # Local top-K\n","    top_pos = order[:K]\n","    top_ref = local_ref_emb_idx[top_pos]\n","    top_sim = sims[top_pos]\n","    top_ls  = local_ref_line[top_pos]\n","    top_is_line = is_line_ref[top_pos]\n","\n","    # line-like pool top-K (line_pos 내부에서만)\n","    line_sims = sims[line_pos]\n","    line_order = np.argsort(-line_sims)[:K]\n","    best_line_pos = line_pos[line_order]\n","    best_line_ref = local_ref_emb_idx[best_line_pos]\n","    best_line_sim = sims[best_line_pos]\n","    best_line_ls  = local_ref_line[best_line_pos]\n","\n","    # best line-like rank in full local list\n","    best_rank = None\n","    for r, p in enumerate(order):\n","        if is_line_ref[p]:\n","            best_rank = r + 1\n","            break\n","\n","    # local top50에서 line-like 몇 개 들어왔나 / 가장 높은 sim의 line-like는 몇 등인가\n","    hit_cnt50 = int(len(hit_pos50))\n","    best_hit_rank50 = None\n","    if hit_cnt50 > 0:\n","        # order에서 hit_pos50 중 가장 앞에 있는 것의 rank (1-index)\n","        ranks = [int(np.where(order == p)[0][0]) + 1 for p in hit_pos50]\n","        best_hit_rank50 = int(min(ranks))\n","\n","    # Plot\n","    plt.figure(figsize=(3*(K+1), 6))\n","\n","    # Row 1\n","    plt.subplot(2, K+1, 1)\n","    plt.imshow(uwm); plt.axis(\"off\")\n","    plt.title(f\"UNK {int(unk_i)}\\nq_line={q_line:.2f}\")\n","\n","    for j in range(K):\n","        rrow = _ref_row(int(top_ref[j]))\n","        plt.subplot(2, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        star = \"★\" if top_is_line[j] else \"\"\n","        plt.title(f\"Local#{j+1}{star}\\ncos={top_sim[j]:.3f}\\nls={top_ls[j]:.2f}\", fontsize=9)\n","\n","    # Row 2\n","    plt.subplot(2, K+1, (K+1)+1)\n","    plt.imshow(uwm); plt.axis(\"off\")\n","    plt.title(f\"Line-like pool\\n(best rank={best_rank})\\n(hit@50={hit_cnt50}, best_hit_rank50={best_hit_rank50})\", fontsize=9)\n","\n","    for j in range(K):\n","        rrow = _ref_row(int(best_line_ref[j]))\n","        plt.subplot(2, K+1, (K+1)+j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"Line#{j+1}\\ncos={best_line_sim[j]:.3f}\\nls={best_line_ls[j]:.2f}\", fontsize=9)\n","\n","    plt.suptitle(\"MATCH/NO MATCH diagnostic (Local Top-K vs Line-like pool)\", y=1.02, fontsize=12)\n","    plt.tight_layout()\n","\n","    img_path = os.path.join(out_dir, f\"unk{int(unk_i):04d}.png\")\n","    plt.savefig(img_path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","\n","    return {\n","        \"unk_i\": int(unk_i),\n","        \"true_label\": str(unk_row.get(\"label\", \"unknown\")),\n","        \"q_line_score\": q_line,\n","        \"best_local_sim\": float(top_sim[0]),\n","        \"best_line_like_sim\": float(best_line_sim[0]),\n","        \"best_line_like_rank_in_local\": int(best_rank) if best_rank is not None else None,\n","        \"line_like_count_in_local_top50\": hit_cnt50,\n","        \"best_line_like_rank_in_top50\": best_hit_rank50,\n","        \"status\": \"MATCH\" if hit_cnt50 > 0 else \"NO_MATCH\",\n","        \"img_path\": img_path,\n","    }\n","\n","# -----------------------------\n","# 5) 전부 저장 (너무 많으면 MAX_CASES로 제한 가능)\n","# -----------------------------\n","MAX_CASES_MATCH = None   # 예: 50으로 두면 match 중 상위 50개만 저장\n","MAX_CASES_NOMATCH = None # 예: 72개 전부 저장하려면 None\n","\n","# q_line 높은 순으로 정렬(“더 thin한 것부터”)\n","match_sorted = sorted(match, key=lambda i: float(line_score(_unk_row(i)[\"waferMap\"])), reverse=True)\n","nomatch_sorted = sorted(nomatch, key=lambda i: float(line_score(_unk_row(i)[\"waferMap\"])), reverse=True)\n","\n","if MAX_CASES_MATCH is not None:\n","    match_sorted = match_sorted[:MAX_CASES_MATCH]\n","if MAX_CASES_NOMATCH is not None:\n","    nomatch_sorted = nomatch_sorted[:MAX_CASES_NOMATCH]\n","\n","rows = []\n","for ui in match_sorted:\n","    rows.append(save_case(ui, DIR_MATCH, K=5))\n","for ui in nomatch_sorted:\n","    rows.append(save_case(ui, DIR_NOMATCH, K=5))\n","\n","df_cases = pd.DataFrame(rows)\n","\n","csv_path = \"reports/thin_scratch_match_nomatch_cases.csv\"\n","df_cases.to_csv(csv_path, index=False)\n","\n","print(\"Saved CSV:\", csv_path)\n","print(\"Saved images:\", OUT_BASE)\n","display(df_cases.groupby(\"status\")[[\"unk_i\"]].count().rename(columns={\"unk_i\":\"n_cases\"}))\n","display(df_cases.head(10))\n"],"metadata":{"id":"WHifP3GV0wEh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YlMhv_dPxAEF"},"source":["### 10.9 트리아지 요약 한 줄 (발표용)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30ZX_CKQwCId"},"outputs":[],"source":["from collections import Counter\n","\n","def _unk_row_by_embidx(unk_i):\n","    # unk_i(임베딩 인덱스) -> test_unknown_df 위치\n","    return test_unknown_df.iloc[int(unk_local_idx[unk_i])]\n","\n","def _ref_row_by_embidx(ref_i):\n","    # ref_i(임베딩 인덱스) -> ref_df 위치\n","    return ref_df.iloc[int(ref_local_idx[ref_i])]\n","\n","def triage_summary_from_refidx(ref_indices, K=5):\n","    labels = [_ref_row_by_embidx(j)[\"label\"] for j in ref_indices[:K]]\n","    cnt = Counter(labels)\n","    top_label, top_count = cnt.most_common(1)[0]\n","    purity = top_count / K\n","    uniq = len(cnt)\n","\n","    if purity >= 0.8:\n","        msg = f\"Top-{K} 중 {top_label} {top_count}/{K} → '{top_label}' 계열 가능성 높음\"\n","    elif uniq >= 4:\n","        msg = f\"Top-{K} 라벨 다양({dict(cnt)}) → 애매 케이스(추가 확인/재측정 권장)\"\n","    else:\n","        msg = f\"Top-{K} 혼재({dict(cnt)}) → 유사 패턴 후보 복수\"\n","    return labels, msg\n","\n","def triage_summary(unk_i, K=5):\n","    # 글로벌 Top-K 요약\n","    return triage_summary_from_refidx(topk_idx[unk_i], K)"]},{"cell_type":"markdown","metadata":{"id":"U5Si9noixFRq"},"source":["### 10.10 데모 화면 출력 (Unknown + Top-K)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xH8AG1o9xDHn"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def show_triage_case_3way(unk_i, K=5, topC=3, lam=0.25, M=500):\n","    unk_row = _unk_row_by_embidx(unk_i)\n","    unk_wm = unk_row[\"waferMap\"]\n","    true_label = unk_row[\"label\"] if \"label\" in unk_row else \"unknown\"\n","\n","    # (1) Global\n","    g_ref_idx = topk_idx[unk_i][:K]\n","    g_ref_sim = topk_sim[unk_i][:K]\n","    _, g_msg = triage_summary_from_refidx(g_ref_idx, K)\n","\n","    # (2) Local multi-cluster pooling\n","    top_cs, lm_ref_idx, lm_ref_sim = local_cluster_topk_multi(unk_i, k=K, topC=topC)\n","    _, lm_msg = triage_summary_from_refidx(lm_ref_idx, K)\n","\n","    # (3) Rerank (local-family Top-M -> line rerank)\n","    rr_ref_idx, rr_emb_sim, rr_feat_sim = rerank_topK(unk_i, M=M, K=K, lam=lam)\n","    _, rr_msg = triage_summary_from_refidx(rr_ref_idx, K)\n","\n","    rows = 3\n","    plt.figure(figsize=(3*(K+1), 3*rows))\n","\n","    # ----- Row 1: Global -----\n","    plt.subplot(rows, K+1, 1)\n","    plt.imshow(unk_wm); plt.axis(\"off\")\n","    plt.title(f\"UNKNOWN\\n(true={true_label})\")\n","\n","    for j in range(K):\n","        rrow = _ref_row_by_embidx(g_ref_idx[j])\n","        plt.subplot(rows, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"{rrow['label']}\\ncos={g_ref_sim[j]:.3f}\")\n","\n","    # ----- Row 2: Local multi -----\n","    plt.subplot(rows, K+1, (K+1)+1)\n","    plt.imshow(unk_wm); plt.axis(\"off\")\n","    plt.title(f\"UNKNOWN\\n(Local topC={topC})\")\n","\n","    for j in range(K):\n","        rrow = _ref_row_by_embidx(lm_ref_idx[j])\n","        plt.subplot(rows, K+1, (K+1)+j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"{rrow['label']}\\ncos={lm_ref_sim[j]:.3f}\")\n","\n","    # ----- Row 3: Rerank -----\n","    plt.subplot(rows, K+1, 2*(K+1)+1)\n","    plt.imshow(unk_wm); plt.axis(\"off\")\n","    plt.title(f\"UNKNOWN\\n(Rerank λ={lam})\")\n","\n","    for j in range(K):\n","        rrow = _ref_row_by_embidx(rr_ref_idx[j])\n","        plt.subplot(rows, K+1, 2*(K+1)+j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"{rrow['label']}\\nemb={rr_emb_sim[j]:.3f}\\nline={rr_feat_sim[j]:.2f}\")\n","\n","    plt.suptitle(\n","        f\"[GLOBAL] {g_msg}\\n\"\n","        f\"[LOCAL_MULTI cs={top_cs}] {lm_msg}\\n\"\n","        f\"[RERANK λ={lam}, M={M}] {rr_msg}\",\n","        y=1.03, fontsize=12\n","    )\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시 실행 (원하는 unk index로 바꿔서 보기)\n","for i in [0, 1, 2]:\n","    show_triage_case_3way(i, K=5, topC=3, lam=0.25, M=500)"]},{"cell_type":"markdown","metadata":{"id":"AJN79lGpxORR"},"source":["### 10.11 데모 결과 저장 (이미지/요약)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_u-292hxH8H"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","\n","OUT_DIR = \"assets/triage\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def save_triage_case(unk_i, K=5, show_local=True):\n","    unk_row = _unk_row_by_embidx(unk_i)\n","    true_label = unk_row[\"label\"] if \"label\" in unk_row else \"unknown\"\n","\n","    # global\n","    g_ref_idx = topk_idx[unk_i][:K]\n","    g_ref_sim = topk_sim[unk_i][:K]\n","    _, g_msg = triage_summary_from_refidx(g_ref_idx, K)\n","\n","    # local\n","    if show_local:\n","        c_id, l_ref_idx, l_ref_sim = local_cluster_topk(unk_i, k=K)\n","        _, l_msg = triage_summary_from_refidx(l_ref_idx, K)\n","    else:\n","        c_id, l_ref_idx, l_ref_sim, l_msg = None, None, None, \"\"\n","\n","    rows = 2 if show_local else 1\n","    plt.figure(figsize=(3*(K+1), 3*rows))\n","\n","    # row 1\n","    plt.subplot(rows, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"]); plt.axis(\"off\")\n","    plt.title(f\"UNKNOWN\\n(true={true_label})\")\n","    for j in range(K):\n","        rrow = _ref_row_by_embidx(g_ref_idx[j])\n","        plt.subplot(rows, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"{rrow['label']}\\ncos={g_ref_sim[j]:.3f}\")\n","\n","    # row 2\n","    if show_local:\n","        plt.subplot(rows, K+1, (K+1)+1)\n","        plt.imshow(unk_row[\"waferMap\"]); plt.axis(\"off\")\n","        plt.title(f\"UNKNOWN\\n(Local c={c_id})\")\n","        for j in range(K):\n","            rrow = _ref_row_by_embidx(l_ref_idx[j])\n","            plt.subplot(rows, K+1, (K+1)+j+2)\n","            plt.imshow(rrow[\"waferMap\"]); plt.axis(\"off\")\n","            plt.title(f\"{rrow['label']}\\ncos={l_ref_sim[j]:.3f}\")\n","\n","    plt.suptitle(f\"[GLOBAL] {g_msg}\" + (f\"\\n[LOCAL c={c_id}] {l_msg}\" if show_local else \"\"), y=1.03, fontsize=12)\n","    plt.tight_layout()\n","\n","    fname = f\"triage_unk{unk_i:04d}_true-{true_label}\"\n","    if show_local:\n","        fname += f\"_c{c_id:02d}\"\n","    fname += \".png\"\n","\n","    path = os.path.join(OUT_DIR, fname)\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path, g_msg\n","\n","# 6개만 저장\n","picked = [0, 1, 2, 3, 4, 5]\n","for i in picked:\n","    p, m = save_triage_case(i, K=5, show_local=True)\n","    print(p, \"|\", m)\n"]},{"cell_type":"markdown","metadata":{"id":"_TslrDbfyisd"},"source":["### 10.12 (선택) OOD 점수로 데모 후보 자동 선별\n","\n","이미 unknown에 대한 MSP/Energy 배열을 갖고 있으면 이 셀은 건너뛰어도 됨."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g62OkjfeyEGE"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","# 전제: model(or loaded_model), device, test_unknown_df, WaferMapDataset(혹은 너가 쓰는 Dataset)이 존재\n","model_use = loaded_model if \"loaded_model\" in globals() else model_use if \"model_use\" in globals() else model\n","model_use = model_use.to(device).eval()\n","\n","INPUT_MODE = \"coords4\" if model_use.conv1.in_channels == 4 else \"repeat3\"\n","print(\"model in_ch:\", model_use.conv1.in_channels, \"=> INPUT_MODE:\", INPUT_MODE)\n","\n","# unknown loader (순서 보존 위해 shuffle=False)\n","unk_score_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64, input_mode=INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","@torch.no_grad()\n","def compute_msp_energy(model, loader):\n","    msps = []\n","    energy_raw = []  # Energy = -logsumexp(logits). OOD일수록 값이 덜 음수(=더 큼)로 가는 경향\n","    for batch in loader:\n","        # loader가 x만 주는 경우 / (x,idx) 주는 경우를 모두 처리\n","        x = batch[0] if isinstance(batch, (list, tuple)) else batch\n","        x = x.to(device)\n","        logits = model(x)\n","\n","        prob = F.softmax(logits, dim=1)\n","        msp = prob.max(dim=1).values\n","\n","        e = -torch.logsumexp(logits, dim=1)  # energy_raw\n","        msps.append(msp.cpu().numpy())\n","        energy_raw.append(e.cpu().numpy())\n","\n","    msps = np.concatenate(msps)\n","    energy_raw = np.concatenate(energy_raw)\n","    return msps, energy_raw\n","\n","msp_u, energy_u = compute_msp_energy(model_use, unk_score_loader)\n","print(\"scores:\", msp_u.shape, energy_u.shape, \"len(df)=\", len(test_unknown_df))"]},{"cell_type":"markdown","metadata":{"id":"g18vtuw_yU3o"},"source":["### 10.13 데모 후보 자동 선택 기준\n","\n","*   (A) unknown스러운 샘플: MSP 낮고, Energy_raw는 큰(덜 음수) 샘플\n","*   (B) 위험 샘플(과신): MSP 높은데도 실제론 unknown인 샘플 (과신 오분류 위험 강조용)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyPv3fdjxQl0"},"outputs":[],"source":["N_DEMO = 8  # 저장할 케이스 개수\n","\n","# A) unknown-likely: MSP 낮은 순 + Energy_raw 큰 순을 rank로 합침\n","rank_msp = np.argsort(msp_u)                 # 낮을수록 unknown\n","rank_e   = np.argsort(-energy_u)             # 클수록 unknown (덜 음수)\n","rank_sum = np.empty_like(rank_msp)\n","rank_sum[rank_msp] = np.arange(len(rank_msp))\n","rank_sum += np.arange(len(rank_e))[np.argsort(rank_e)]  # 간단 합산\n","\n","demo_unknownlike = np.argsort(rank_sum)[:N_DEMO]\n","\n","# B) overconfident unknown: MSP 높은 순\n","demo_overconf = np.argsort(-msp_u)[:min(N_DEMO, 5)]\n","\n","print(\"demo_unknownlike:\", demo_unknownlike)\n","print(\"demo_overconf:\", demo_overconf)"]},{"cell_type":"markdown","metadata":{"id":"hcSKfSHdyRS_"},"source":["### 10.14 트리아지 결과 저장 (그림 + CSV 요약)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FFJXSmvyCJk"},"outputs":[],"source":["import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","OUT_DIR = \"assets/triage\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def triage_summary(unk_i, K=5):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[unk_i][:K]]\n","    cnt = Counter(labels)\n","    top_label, top_count = cnt.most_common(1)[0]\n","    purity = top_count / K\n","    uniq = len(cnt)\n","\n","    if purity >= 0.8:\n","        msg = f\"Top-{K}: {top_label} {top_count}/{K} → '{top_label}' 계열 가능성 높음\"\n","    elif uniq >= 4:\n","        msg = f\"Top-{K} 라벨 다양({dict(cnt)}) → 애매 케이스(추가 확인/재측정 권장)\"\n","    else:\n","        msg = f\"Top-{K} 혼재({dict(cnt)}) → 후보 복수\"\n","    return labels, purity, msg\n","\n","def save_triage_case(unk_i, K=5, extra_note=\"\"):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    labels, purity, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    title = msg + (f\" | {extra_note}\" if extra_note else \"\")\n","    plt.suptitle(title, y=1.05, fontsize=11)\n","    plt.tight_layout()\n","\n","    fname = f\"triage_unk{unk_i:04d}_true-{unk_row['label']}.png\"\n","    path = os.path.join(OUT_DIR, fname)\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","\n","    return {\n","        \"unk_i\": int(unk_i),\n","        \"true_label\": unk_row[\"label\"],\n","        \"topk_labels\": \"|\".join(labels),\n","        \"purity\": float(purity),\n","        \"note\": title,\n","        \"img_path\": path\n","    }\n","\n","def save_demo_set(indices, tag, K=5):\n","    rows = []\n","    for i in indices:\n","        extra = f\"{tag}\"\n","        rows.append(save_triage_case(int(i), K=K, extra_note=extra))\n","    return rows\n","\n","# demo_unknownlike / demo_overconf가 없으면(위 셀 스킵했으면) 직접 indices를 넣어도 됨\n","K = 5\n","rows_all = []\n","if \"demo_unknownlike\" in globals():\n","    rows_all += save_demo_set(demo_unknownlike, \"OOD-unknownlike\", K=K)\n","if \"demo_overconf\" in globals():\n","    rows_all += save_demo_set(demo_overconf, \"OOD-overconfident\", K=K)\n","\n","df_sum = pd.DataFrame(rows_all)\n","\n","# OOD 점수도 같이 저장(있으면)\n","if \"msp_u\" in globals():\n","    df_sum[\"msp\"] = df_sum[\"unk_i\"].apply(lambda i: float(msp_u[i]))\n","if \"energy_u\" in globals():\n","    df_sum[\"energy_raw\"] = df_sum[\"unk_i\"].apply(lambda i: float(energy_u[i]))\n","\n","csv_path = os.path.join(OUT_DIR, \"triage_summary.csv\")\n","df_sum.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","\n","print(\"✅ saved images to:\", OUT_DIR)\n","print(\"✅ saved summary csv:\", csv_path)\n","df_sum.head()"]},{"cell_type":"markdown","metadata":{"id":"ibqI3wqYa-Rc"},"source":["### 10.15 Unknown → Unknown 유사사례 Top-K (Nearest Neighbors)\n","\n","지금까지는 **Unknown → Known(레퍼런스) Top-K**로,\n","Unknown이 “기존에 알려진 결함 중 무엇과 비슷한지”를 보여주는 트리아지였습니다.\n","\n","다음 단계에서는 **Unknown끼리(Unknown → Unknown) 유사사례 Top-K**를 추가합니다.\n","\n","- 목적: unknown이 “1회성”인지, “비슷한 패턴이 반복(재발)되는지” 빠르게 확인\n","- 입력: `unk_emb`, `test_unknown_df`\n","- 출력: query unknown 1장 + 가장 유사한 unknown K장(코사인 유사도)\n","\n","> 시연/작품 톤을 살리려면 `true label` 표시는 숨기고(옵션), 모양 기반으로만 판단하게 구성합니다."]},{"cell_type":"markdown","metadata":{"id":"DHdKbQL5bS-l"},"source":["#### 10.15.1 unknown → unknown “가장 비슷한 샘플 Top-K” (Nearest Neighbors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O4FKWKWybGqN"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import NearestNeighbors\n","import os\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","unk_n = l2norm(unk_emb).astype(np.float32)\n","\n","# cosine distance 기반 최근접 이웃\n","K_NN = 6  # 자기 자신 포함해서 6개 -> 나중에 self 제외하면 5개\n","knn = NearestNeighbors(n_neighbors=K_NN, metric=\"cosine\")\n","knn.fit(unk_n)\n","\n","dist, idx = knn.kneighbors(unk_n)  # dist 낮을수록 유사(가까움), idx: (N_unk, K_NN)\n","# cosine similarity로 보고 싶으면 sim = 1 - dist\n","sim = 1.0 - dist\n","\n","print(\"idx shape:\", idx.shape, \"sim shape:\", sim.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"SQJgI_3hb8y7"},"source":["#### 10.15.2 unknown 유사사례 화면 출력\n","\n","발표/데모에선 show_true_label=False로 숨기면 “진짜 unknown 트리아지” 느낌이 더 살음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kU07-RWJyKj2"},"outputs":[],"source":["def show_unknown_neighbors(unk_i, K_show=5, show_true_label=True):\n","    # 첫 번째 이웃은 자기 자신일 가능성이 큼 -> 제외\n","    neigh = idx[unk_i]\n","    neigh_sim = sim[unk_i]\n","\n","    # self 제외(동일 인덱스)\n","    pairs = [(j, s) for j, s in zip(neigh, neigh_sim) if j != unk_i]\n","    pairs = pairs[:K_show]\n","\n","    plt.figure(figsize=(3*(K_show+1), 3))\n","    row = test_unknown_df.iloc[unk_i]\n","    plt.subplot(1, K_show+1, 1)\n","    plt.imshow(row[\"waferMap\"])\n","    title = \"UNKNOWN(query)\"\n","    if show_true_label and \"label\" in row:\n","        title += f\"\\n(true={row['label']})\"\n","    plt.title(title)\n","    plt.axis(\"off\")\n","\n","    for t, (j, s) in enumerate(pairs):\n","        r = test_unknown_df.iloc[int(j)]\n","        plt.subplot(1, K_show+1, t+2)\n","        plt.imshow(r[\"waferMap\"])\n","        title = f\"unk#{int(j)}\\ncos={float(s):.3f}\"\n","        if show_true_label and \"label\" in r:\n","            title += f\"\\n(true={r['label']})\"\n","        plt.title(title)\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시\n","for i in [0, 1, 2]:\n","    show_unknown_neighbors(i, K_show=5, show_true_label=True)\n"]},{"cell_type":"markdown","metadata":{"id":"SqI8qHnBcHlj"},"source":["#### 10.15.3 unknown 클러스터링 (DBSCAN: “비슷한 애들끼리 자동 그룹핑”)\n","\n","KMeans는 “군집 개수 K를 미리 정해야” 해서 MVP-2에는 덜 직관적이고,  \n","DBSCAN은 “밀도 기반”이라 신규 패턴 후보군 만들 때 스토리가 좋음."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYjGt1wycnzO"},"outputs":[],"source":["from sklearn.cluster import DBSCAN\n","from collections import Counter\n","\n","# cosine distance 기준 eps는 데이터마다 달라서 0.15~0.35 정도를 먼저 시도\n","eps = 0.25\n","min_samples = 10\n","\n","db = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\")\n","unk_cluster = db.fit_predict(unk_n)  # -1은 noise(어느 군집에도 안 들어감)\n","\n","cnt = Counter(unk_cluster)\n","print(\"cluster counts:\", cnt)\n","print(\"num clusters (excluding -1):\", len([k for k in cnt.keys() if k != -1]))"]},{"cell_type":"markdown","metadata":{"id":"hpWwZXTgcrSi"},"source":["eps를 3개만 빠르게 스윕해서 “너무 다 -1”인지 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQ6pxL8tcBPs"},"outputs":[],"source":["for eps_try in [0.20, 0.25, 0.30]:\n","    db = DBSCAN(eps=eps_try, min_samples=min_samples, metric=\"cosine\")\n","    cl = db.fit_predict(unk_n)\n","    c = Counter(cl)\n","    ncl = len([k for k in c.keys() if k != -1])\n","    print(f\"eps={eps_try:.2f} | clusters={ncl} | noise={c.get(-1,0)} / {len(cl)}\")"]},{"cell_type":"markdown","metadata":{"id":"5STsHzLQcvfy"},"source":["#### 10.15.4 군집별 대표 샘플 + 유사 샘플 저장(포스터/슬라이드 바로 사용)"]},{"cell_type":"markdown","metadata":{"id":"uGAtgS-Yc1R8"},"source":["군집 대표(centroid에 가장 가까운 샘플) 찾기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1GOx7EWctms"},"outputs":[],"source":["import numpy as np\n","\n","def cluster_representatives(emb, cluster_ids):\n","    reps = {}\n","    for cid in sorted(set(cluster_ids)):\n","        if cid == -1:\n","            continue\n","        members = np.where(cluster_ids == cid)[0]\n","        if len(members) == 0:\n","            continue\n","        # centroid\n","        c = emb[members].mean(axis=0, keepdims=True)\n","        c = l2norm(c)[0]\n","        # centroid와 cosine similarity 최대인 샘플\n","        sims = emb[members] @ c\n","        rep = members[np.argmax(sims)]\n","        reps[cid] = int(rep)\n","    return reps\n","\n","reps = cluster_representatives(unk_n, unk_cluster)\n","print(\"representatives:\", reps)"]},{"cell_type":"markdown","metadata":{"id":"iDD7MaT2c7ee"},"source":["군집 대표 + 같은 군집 Top-K 이웃을 한 장으로 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPPTK7cIc3bU"},"outputs":[],"source":["OUT_DIR = \"assets/triage_unknown\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def save_cluster_panel(cid, rep_i, K_show=5, show_true_label=True):\n","    # rep_i의 이웃 중 같은 군집만 추림\n","    neigh = idx[rep_i]\n","    neigh_sim = sim[rep_i]\n","    pairs = []\n","    for j, s in zip(neigh, neigh_sim):\n","        j = int(j)\n","        if j == rep_i:\n","            continue\n","        if unk_cluster[j] == cid:\n","            pairs.append((j, float(s)))\n","        if len(pairs) >= K_show:\n","            break\n","\n","    plt.figure(figsize=(3*(K_show+1), 3))\n","    rep_row = test_unknown_df.iloc[rep_i]\n","    plt.subplot(1, K_show+1, 1)\n","    plt.imshow(rep_row[\"waferMap\"])\n","    title = f\"cluster {cid}\\nrep unk#{rep_i}\"\n","    if show_true_label and \"label\" in rep_row:\n","        title += f\"\\n(true={rep_row['label']})\"\n","    plt.title(title)\n","    plt.axis(\"off\")\n","\n","    for t, (j, s) in enumerate(pairs):\n","        r = test_unknown_df.iloc[j]\n","        plt.subplot(1, K_show+1, t+2)\n","        plt.imshow(r[\"waferMap\"])\n","        title = f\"unk#{j}\\ncos={s:.3f}\"\n","        if show_true_label and \"label\" in r:\n","            title += f\"\\n(true={r['label']})\"\n","        plt.title(title)\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    path = os.path.join(OUT_DIR, f\"unknown_cluster{cid}_rep{rep_i}.png\")\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path\n","\n","saved = []\n","for cid, rep_i in list(reps.items())[:8]:  # 최대 8개 군집만 저장(조절 가능)\n","    saved.append(save_cluster_panel(cid, rep_i, K_show=5, show_true_label=True))\n","\n","print(\"saved:\", len(saved), \"files in\", OUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"u8usA4CRdCGE"},"source":["요약 CSV 저장 (군집 크기/대표/라벨 분포)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68z-9mhVc9wU"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter\n","\n","rows = []\n","for cid in sorted(set(unk_cluster)):\n","    members = np.where(unk_cluster == cid)[0]\n","    if len(members) == 0:\n","        continue\n","    row = {\"cluster_id\": int(cid), \"count\": int(len(members))}\n","    if cid != -1 and cid in reps:\n","        row[\"rep_unk_i\"] = reps[cid]\n","    # 개발 중에는 true label 분포도 같이 기록(최종 데모에선 숨겨도 됨)\n","    if \"label\" in test_unknown_df.columns:\n","        labels = test_unknown_df.iloc[members][\"label\"].tolist()\n","        row[\"label_dist\"] = dict(Counter(labels))\n","    rows.append(row)\n","\n","df_cl = pd.DataFrame(rows).sort_values([\"cluster_id\"])\n","csv_path = os.path.join(OUT_DIR, \"unknown_clusters_summary.csv\")\n","df_cl.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","csv_path, df_cl.head()"]},{"cell_type":"markdown","metadata":{"id":"moWsMIhSe9yJ"},"source":["### 10.16 Top-K 기반 ‘후보군’ 클러스터링"]},{"cell_type":"markdown","metadata":{"id":"mD7zERNkfebY"},"source":["#### 10.16.1 unknown을 “Top-K 라벨 분포 벡터”로 변환\n","\n","예: known 클래스가 7개면 unknown 하나를 7차원 벡터로 만듦\n","(Top-K에서 Loc가 3개면 Loc 차원에 3/5 같은 값)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EXBGtu0dEWF"},"outputs":[],"source":["import numpy as np\n","from collections import Counter\n","\n","known_labels = sorted(ref_df[\"label\"].unique())\n","label_to_j = {c:j for j,c in enumerate(known_labels)}\n","K = topk_idx.shape[1]\n","\n","def topk_label_vector(i):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[i]]\n","    cnt = Counter(labels)\n","    v = np.zeros(len(known_labels), dtype=np.float32)\n","    for lab, n in cnt.items():\n","        v[label_to_j[lab]] = n / K\n","    return v, cnt, labels\n","\n","X_triage = np.stack([topk_label_vector(i)[0] for i in range(len(test_unknown_df))], axis=0)\n","print(\"X_triage shape:\", X_triage.shape)  # (N_unknown, num_known_classes)"]},{"cell_type":"markdown","metadata":{"id":"UrJej2k8fNWl"},"source":["#### 10.16.2 KMeans로 “Top-K 패턴 그룹” 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8HnxjQNfKX9"},"outputs":[],"source":["from sklearn.cluster import KMeans\n","from collections import Counter\n","\n","n_clusters = 6\n","km = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=\"auto\")\n","triage_cluster = km.fit_predict(X_triage)\n","\n","print(\"cluster counts:\", Counter(triage_cluster))"]},{"cell_type":"markdown","metadata":{"id":"qoxS4cwNfXiT"},"source":["#### 10.16.3 군집을 사람이 읽기 쉬운 말로 요약"]},{"cell_type":"markdown","metadata":{"id":"ElUUu2s8fpHI"},"source":["각 군집에서 “Top-K가 주로 어느 라벨로 쏠리는지”를 요약해줌.\n","\n","예시 출력 해석:  \n","Loc 0.62, Edge-Loc 0.21 …  \n","→ “이 그룹은 Top-K가 Loc 쪽으로 강하게 몰림”"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DgtLWF-fVKs"},"outputs":[],"source":["def summarize_cluster(cid, topn=3):\n","    members = np.where(triage_cluster == cid)[0]\n","    mean_v = X_triage[members].mean(axis=0)  # 평균 분포\n","    top = mean_v.argsort()[::-1][:topn]\n","    return [(known_labels[j], float(mean_v[j])) for j in top], len(members)\n","\n","for cid in range(n_clusters):\n","    top, n = summarize_cluster(cid, topn=3)\n","    print(f\"[cluster {cid}] n={n} | top:\", top)"]},{"cell_type":"markdown","metadata":{"id":"2Tt4OofBf1K2"},"source":["#### 10.16.4 군집 대표 unknown 뽑고, “Top-K 패널” 자동 저장\n","대표는 “군집 평균 분포(mean_v)와 가장 가까운 unknown”으로 선택."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M85DNdknfuk0"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","\n","OUT_DIR = \"assets/triage_clusters\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def pick_representative(cid):\n","    members = np.where(triage_cluster == cid)[0]\n","    mean_v = X_triage[members].mean(axis=0, keepdims=True)\n","    # cosine similarity로 가장 가까운 멤버 선택\n","    A = members\n","    num = (X_triage[A] @ mean_v.T).squeeze()\n","    den = (np.linalg.norm(X_triage[A], axis=1) * np.linalg.norm(mean_v) + 1e-12)\n","    cos = num / den\n","    return int(A[np.argmax(cos)])\n","\n","def save_topk_panel(unk_i, K=5, title_prefix=\"\"):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(title_prefix, y=1.05, fontsize=11)\n","    plt.tight_layout()\n","    path = os.path.join(OUT_DIR, f\"clusterPanel_unk{unk_i:04d}.png\")\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path\n","\n","saved = []\n","for cid in range(n_clusters):\n","    rep = pick_representative(cid)\n","    top, n = summarize_cluster(cid, topn=3)\n","    title = f\"Cluster {cid} (n={n}) | top={top}\"\n","    saved.append(save_topk_panel(rep, K=K, title_prefix=title))\n","\n","print(\"saved panels:\", len(saved), \"in\", OUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"19pCtx9Rf8rD"},"source":["#### 10.16.5 요약 CSV 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEutiU9wf6kN"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter\n","\n","rows = []\n","for cid in range(n_clusters):\n","    members = np.where(triage_cluster == cid)[0]\n","    rep = pick_representative(cid)\n","    top, n = summarize_cluster(cid, topn=5)\n","    rows.append({\n","        \"cluster_id\": cid,\n","        \"count\": n,\n","        \"rep_unk_i\": rep,\n","        \"top_known_mix\": top\n","    })\n","\n","df_clusters = pd.DataFrame(rows)\n","csv_path = os.path.join(OUT_DIR, \"triage_clusters_summary.csv\")\n","df_clusters.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","csv_path, df_clusters"]},{"cell_type":"markdown","source":["## 11. 결과 보고서"],"metadata":{"id":"nw2nPeouVAnP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5lrsRQUgBK0"},"outputs":[],"source":["# =========================\n","# REPORT (robust, single cell)\n","# =========================\n","import os, json, subprocess, datetime, sys\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n","\n","# -------------------------\n","# 0) 기본 경로\n","# -------------------------\n","PROJECT_DIR = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis\"\n","OUT_ROOT = os.path.join(PROJECT_DIR, \"reports\")\n","os.makedirs(OUT_ROOT, exist_ok=True)\n","\n","def _safe(s: str) -> str:\n","    s = str(s)\n","    bad = [' ', '/', '\\\\', ':', '[', ']', '{', '}', '(', ')', ',', '\"', \"'\"]\n","    for b in bad:\n","        s = s.replace(b, \"_\")\n","    return s\n","\n","def save_json(path, obj):\n","    with open(path, \"w\") as f:\n","        json.dump(obj, f, indent=2, ensure_ascii=False)\n","\n","def save_txt(path, text):\n","    with open(path, \"w\") as f:\n","        f.write(text)\n","\n","def get_git_hash():\n","    try:\n","        return subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n","    except Exception:\n","        return None\n","\n","# -------------------------\n","# 1) 모델 선택 (여기서 절대 꼬이지 않게 강제)\n","# -------------------------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model_use = None\n","model_source = None\n","if \"model\" in globals() and model is not None:\n","    model_use = model\n","    model_source = \"model\"\n","elif \"loaded_model\" in globals() and loaded_model is not None:\n","    model_use = loaded_model\n","    model_source = \"loaded_model\"\n","\n","if model_use is None:\n","    raise RuntimeError(\"No model found. Need `model` or `loaded_model` in globals().\")\n","\n","model_use = model_use.to(device).eval()\n","\n","# -------------------------\n","# 2) 라벨/매핑 확정 (잔존 변수 사용 금지)\n","# -------------------------\n","if \"class_to_idx\" not in globals() or class_to_idx is None:\n","    raise RuntimeError(\"class_to_idx not found.\")\n","if \"known_classes\" not in globals() or known_classes is None:\n","    # class_to_idx로부터 known_classes 재구성\n","    known_classes = [None] * len(class_to_idx)\n","    for c, i in class_to_idx.items():\n","        known_classes[i] = c\n","\n","# idx_to_class도 확정\n","idx_to_class_local = {i: c for c, i in class_to_idx.items()}\n","\n","label_names = list(known_classes)  # 표시 순서\n","label_ids   = [class_to_idx[c] for c in label_names]  # 실제 y id\n","\n","K = len(label_names)\n","\n","# -------------------------\n","# 3) 사용된 입력 설정(기록용) 확정\n","#   우선순위: __LOADERS_CFG__ > MODEL_CFG > (INPUT_MODE/RESIZE)\n","# -------------------------\n","resize_used = None\n","input_mode_used = None\n","\n","if \"__LOADERS_CFG__\" in globals() and __LOADERS_CFG__ is not None:\n","    # (__LOADERS_CFG__ = (RESIZE, INPUT_MODE, ...)) 형태\n","    try:\n","        resize_used = int(__LOADERS_CFG__[0])\n","        input_mode_used = str(__LOADERS_CFG__[1])\n","    except Exception:\n","        pass\n","\n","if (resize_used is None or input_mode_used is None) and (\"MODEL_CFG\" in globals()) and isinstance(MODEL_CFG, dict):\n","    if resize_used is None and \"resize\" in MODEL_CFG:\n","        resize_used = int(MODEL_CFG[\"resize\"])\n","    if input_mode_used is None and \"input_mode\" in MODEL_CFG:\n","        input_mode_used = str(MODEL_CFG[\"input_mode\"])\n","\n","if resize_used is None and \"RESIZE\" in globals():\n","    resize_used = int(RESIZE)\n","if input_mode_used is None and \"INPUT_MODE\" in globals():\n","    input_mode_used = str(INPUT_MODE)\n","\n","# fallback\n","if resize_used is None:\n","    resize_used = 64\n","if input_mode_used is None:\n","    input_mode_used = \"unknown_input_mode\"\n","\n","# -------------------------\n","# 4) OUT_DIR (run_id 생성)\n","#   - CKPT_PATH / best_path / last_path가 있으면 그 이름을 활용\n","# -------------------------\n","ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","ckpt_ref = None\n","for cand in [\"CKPT_PATH\", \"best_path\", \"last_path\"]:\n","    if cand in globals() and globals()[cand]:\n","        ckpt_ref = globals()[cand]\n","        break\n","\n","ckpt_base = _safe(os.path.basename(ckpt_ref)) if isinstance(ckpt_ref, str) else f\"no_ckpt_{ts}\"\n","run_id = f\"{ts}_{_safe(getattr(model_use, '__class__', type(model_use)).__name__)}_R{resize_used}_{input_mode_used}_K{K}_{ckpt_base}\".replace(\".pt\",\"\").replace(\".pth\",\"\").replace(\".ckpt\",\"\")\n","OUT_DIR = os.path.join(OUT_ROOT, run_id)\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","print(\"✅ OUT_DIR:\", OUT_DIR)\n","\n","# -------------------------\n","# 5) TEST_KNOWN loader 존재 확인\n","# -------------------------\n","if \"test_known_loader\" not in globals() or test_known_loader is None:\n","    raise RuntimeError(\"test_known_loader not found. Make sure loaders are built before running report cell.\")\n","\n","# -------------------------\n","# 6) 배치 sanity + (중요) y가 idx로 들어오는 사고 감지\n","# -------------------------\n","xb, yb = next(iter(test_known_loader))\n","x_min, x_max = float(xb.min().item()), float(xb.max().item())\n","\n","# yb가 Tensor/np/리스트 등 가능 -> numpy로 확인\n","if torch.is_tensor(yb):\n","    yb_np = yb.detach().cpu().numpy()\n","else:\n","    yb_np = np.array(yb)\n","\n","print(\"[REPORT sanity]\")\n","print(f\"  model_source={model_source}  device={device}\")\n","print(f\"  input_mode_used={input_mode_used}  resize_used={resize_used}\")\n","print(f\"  batch_x={tuple(xb.shape)}  x_range=({x_min:.3f},{x_max:.3f})\")\n","print(f\"  batch_y_unique(sample)={np.unique(yb_np)[:10]}\")\n","\n","# y 값이 클래스 범위를 크게 벗어나면 (x, idx) 혹은 (x,y,idx)에서 y가 idx로 들어간 사고 가능성\n","if yb_np.size > 0 and (yb_np.max() >= K or yb_np.min() < 0):\n","    raise RuntimeError(\n","        f\"y values look wrong (min={yb_np.min()}, max={yb_np.max()}, K={K}). \"\n","        \"Your loader might be returning (x, idx) or y is not class id.\"\n","    )\n","\n","# -------------------------\n","# 7) 예측\n","# -------------------------\n","@torch.no_grad()\n","def predict_loader(model, loader):\n","    ys, ps = [], []\n","    for batch in loader:\n","        # (x,y) 또는 (x,y,idx) 모두 지원\n","        x = batch[0]\n","        y = batch[1]\n","\n","        x = x.to(device)\n","        logits = model(x)\n","        pred = logits.argmax(dim=1).detach().cpu().numpy()\n","\n","        if torch.is_tensor(y):\n","            y_np = y.detach().cpu().numpy()\n","        else:\n","            y_np = np.array(y)\n","\n","        ys.append(y_np)\n","        ps.append(pred)\n","\n","    y_true = np.concatenate(ys)\n","    y_pred = np.concatenate(ps)\n","    return y_true, y_pred\n","\n","y_true, y_pred = predict_loader(model_use, test_known_loader)\n","\n","acc   = accuracy_score(y_true, y_pred)\n","macro = f1_score(y_true, y_pred, average=\"macro\")\n","pred_dist = np.bincount(y_pred, minlength=K).tolist()\n","true_dist = np.bincount(y_true, minlength=K).tolist()\n","\n","rep = classification_report(\n","    y_true, y_pred,\n","    labels=label_ids,\n","    target_names=label_names,\n","    zero_division=0\n",")\n","\n","# -------------------------\n","# 8) confusion matrix 저장/플롯\n","# -------------------------\n","cm_raw = confusion_matrix(y_true, y_pred, labels=label_ids)\n","cm_row = cm_raw / np.clip(cm_raw.sum(axis=1, keepdims=True), 1, None)\n","\n","np.save(os.path.join(OUT_DIR, \"cm_raw.npy\"), cm_raw)\n","np.save(os.path.join(OUT_DIR, \"cm_row_norm.npy\"), cm_row)\n","\n","plt.figure(figsize=(8, 6))\n","plt.imshow(cm_row, vmin=0, vmax=1)\n","plt.xticks(range(K), label_names, rotation=45, ha=\"right\")\n","plt.yticks(range(K), label_names)\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix (row-normalized)\")\n","plt.colorbar(fraction=0.046, pad=0.04)\n","plt.tight_layout()\n","plt.savefig(os.path.join(OUT_DIR, \"test_cm_row_norm.png\"), dpi=200)\n","plt.close()\n","print(\"✅ saved test_cm_row_norm.png\")\n","\n","# -------------------------\n","# 9) report/meta 저장\n","# -------------------------\n","save_txt(\n","    os.path.join(OUT_DIR, \"test_report.txt\"),\n","    f\"[TEST]\\nacc={acc:.4f}, macroF1={macro:.4f}\\n\"\n","    f\"true_dist={true_dist}\\n\"\n","    f\"pred_dist={pred_dist}\\n\\n{rep}\\n\"\n",")\n","print(\"✅ saved test_report.txt\")\n","\n","meta = {\n","    \"timestamp\": ts,\n","    \"out_dir\": OUT_DIR,\n","    \"model_source\": model_source,\n","    \"device\": device,\n","    \"torch\": torch.__version__,\n","    \"python\": sys.version,\n","    \"git_hash\": get_git_hash(),\n","    \"ckpt_ref\": ckpt_ref if isinstance(ckpt_ref, str) else None,\n","    \"resize_used\": resize_used,\n","    \"input_mode_used\": input_mode_used,\n","    \"conv1_in_channels\": int(getattr(getattr(model_use, \"conv1\", None), \"in_channels\", -1)),\n","    \"num_classes\": K,\n","    \"known_classes\": label_names,\n","    \"class_to_idx\": dict(class_to_idx),\n","    \"metrics\": {\n","        \"test_acc\": float(acc),\n","        \"test_macro_f1\": float(macro),\n","        \"true_dist\": true_dist,\n","        \"pred_dist\": pred_dist,\n","        \"x_range\": [x_min, x_max],\n","        \"x_shape\": list(xb.shape),\n","    },\n","}\n","\n","# 있으면 같이 기록\n","for k in [\"RANDOM_STATE\", \"MODEL_CFG\", \"UNKNOWN_CLASSES\", \"EXCLUDE_CLASSES\"]:\n","    if k in globals():\n","        try:\n","            meta[k.lower()] = globals()[k]\n","        except Exception:\n","            pass\n","\n","save_json(os.path.join(OUT_DIR, \"runmeta.json\"), meta)\n","print(\"✅ saved runmeta.json\")\n","\n","# -------------------------\n","# 10) (옵션) 임베딩/UMAP 저장\n","# -------------------------\n","def try_save_npy(name, arr):\n","    try:\n","        np.save(os.path.join(OUT_DIR, f\"{name}.npy\"), arr)\n","        print(f\"✅ saved {name}.npy\", getattr(arr, \"shape\", None))\n","    except Exception as e:\n","        print(f\"⚠️ skip save {name}.npy:\", repr(e))\n","\n","for name in [\"ref_emb\", \"ref_y\", \"unk_emb\"]:\n","    if name in globals():\n","        try_save_npy(name, globals()[name])\n","\n","# UMAP은 설치 강제하지 않고, 있으면만 수행\n","def save_umap_known_unknown(ref_emb, ref_y, unk_emb, random_state, out_dir):\n","    import umap  # 없으면 ImportError\n","    N_REF_VIS = min(5000, len(ref_emb))\n","    N_UNK_VIS = min(2000, len(unk_emb))\n","\n","    rng = np.random.RandomState(random_state if random_state is not None else 42)\n","    ref_vis_idx = rng.choice(len(ref_emb), size=N_REF_VIS, replace=False)\n","    unk_vis_idx = rng.choice(len(unk_emb), size=N_UNK_VIS, replace=False)\n","\n","    X_vis = np.vstack([ref_emb[ref_vis_idx], unk_emb[unk_vis_idx]])\n","    y_vis = np.concatenate([ref_y[ref_vis_idx], -1*np.ones(N_UNK_VIS, dtype=int)])\n","\n","    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=(random_state if random_state is not None else 42))\n","    Z = reducer.fit_transform(X_vis)\n","\n","    np.save(os.path.join(out_dir, \"umap_Z.npy\"), Z)\n","    np.save(os.path.join(out_dir, \"umap_y.npy\"), y_vis)\n","\n","    plt.figure(figsize=(8,6))\n","    mask_unk = (y_vis == -1)\n","    plt.scatter(Z[mask_unk,0], Z[mask_unk,1], s=6, label=\"Unknown\", alpha=0.9)\n","    for k in sorted(np.unique(y_vis)):\n","        if k == -1:\n","            continue\n","        m = (y_vis == k)\n","        name = idx_to_class_local.get(int(k), f\"Class {int(k)}\")\n","        plt.scatter(Z[m,0], Z[m,1], s=6, label=name, alpha=0.9)\n","\n","    plt.title(\"Embedding 2D (UMAP): known vs unknown\")\n","    plt.legend(markerscale=3, bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(out_dir, \"umap_known_unknown.png\"), dpi=200)\n","    plt.close()\n","    print(\"✅ saved umap_known_unknown.png + umap_Z.npy + umap_y.npy\")\n","\n","if all(k in globals() for k in [\"ref_emb\", \"ref_y\", \"unk_emb\"]):\n","    try:\n","        rs = globals()[\"RANDOM_STATE\"] if \"RANDOM_STATE\" in globals() else 42\n","        save_umap_known_unknown(ref_emb, ref_y, unk_emb, rs, OUT_DIR)\n","    except Exception as e:\n","        print(\"⚠️ skip UMAP:\", repr(e))\n","else:\n","    print(\"⚠️ skip UMAP (need ref_emb, ref_y, unk_emb)\")\n","\n","print(\"DONE ✅\")"]},{"cell_type":"code","source":[],"metadata":{"id":"VTyVskuYuhMH"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}