{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Open-set Wafer Map Triage (WM-811K)\n","\n","- **MVP-1(ì™„ë£Œ)**: Known ë¶„ë¥˜ + OOD(Unknown íƒì§€, MSP/Energy) í‰ê°€  \n","- **MVP-2(ì§„í–‰ì¤‘)**: íŠ¸ë¦¬ì•„ì§€(UMAP ì‹œê°í™” + Top-K ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰)\n","\n","> í•µì‹¬: Unknownì„ â€œUnknownâ€ìœ¼ë¡œ ê±°ë¶€(reject)í•˜ê³ , ì´í›„ íŒë‹¨ì„ ë•ëŠ” íŠ¸ë¦¬ì•„ì§€ ì›Œí¬í”Œë¡œìš°"],"metadata":{"id":"UIqvq9cFUjPb"}},{"cell_type":"markdown","source":["## 0. í™˜ê²½ ì„¤ì •\n","- Google Drive ë§ˆìš´íŠ¸, ê²½ë¡œ/ì‹œë“œ ì„¤ì •"],"metadata":{"id":"ETatusOj_t7G"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"Jr1KElMF_th2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. ë°ì´í„° ë¡œë“œ ë° í™•ì¸"],"metadata":{"id":"yqVRucdizMuf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1NhVam2_Fi4"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/data/LSWMD.pkl\")\n","print(df.shape)\n","print(df[\"failureType\"].head())      # ë³´í†µ list í˜•íƒœê±°ë‚˜ ë¹ˆ list\n","print(df[\"trianTestLabel\"].head())   # ê¸°ì¡´ train/test í‘œê¸°ê°€ ìˆì„ ìˆ˜ ìˆìŒ(ìš°ë¦¬ëŠ” ì¬ë¶„í•  ê¶Œì¥)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDOFE9zrrbu8","executionInfo":{"status":"ok","timestamp":1767860215530,"user_tz":-540,"elapsed":20757,"user":{"displayName":"Myunggyun Choi (think_virus)","userId":"16622592930277680639"}},"outputId":"38b44d4f-58cc-4272-ba30-cd8e4cfaa933"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### 1.1 ë°ì´í„° êµ¬ì¡° í™•ì¸"],"metadata":{"id":"fjrCpVOUzPJ5"}},{"cell_type":"code","source":["print(df.columns)\n","print(df[[\"waferMap\",\"failureType\",\"trianTestLabel\"]].head(3))\n","\n","# waferMap í•œ ê°œì˜ í˜•íƒœ í™•ì¸\n","wm0 = df[\"waferMap\"].iloc[0]\n","print(type(wm0), getattr(wm0, \"shape\", None))"],"metadata":{"id":"lMLpGPzlIZCi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2 ë¼ë²¨ ì „ì²˜ë¦¬ (failureType â†’ label)"],"metadata":{"id":"a-5bybsCzeXj"}},{"cell_type":"code","source":["import numpy as np\n","\n","def get_label(x):\n","    if isinstance(x, (list, tuple, np.ndarray)):\n","        return str(x[0][0]) if len(x) > 0 else None\n","    if isinstance(x, str) and x.strip() != \"\":\n","        return x\n","    return None\n","\n","df[\"label\"] = df[\"failureType\"].apply(get_label)\n","\n","print(df[\"label\"].value_counts(dropna=False).head(15))\n","print(\"labeled count:\", df[\"label\"].notna().sum())"],"metadata":{"id":"5xLjOHq7zZ4t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(df.iloc[0][\"label\"]))"],"metadata":{"id":"WeuCIcGvyt8b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Open-set í‰ê°€ ì„¤ê³„ (í´ë˜ìŠ¤ í™€ë“œì•„ì›ƒ)\n","- Donutê³¼ Scratchë¥¼ Unknown(í™€ë“œì•„ì›ƒ)ìœ¼ë¡œ ì„¤ì •"],"metadata":{"id":"eg4POGB90AVA"}},{"cell_type":"code","source":["UNKNOWN_CLASSES = [\"Donut\", \"Scratch\"]\n","\n","labeled = df[df[\"label\"].notna()].copy()\n","known_df = labeled[~labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","unknown_df = labeled[labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","\n","print(\"labeled:\", len(labeled))\n","print(\"known:\", len(known_df))\n","print(\"unknown:\", len(unknown_df))\n","print(\"known classes:\", sorted(known_df[\"label\"].unique()))\n","print(\"unknown classes:\", sorted(unknown_df[\"label\"].unique()))"],"metadata":{"id":"YoVXY6tzzgtM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. í´ë˜ìŠ¤ ì´í•´ ë° ì‹œê°í™”"],"metadata":{"id":"ETa1JYOssN93"}},{"cell_type":"markdown","source":["### 3.1 í´ë˜ìŠ¤ ì •ì˜ + ì»¬ëŸ¬ ì˜ë¯¸\n","\n","\n","- **Center**: ì›¨ì´í¼ **ì¤‘ì‹¬(ê°€ìš´ë°)**ì— ë¶ˆëŸ‰ì´ ëª°ë ¤ ìˆëŠ” íŒ¨í„´ (ê°€ìš´ë° ë­‰ì¹¨)\n","- **Donut**: ì¤‘ì‹¬ì€ ë¹„êµì  ê¹¨ë—í•˜ê³ , ê·¸ ì£¼ë³€ì— **ë™ì‹¬ì›(ë„ë„› ë§)**ì²˜ëŸ¼ ë¶ˆëŸ‰ì´ ë¶„í¬ (ì›í˜• ë )\n","- **Edge-Loc (Edge-Local)**: ì›¨ì´í¼ **ê°€ì¥ìë¦¬ì˜ íŠ¹ì • êµ¬ê°„**ì—ë§Œ ë¶ˆëŸ‰ì´ ëª°ë¦° íŒ¨í„´ (í…Œë‘ë¦¬ í•œìª½ë§Œ)\n","- **Edge-Ring**: ì›¨ì´í¼ **í…Œë‘ë¦¬ ì „ì²´ë¥¼ ë”°ë¼ ê³ ë¦¬(ë§)**ì²˜ëŸ¼ ë¶ˆëŸ‰ì´ ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´ (ë‘˜ë ˆ ì „ì²´ ë )\n","- **Loc (Local)**: ì›¨ì´í¼ ë‚´ë¶€ì—ì„œ **ì¤‘ì‹¬/í…Œë‘ë¦¬ê°€ ì•„ë‹Œ ì„ì˜ ìœ„ì¹˜**ì— ë¶ˆëŸ‰ì´ ë­‰ì¹œ íŒ¨í„´ (ì•ˆìª½ ì–´ë”˜ê°€ ë©ì–´ë¦¬)\n","- **Random**: ì›¨ì´í¼ ì „ì²´ì— ë¶ˆëŸ‰ì´ **ë“¬ì„±ë“¬ì„±, ë¹„êµì  ê³ ë¥´ê²Œ í©ì–´ì§„** íŒ¨í„´ (ì—¬ê¸°ì €ê¸° ì )\n","- **Scratch**: **ì§ì„ /ê³¡ì„  í˜•íƒœë¡œ ê¸¸ê²Œ ì´ì–´ì§„** ë¶ˆëŸ‰ íŒ¨í„´ (ê¸íŒ ìêµ­ì²˜ëŸ¼ ì„ /í˜¸)\n","- **Near-full**: ì›¨ì´í¼ **ê±°ì˜ ì „ì²´ê°€ ë¶ˆëŸ‰ìœ¼ë¡œ ì±„ì›Œì§„** íŒ¨í„´ (ëŒ€ë¶€ë¶„ ë¶ˆëŸ‰)\n","- **none**: ëšœë ·í•œ ê²°í•¨ íŒ¨í„´ì´ ì—†ê±°ë‚˜ ê²°í•¨ì´ ê±°ì˜ ì—†ëŠ” ìƒíƒœ (íŒ¨í„´ ì—†ìŒ)\n","---\n","- ë³´ë¼(ê°€ì¥ ì–´ë‘ìš´ ìƒ‰) = ì‘ì€ ê°’ (ë³´í†µ 0) â†’ ì›¨ì´í¼ ë°”ê¹¥/ë°°ê²½\n","- íŒŒë‘(ì¤‘ê°„ ê°’) = ì¤‘ê°„ ê°’ (ë³´í†µ 1) â†’ ì •ìƒ die (pass)\n","- ë…¸ë‘(ê°€ì¥ ë°ì€ ìƒ‰) = í° ê°’ (ë³´í†µ 2) â†’ ë¶ˆëŸ‰ die (fail)"],"metadata":{"id":"UCkHAU1bsClI"}},{"cell_type":"markdown","source":["### 3.2 í´ë˜ìŠ¤ë³„ ëŒ€í‘œ 1ì¥ ê·¸ë¦¬ë“œë¡œ ë³´ê¸°"],"metadata":{"id":"hUVRxPR4hPij"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","labels = sorted(labeled[\"label\"].unique())\n","n = len(labels)\n","\n","cols = 4\n","rows = (n + cols - 1) // cols\n","\n","plt.figure(figsize=(4*cols, 4*rows))\n","for i, lab in enumerate(labels):\n","    wm = labeled[labeled[\"label\"] == lab][\"waferMap\"].iloc[0]  # ì²« ìƒ˜í”Œ\n","    ax = plt.subplot(rows, cols, i+1)\n","    ax.imshow(wm, interpolation=\"nearest\")\n","    ax.set_title(lab)\n","    ax.axis(\"off\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"7gukBRnNsG2m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.3 íŠ¹ì • Failure Type ëœë¤ ìƒ˜í”Œ ë³´ê¸°"],"metadata":{"id":"Krj0gzWYsV94"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def show_samples(label, n=8, seed=42):\n","    sub = labeled[labeled[\"label\"] == label]\n","    if len(sub) == 0:\n","        print(\"No samples for:\", label)\n","        return\n","    sub = sub.sample(n=min(n, len(sub)), random_state=seed)\n","\n","    cols = 4\n","    rows = (len(sub) + cols - 1) // cols\n","    plt.figure(figsize=(4*cols, 4*rows))\n","    for i, wm in enumerate(sub[\"waferMap\"].tolist()):\n","        ax = plt.subplot(rows, cols, i+1)\n","        ax.imshow(wm, interpolation=\"nearest\")\n","        ax.axis(\"off\")\n","    plt.suptitle(f\"{label} (n={len(sub)})\", y=1.02, fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ì˜ˆì‹œ\n","for label in [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Random\", \"Scratch\", \"Near-full\", \"none\"]:\n","    show_samples(label, n=8, seed=0)"],"metadata":{"collapsed":true,"id":"uUnhzrRLsa0M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. ë°ì´í„° ë¶„í•  (train/val/test_known/test_unknown)\n","\n","- train = 70%\n","- val = 15%\n","- test_known = 15%\n","- test_unknown = unknown_df ì „ë¶€\n","\n","ì´ ë¹„ìœ¨ì€ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì•„ì£¼ í”í•œ ê¸°ë³¸ê°’\n","\n","- trainì„ ì¶©ë¶„íˆ í¬ê²Œ ê°€ì ¸ê°€ì•¼ í•™ìŠµì´ ì˜ ë˜ê³ \n","- val/testë„ ë„ˆë¬´ ì‘ìœ¼ë©´ ì§€í‘œê°€ í”ë“¤ë¦¬ë‹ˆê¹Œ ì ë‹¹íˆ í™•ë³´í•˜ëŠ” ê· í˜•"],"metadata":{"id":"EvmhBLFXmgyd"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_df, temp_df = train_test_split(\n","    known_df, test_size=0.3, random_state=42, stratify=known_df[\"label\"] # stratifyëŠ” ê° splitë§ˆë‹¤ ë¼ë²¨ ë¹„ìœ¨ì´ ì›ë˜ ë°ì´í„°ë‘ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€ë˜ë„ë¡ ë‚˜ëˆ ì£¼ëŠ” ì˜µì…˜\n",")\n","val_df, test_known_df = train_test_split(\n","    temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"]\n",")\n","\n","test_unknown_df = unknown_df.copy()\n","\n","print(\"train:\", len(train_df), \"val:\", len(val_df),\n","      \"test_known:\", len(test_known_df), \"test_unknown:\", len(test_unknown_df))"],"metadata":{"id":"3kPjFBtWz7f8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Dataset/DataLoader êµ¬ì„± (ì „ì²˜ë¦¬/ì¦ê°•)\n","\n","\n","*   waferMapì„ 64Ã—64ë¡œ resize\n","*   1ì±„ë„ì„ 3ì±„ë„ë¡œ ë³µì œí•´ì„œ ResNetì— ë„£ê¸° (ê°€ì¥ ì‰¬ìš´ ë°©ì‹)\n","*   íšŒì „/ë°˜ì „ ì¦ê°•ì€ trainì—ë§Œ"],"metadata":{"id":"rTQ0Plp_mpkJ"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","known_classes = sorted(train_df[\"label\"].unique())\n","class_to_idx = {c:i for i,c in enumerate(known_classes)}\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","print(class_to_idx)\n","\n","class WaferMapDataset(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64):\n","        self.df = df.reset_index(drop=True)\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = resize\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        # x: (1,H,W)\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[2])  # ì¢Œìš°\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[1])  # ìƒí•˜\n","        k = int(torch.randint(0, 4, (1,)).item())\n","        x = torch.rot90(x, k, dims=[1,2])\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        wm = row[\"waferMap\"]  # numpy 2D\n","        x = torch.tensor(wm, dtype=torch.float32).unsqueeze(0)  # (1,H,W)\n","\n","        # 0/1/2 í˜•íƒœë©´ 0~1ë¡œ ìŠ¤ì¼€ì¼ (ì„ íƒ)\n","        mx = x.max()\n","        x = x / (mx if mx > 0 else 1.0)\n","\n","        # resize\n","        x = F.interpolate(x.unsqueeze(0), size=(self.resize, self.resize), mode=\"nearest\").squeeze(0)\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        # ResNet ì…ë ¥ ë§ì¶”ê¸°: 3ì±„ë„\n","        x = x.repeat(3, 1, 1)  # (3,resize,resize)\n","\n","        if self.class_to_idx is None:\n","            return x\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return x, y\n","\n","train_loader = DataLoader(WaferMapDataset(train_df, class_to_idx, True, 64),\n","                          batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(WaferMapDataset(val_df, class_to_idx, False, 64),\n","                        batch_size=256, shuffle=False, num_workers=2)\n","test_known_loader = DataLoader(WaferMapDataset(test_known_df, class_to_idx, False, 64),\n","                               batch_size=256, shuffle=False, num_workers=2)\n","test_unknown_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64),\n","    batch_size=256, shuffle=False, num_workers=2\n",")"],"metadata":{"id":"MDQQDaKPmpBM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Known ë¶„ë¥˜ê¸° í•™ìŠµ (ResNet18 ë² ì´ìŠ¤ë¼ì¸)"],"metadata":{"id":"BvA0Nu_WoDyh"}},{"cell_type":"code","source":["import torchvision.models as models\n","import torch.nn as nn\n","from tqdm import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = models.resnet18(weights=None)\n","model.fc = nn.Linear(model.fc.in_features, len(known_classes))\n","model = model.to(device)\n","\n","opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","\n","def run_epoch(loader, train=True):\n","    model.train(train)\n","    total_loss, correct, total = 0, 0, 0\n","    for x, y in tqdm(loader, leave=False):\n","        x = x.to(device)\n","        y = torch.tensor(y).to(device)\n","\n","        logits = model(x)\n","        loss = criterion(logits, y)\n","\n","        if train:\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","        total_loss += loss.item() * x.size(0)\n","        pred = logits.argmax(dim=1)\n","        correct += (pred == y).sum().item()\n","        total += x.size(0)\n","\n","    return total_loss/total, correct/total\n","\n","for epoch in range(1, 6):\n","    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n","    va_loss, va_acc = run_epoch(val_loader, train=False)\n","    print(f\"Epoch {epoch} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}\")"],"metadata":{"id":"Cb3m6QkbmjoC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Known ì„±ëŠ¥ í‰ê°€ (macro-F1 ì¤‘ì‹¬)"],"metadata":{"id":"ewbcL6n4rW_R"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report\n","\n","@torch.no_grad()\n","def predict_known(loader):\n","    model.eval()\n","    ys, ps = [], []\n","    for x, y in loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        pred = logits.argmax(dim=1).cpu().numpy()\n","        ys.append(np.array(y))\n","        ps.append(pred)\n","    y_true = np.concatenate(ys)\n","    y_pred = np.concatenate(ps)\n","    return y_true, y_pred\n","\n","y_true, y_pred = predict_known(test_known_loader)\n","print(\"macro-F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n","print(classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(len(known_classes))]))"],"metadata":{"id":"jzNNV_XwoF7r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. OOD(Unknown íƒì§€) í‰ê°€: MSP vs Energy"],"metadata":{"id":"jum0FDZJrfWD"}},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score, average_precision_score\n","\n","@torch.no_grad()\n","def collect_scores(loader, known=True, T=1.0):\n","    model.eval()\n","    msp_list, energy_list = [], []\n","    for batch in loader:\n","        x = batch[0] if known else batch\n","        x = x.to(device)\n","\n","        logits = model(x) / T\n","        prob = torch.softmax(logits, dim=1)\n","        msp = prob.max(dim=1).values                   # ë†’ì„ìˆ˜ë¡ known\n","        energy = -T * torch.logsumexp(logits, dim=1)   # ë³´í†µ -energyê°€ ë†’ì„ìˆ˜ë¡ knownë¡œ ì‚¬ìš©\n","\n","        msp_list.append(msp.cpu().numpy())\n","        energy_list.append(energy.cpu().numpy())\n","\n","    return np.concatenate(msp_list), np.concatenate(energy_list)\n","\n","msp_k, en_k = collect_scores(test_known_loader, known=True)\n","msp_u, en_u = collect_scores(test_unknown_loader, known=False)\n","\n","y = np.concatenate([np.ones_like(msp_k), np.zeros_like(msp_u)])  # known=1, unknown=0\n","\n","score_msp = np.concatenate([msp_k, msp_u])\n","score_energy = np.concatenate([-en_k, -en_u])  # -energyë¥¼ known ì ìˆ˜ë¡œ\n","\n","print(\"AUROC MSP   :\", roc_auc_score(y, score_msp))\n","print(\"AUPR  MSP   :\", average_precision_score(y, score_msp))\n","print(\"AUROC Energy:\", roc_auc_score(y, score_energy))\n","print(\"AUPR  Energy:\", average_precision_score(y, score_energy))"],"metadata":{"id":"j4FMGusPrUAS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ef8a256"},"source":["## 9. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n","\n","\n","ì €ì¥ëœ `state_dict`ë¥¼ ë¶ˆëŸ¬ì™€ ìƒˆë¡œìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì— ë¡œë“œí•©ë‹ˆë‹¤. ì´ë•Œ, ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ëŠ” ì €ì¥í•  ë•Œì™€ ë™ì¼í•˜ê²Œ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"0372b366"},"source":["import os, json\n","from datetime import datetime\n","import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","CKPT_DIR = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/checkpoints\"\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","def _safe(s: str) -> str:\n","    return (\n","        str(s).replace(\" \", \"\")\n","        .replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n","        .replace(\",\", \"-\").replace(\"[\", \"\").replace(\"]\", \"\")\n","        .replace(\"'\", \"\").replace('\"', \"\")\n","    )\n","\n","def _get(name, default=None):\n","    # ë…¸íŠ¸ë¶ ì „ì—­ ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°\n","    return globals().get(name, default)\n","\n","def save_mvp_checkpoint(\n","    model,\n","    class_to_idx,\n","    unknown_classes,\n","    resize=64,\n","    arch=\"resnet18\",\n","    optimizer=None,\n","    ckpt_dir=CKPT_DIR,\n","    extra_cfg=None,\n","):\n","    \"\"\"\n","    âœ… ìë™ ì €ì¥:\n","    - ë…¸íŠ¸ë¶ì— val_macro_f1 / auroc_msp / auroc_energy / epochs ë“±ì˜ ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë©”íƒ€+íŒŒì¼ëª…ì— ë°˜ì˜\n","    - ì—†ìœ¼ë©´ ì—†ëŠ”ëŒ€ë¡œ ì €ì¥ (MVP ì¤‘ê°„ ì €ì¥ì—ë„ ì‚¬ìš© ê°€ëŠ¥)\n","    \"\"\"\n","    os.makedirs(ckpt_dir, exist_ok=True)\n","\n","    # ìë™ìœ¼ë¡œ ë©”íŠ¸ë¦­/ì„¤ì • ê°’ ëŒì–´ì˜¤ê¸°(ìˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ None)\n","    epochs = _get(\"epochs_run\", None) or _get(\"EPOCHS\", None) or _get(\"epochs\", None)\n","    val_macro_f1 = _get(\"val_macro_f1\", None)\n","    auroc_msp = _get(\"auroc_msp\", None)\n","    auroc_energy = _get(\"auroc_energy\", None)\n","    holdout = \"-\".join([_safe(x) for x in (unknown_classes or [])]) or \"none\"\n","    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","    # íŒŒì¼ëª… êµ¬ì„±(ìˆëŠ” ì •ë³´ë§Œ ì¶”ê°€)\n","    parts = [ts, _safe(arch), f\"r{int(resize)}\", f\"holdout-{holdout}\"]\n","    if epochs is not None:\n","        parts.append(f\"ep{int(epochs):02d}\")\n","    if val_macro_f1 is not None:\n","        parts.append(f\"valF1-{float(val_macro_f1):.3f}\")\n","    if auroc_msp is not None:\n","        parts.append(f\"aurocMSP-{float(auroc_msp):.3f}\")\n","    if auroc_energy is not None:\n","        parts.append(f\"aurocEn-{float(auroc_energy):.3f}\")\n","\n","    run_name = \"_\".join(parts)\n","    ckpt_path = os.path.join(ckpt_dir, run_name + \".pt\")\n","\n","    # ì²´í¬í¬ì¸íŠ¸ ë‚´ìš©\n","    ckpt = {\n","        \"arch\": arch,\n","        \"resize\": int(resize),\n","        \"unknown_classes\": list(unknown_classes) if unknown_classes is not None else None,\n","        \"class_to_idx\": dict(class_to_idx),\n","        \"model_state_dict\": model.state_dict(),\n","        \"metrics\": {\n","            \"val_macro_f1\": val_macro_f1,\n","            \"auroc_msp\": auroc_msp,\n","            \"auroc_energy\": auroc_energy,\n","        },\n","        \"cfg\": extra_cfg or {},\n","        \"saved_at\": datetime.now().isoformat(),\n","    }\n","    if optimizer is not None:\n","        ckpt[\"optimizer_state_dict\"] = optimizer.state_dict()\n","\n","    torch.save(ckpt, ckpt_path)\n","\n","    # ì‚¬ëŒì´ ë³´ê¸° ì¢‹ì€ ë©”íƒ€ jsonë„ ê°™ì´ ì €ì¥(ì„ íƒì´ì§€ë§Œ ì¶”ì²œ)\n","    meta_path = ckpt_path.replace(\".pt\", \".json\")\n","    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(\n","            {k: ckpt[k] for k in [\"arch\", \"resize\", \"unknown_classes\", \"metrics\", \"cfg\", \"saved_at\"]},\n","            f, ensure_ascii=False, indent=2\n","        )\n","\n","    print(\"âœ… Saved:\", ckpt_path)\n","    print(\"ğŸ“ Meta :\", meta_path)\n","    return ckpt_path\n","\n","def load_mvp_checkpoint(path, device=\"cpu\"):\n","    ckpt = torch.load(path, map_location=device)\n","\n","    class_to_idx = ckpt[\"class_to_idx\"]\n","    known_classes = [None] * len(class_to_idx)\n","    for cls, idx in class_to_idx.items():\n","        known_classes[idx] = cls\n","\n","    arch = ckpt.get(\"arch\", \"resnet18\")\n","    if arch == \"resnet18\":\n","        model = models.resnet18(weights=None)\n","        model.fc = nn.Linear(model.fc.in_features, len(known_classes))\n","    else:\n","        raise ValueError(f\"Unsupported arch: {arch}\")\n","\n","    model.load_state_dict(ckpt[\"model_state_dict\"])\n","    model = model.to(device).eval()\n","\n","    print(\"âœ… Loaded:\", path)\n","    print(\" - arch:\", arch, \"| resize:\", ckpt.get(\"resize\"))\n","    print(\" - unknown_classes:\", ckpt.get(\"unknown_classes\"))\n","    print(\" - metrics:\", ckpt.get(\"metrics\", {}))\n","    return model, ckpt, known_classes, class_to_idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ckpt_path = save_mvp_checkpoint(model, class_to_idx, UNKNOWN_CLASSES, resize=64, arch=\"resnet18\", optimizer=None)"],"metadata":{"id":"NaKk1QccAxeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","# =========================\n","# 0) ê¸°ë³¸ ì„¤ì •\n","# =========================\n","DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/data/LSWMD.pkl\"\n","\n","CKPT_DIR  = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/checkpoints\"\n","# âœ… ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ìë™ ì„ íƒ(ì›í•˜ë©´ CKPT_PATHë¥¼ ì§ì ‘ ì§€ì •í•´ë„ ë¨)\n","if \"CKPT_PATH\" not in globals() or CKPT_PATH is None:\n","    pts = sorted([os.path.join(CKPT_DIR, f) for f in os.listdir(CKPT_DIR) if f.endswith(\".pt\")])\n","    assert len(pts) > 0, f\"No .pt found in {CKPT_DIR}\"\n","    CKPT_PATH = pts[-1]\n","\n","device = \"cuda\" if \"torch\" in globals() and torch.cuda.is_available() else \"cpu\"\n","RANDOM_STATE = 42\n","\n","print(\"Using CKPT_PATH:\", CKPT_PATH)\n","print(\"Using DATA_PATH:\", DATA_PATH)\n","print(\"Device:\", device)\n","\n","# =========================\n","# 1) ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n","# =========================\n","loaded_model, ckpt, known_classes_loaded, class_to_idx_loaded = load_mvp_checkpoint(CKPT_PATH, device=device)\n","\n","# ë…¸íŠ¸ë¶ ê³µí†µ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë§ì¶”ê¸°\n","model = loaded_model\n","class_to_idx = class_to_idx_loaded\n","\n","# ckptì— ë“¤ì–´ìˆëŠ” ì„¤ì •(ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)\n","UNKNOWN_CLASSES = ckpt.get(\"unknown_classes\", None) or [\"Donut\", \"Scratch\"]\n","RESIZE = int(ckpt.get(\"resize\", 64))\n","\n","# âš ï¸ ì´í›„ ì½”ë“œì—ì„œ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ:\n","known_classes_model = known_classes_loaded     # ëª¨ë¸ ì¶œë ¥ ë§¤í•‘ ê¸°ì¤€(ê³ ì •)\n","print(\"Holdout(UNKNOWN_CLASSES):\", UNKNOWN_CLASSES)\n","print(\"RESIZE:\", RESIZE)\n","print(\"known_classes_model:\", known_classes_model)\n","\n","# =========================\n","# 2) ë°ì´í„° ë¡œë“œ & label ìƒì„±(í•µì‹¬ ìˆ˜ì • í¬ì¸íŠ¸)\n","#    - failureTypeì´ listê°€ ì•„ë‹ˆë¼ np.ndarrayì¸ ê²½ìš°ê°€ ë§ì•„ì„œ ê·¸ê²ƒë„ ì²˜ë¦¬í•´ì•¼ í•¨\n","# =========================\n","df = pd.read_pickle(DATA_PATH)\n","\n","def _to_label(x):\n","    # None / NaN\n","    if x is None:\n","        return None\n","    if isinstance(x, float) and np.isnan(x):\n","        return None\n","\n","    # âœ… í•µì‹¬: numpy.ndarray / list / tuple ì•ˆì— ë˜ ndarrayê°€ ìˆëŠ” ê²½ìš°ê°€ ìˆì–´ì„œ\n","    # \"ìŠ¤ì¹¼ë¼ ë¬¸ìì—´\"ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ì²« ì›ì†Œë¥¼ ê³„ì† ë²—ê¹€\n","    for _ in range(5):\n","        if isinstance(x, np.ndarray):\n","            if x.size == 0:\n","                return None\n","            x = x.ravel()[0]\n","            continue\n","        if isinstance(x, (list, tuple)):\n","            if len(x) == 0:\n","                return None\n","            x = x[0]\n","            continue\n","        break\n","\n","    # numpy scalar â†’ python scalar\n","    if isinstance(x, np.generic):\n","        x = x.item()\n","\n","    # ìµœì¢… ë¬¸ìì—´ ì •ë¦¬\n","    if isinstance(x, str):\n","        x = x.strip()\n","        return x if x != \"\" else None\n","\n","    # í˜¹ì‹œë¼ë„ ì—¬ê¸°ê¹Œì§€ ì™”ëŠ”ë° ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´í™”(ê±°ì˜ ì—†ìŒ)\n","    return str(x)\n","\n","df[\"label\"] = df[\"failureType\"].apply(_to_label)\n","\n","print(\"\\n[Debug] failureType type top:\")\n","print(df[\"failureType\"].apply(type).value_counts().head(5))\n","print(\"\\n[Debug] label value top:\")\n","print(df[\"label\"].value_counts(dropna=False).head(10))\n","\n","# =========================\n","# 3) Open-set êµ¬ì„±(holdout) + split (10.2ì—ì„œ í•„ìš”í•œ ë³€ìˆ˜ ìƒì„±)\n","# =========================\n","labeled = df[df[\"label\"].notna()].copy()\n","\n","# âœ… ëª¨ë¸ì´ í•™ìŠµí•œ known í´ë˜ìŠ¤(ckptì˜ class_to_idx)ë§Œ known í›„ë³´ë¡œ ì‚¬ìš© (ì•ˆì „)\n","KNOWN_SET = set(class_to_idx.keys())\n","\n","known_all = labeled[labeled[\"label\"].isin(KNOWN_SET)].copy()\n","known_df = known_all[~known_all[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","unknown_df = labeled[labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","\n","print(\"\\nCounts:\")\n","print(\" - labeled   :\", len(labeled))\n","print(\" - known_all :\", len(known_all))\n","print(\" - known_df  :\", len(known_df))\n","print(\" - unknown_df:\", len(unknown_df))\n","\n","# known_dfê°€ 0ì´ë©´ ì—¬ê¸°ì„œ ë©ˆì¶”ê³  ì›ì¸ í™•ì¸\n","if len(known_df) == 0:\n","    raise ValueError(\n","        \"known_dfê°€ 0ì…ë‹ˆë‹¤. label ìƒì„±/í•„í„°ë§ ë¬¸ì œì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.\\n\"\n","        \"ìœ„ Debug ì¶œë ¥(label value top)ì—ì„œ ì‹¤ì œ ë¼ë²¨ ë¬¸ìì—´ì„ í™•ì¸í•˜ì„¸ìš”.\"\n","    )\n","\n","# stratifyê°€ ê°€ë” ì‹¤íŒ¨(íŠ¹íˆ ë§¤ìš° ì‘ì€ í´ë˜ìŠ¤)í•  ìˆ˜ ìˆì–´ fallback í¬í•¨\n","try:\n","    train_df, temp_df = train_test_split(\n","        known_df, test_size=0.3, random_state=RANDOM_STATE, stratify=known_df[\"label\"]\n","    )\n","    val_df, test_known_df = train_test_split(\n","        temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[\"label\"]\n","    )\n","except ValueError as e:\n","    print(\"\\n[Warn] Stratified split failed. Falling back to non-stratified split.\")\n","    print(\"Reason:\", e)\n","    train_df, temp_df = train_test_split(\n","        known_df, test_size=0.3, random_state=RANDOM_STATE, shuffle=True\n","    )\n","    val_df, test_known_df = train_test_split(\n","        temp_df, test_size=0.5, random_state=RANDOM_STATE, shuffle=True\n","    )\n","\n","test_unknown_df = unknown_df.reset_index(drop=True)\n","\n","# âœ… 10.2ì—ì„œ ì“°ëŠ” known_classesëŠ” ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ(ë¹„ì–´ìˆì§€ ì•Šê²Œ) ë‹¤ì‹œ ì„¸íŒ…\n","known_classes = sorted(train_df[\"label\"].unique())\n","\n","print(\"\\nSplit:\")\n","print(\" - train       :\", len(train_df))\n","print(\" - val         :\", len(val_df))\n","print(\" - test_known  :\", len(test_known_df))\n","print(\" - test_unknown:\", len(test_unknown_df))\n","\n","known_classes = sorted(train_df[\"label\"].unique())\n","class_to_idx = {c:i for i,c in enumerate(known_classes)}\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","print(class_to_idx)\n","\n","class WaferMapDataset(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64):\n","        self.df = df.reset_index(drop=True)\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = resize\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        # x: (1,H,W)\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[2])  # ì¢Œìš°\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[1])  # ìƒí•˜\n","        k = int(torch.randint(0, 4, (1,)).item())\n","        x = torch.rot90(x, k, dims=[1,2])\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        wm = row[\"waferMap\"]  # numpy 2D\n","        x = torch.tensor(wm, dtype=torch.float32).unsqueeze(0)  # (1,H,W)\n","\n","        # 0/1/2 í˜•íƒœë©´ 0~1ë¡œ ìŠ¤ì¼€ì¼ (ì„ íƒ)\n","        mx = x.max()\n","        x = x / (mx if mx > 0 else 1.0)\n","\n","        # resize\n","        x = F.interpolate(x.unsqueeze(0), size=(self.resize, self.resize), mode=\"nearest\").squeeze(0)\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        # ResNet ì…ë ¥ ë§ì¶”ê¸°: 3ì±„ë„\n","        x = x.repeat(3, 1, 1)  # (3,resize,resize)\n","\n","        if self.class_to_idx is None:\n","            return x\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return x, y\n","\n","train_loader = DataLoader(WaferMapDataset(train_df, class_to_idx, True, 64),\n","                          batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(WaferMapDataset(val_df, class_to_idx, False, 64),\n","                        batch_size=256, shuffle=False, num_workers=2)\n","test_known_loader = DataLoader(WaferMapDataset(test_known_df, class_to_idx, False, 64),\n","                               batch_size=256, shuffle=False, num_workers=2)\n","test_unknown_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","print(\"\\nREADY âœ…\")\n","print(\" - known_classes(for 10.2):\", known_classes)\n","print(\" - known_classes_model(ckpt):\", known_classes_model)\n","print(\" - resize:\", RESIZE, \"| holdout:\", UNKNOWN_CLASSES)\n"],"metadata":{"id":"JBbSvXSOBr9u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. íŠ¸ë¦¬ì•„ì§€(MVP-2): ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ì‚¬ë¡€/ì‹œê°í™”"],"metadata":{"id":"HCR7aztMgr-T"}},{"cell_type":"markdown","source":["### 10.1 íŠ¸ë¦¬ì•„ì§€ìš© Dataset (ì´ë¯¸ì§€ + ë¼ë²¨ + row index)"],"metadata":{"id":"d0NANDMyhTAv"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import numpy as np\n","\n","class WaferMapDatasetWithIdx(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64):\n","        self.df = df.reset_index(drop=True).copy()\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = resize\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[2])  # ì¢Œìš°\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[1])  # ìƒí•˜\n","        k = int(torch.randint(0, 4, (1,)).item())\n","        x = torch.rot90(x, k, dims=[1,2])\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        wm = row[\"waferMap\"]\n","        x = torch.tensor(wm, dtype=torch.float32).unsqueeze(0)  # (1,H,W)\n","\n","        mx = x.max()\n","        x = x / (mx if mx > 0 else 1.0)\n","\n","        x = F.interpolate(x.unsqueeze(0), size=(self.resize, self.resize), mode=\"nearest\").squeeze(0)\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        x = x.repeat(3, 1, 1)  # (3,resize,resize)\n","\n","        # ë¼ë²¨ì´ ì—†ìœ¼ë©´ x, idxë§Œ\n","        if self.class_to_idx is None:\n","            return x, idx\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return x, y, idx"],"metadata":{"id":"QT6jB4HAgxcF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.2 ë ˆí¼ëŸ°ìŠ¤(known) í’€ ìƒ˜í”Œë§"],"metadata":{"id":"Z3szZwQwg3YH"}},{"cell_type":"code","source":["# âœ… ì¶”ì²œ: referenceì—ì„œëŠ” noneì„ ì¤„ì´ê±°ë‚˜ ì œì™¸\n","MAX_PER_CLASS = 1500\n","MAX_NONE = 2000\n","\n","ref_parts = []\n","for c in known_classes:\n","    sub = train_df[train_df[\"label\"] == c]\n","    if c == \"none\":\n","        sub = sub.sample(n=min(len(sub), MAX_NONE), random_state=42)\n","    else:\n","        sub = sub.sample(n=min(len(sub), MAX_PER_CLASS), random_state=42)\n","    ref_parts.append(sub)\n","\n","ref_df = pd.concat(ref_parts).sample(frac=1.0, random_state=42).reset_index(drop=True)\n","print(\"ref_df size:\", len(ref_df))\n","print(ref_df[\"label\"].value_counts().head())"],"metadata":{"id":"uN5aESipg6EC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.3 ì„ë² ë”© ì¶”ì¶œ ëª¨ë¸ (fc ì§ì „ íŠ¹ì§•)"],"metadata":{"id":"iKotJqQ8hmus"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# modelì€ ë„ˆê°€ í•™ìŠµí•œ ëª¨ë¸(ë˜ëŠ” loaded_model) ì‚¬ìš©\n","model = loaded_model if \"loaded_model\" in globals() else model\n","model = model.to(device).eval()\n","\n","# fc ì œê±° â†’ ì„ë² ë”© ì¶”ì¶œê¸°\n","embed_model = nn.Sequential(*list(model.children())[:-1]).to(device).eval()\n","\n","@torch.no_grad()\n","def collect_embeddings_ref(loader):\n","    embs, labels, idxs = [], [], []\n","    for x, y, idx in loader:\n","        x = x.to(device)\n","        e = embed_model(x).squeeze(-1).squeeze(-1)  # (N,512,1,1) -> (N,512)\n","        embs.append(e.cpu())\n","        labels.append(torch.tensor(y))\n","        idxs.append(torch.tensor(idx))\n","    return torch.cat(embs, 0).numpy(), torch.cat(labels, 0).numpy(), torch.cat(idxs, 0).numpy()\n","\n","@torch.no_grad()\n","def collect_embeddings_unknown(loader):\n","    embs, idxs = [], []\n","    for x, idx in loader:\n","        x = x.to(device)\n","        e = embed_model(x).squeeze(-1).squeeze(-1)\n","        embs.append(e.cpu())\n","        idxs.append(torch.tensor(idx))\n","    return torch.cat(embs, 0).numpy(), torch.cat(idxs, 0).numpy()"],"metadata":{"id":"0A6_865Nho8o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.4 ì„ë² ë”© ì¶”ì¶œ (ref/unknown)"],"metadata":{"id":"F4UgUGpBhruv"}},{"cell_type":"code","source":["# reference(known)\n","ref_loader = DataLoader(\n","    WaferMapDatasetWithIdx(ref_df, class_to_idx=class_to_idx, is_train=False, resize=64),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","# unknown(test_unknown_df)\n","unk_loader = DataLoader(\n","    WaferMapDatasetWithIdx(test_unknown_df, class_to_idx=None, is_train=False, resize=64),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","ref_emb, ref_y, ref_local_idx = collect_embeddings_ref(ref_loader)\n","unk_emb, unk_local_idx = collect_embeddings_unknown(unk_loader)\n","\n","print(\"ref_emb:\", ref_emb.shape, \"unk_emb:\", unk_emb.shape)"],"metadata":{"id":"wDpeeC4egy9s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.5 Unknown â†’ ìœ ì‚¬ì‚¬ë¡€ Top-K ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"],"metadata":{"id":"gyPJJR5Ci6bk"}},{"cell_type":"code","source":["import numpy as np\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","ref_n = l2norm(ref_emb)\n","unk_n = l2norm(unk_emb)\n","\n","# Top-K retrieval\n","K = 5\n","# (unk x ref) similarityê°€ ì»¤ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ unkë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬\n","def topk_retrieval(unk_n, ref_n, k=5, chunk=512):\n","    topk_idx_all, topk_sim_all = [], []\n","    ref_t = torch.tensor(ref_n, dtype=torch.float32)\n","    for i in range(0, len(unk_n), chunk):\n","        u = torch.tensor(unk_n[i:i+chunk], dtype=torch.float32)\n","        sim = u @ ref_t.T  # cosine similarity\n","        topk_sim, topk_idx = torch.topk(sim, k=k, dim=1)\n","        topk_idx_all.append(topk_idx.numpy())\n","        topk_sim_all.append(topk_sim.numpy())\n","    return np.vstack(topk_idx_all), np.vstack(topk_sim_all)\n","\n","topk_idx, topk_sim = topk_retrieval(unk_n, ref_n, k=K, chunk=512)\n","print(topk_idx.shape, topk_sim.shape)  # (num_unknown, K)"],"metadata":{"id":"DmoNPrpqhvA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.6 Top-K ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜"],"metadata":{"id":"l2AgTxlci--V"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def show_triage_case(unk_i, K=5):\n","    # unknown ìƒ˜í”Œ\n","    unk_row = test_unknown_df.iloc[int(unk_local_idx[unk_i])]\n","    unk_wm = unk_row[\"waferMap\"]\n","\n","    # ref ìƒ˜í”Œë“¤\n","    ref_indices = topk_idx[unk_i][:K]\n","    ref_sims = topk_sim[unk_i][:K]\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    # unknown\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_wm)\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rloc = int(ref_local_idx[ref_indices[j]])  # ref_dfì˜ ë¡œì»¬ ì¸ë±ìŠ¤\n","        rrow = ref_df.iloc[rloc]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={ref_sims[j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ì˜ˆì‹œë¡œ 3ê°œë§Œ ë³´ê¸°\n","for i in [0, 1, 2]:\n","    show_triage_case(i, K=5)"],"metadata":{"id":"5E5hzrmGi8tT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.7 2D ì‹œê°í™” (UMAP)"],"metadata":{"id":"mm2w_a0ejGSW"}},{"cell_type":"code","source":["!pip -q install umap-learn\n","\n","import umap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# ì‹œê°í™”ëŠ” ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë¦¬ë‹ˆ ìƒ˜í”Œë§\n","N_REF_VIS = min(5000, len(ref_emb))\n","N_UNK_VIS = min(2000, len(unk_emb))\n","\n","rng = np.random.RandomState(42)\n","ref_vis_idx = rng.choice(len(ref_emb), size=N_REF_VIS, replace=False)\n","unk_vis_idx = rng.choice(len(unk_emb), size=N_UNK_VIS, replace=False)\n","\n","X_vis = np.vstack([ref_emb[ref_vis_idx], unk_emb[unk_vis_idx]])\n","y_vis = np.concatenate([ref_y[ref_vis_idx], -1*np.ones(N_UNK_VIS, dtype=int)])  # unknown=-1\n","\n","reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n","Z = reducer.fit_transform(X_vis)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[:,0], Z[:,1], c=y_vis, s=6)  # ìƒ‰ì€ í´ë˜ìŠ¤ idë¡œ ìë™\n","plt.title(\"Embedding 2D (UMAP): known vs unknown\")\n","plt.show()"],"metadata":{"id":"A0_s_zQ9jDMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","print(\"known points:\", np.sum(y_vis != -1))\n","print(\"unknown points:\", np.sum(y_vis == -1))\n","print(\"unique labels (incl -1):\", np.unique(y_vis)[:20])"],"metadata":{"id":"IaJdjzCljI2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","known_mask = (y_vis != -1)\n","unk_mask = (y_vis == -1)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[known_mask,0], Z[known_mask,1], s=6, alpha=0.25, label=\"known\")\n","plt.scatter(Z[unk_mask,0],   Z[unk_mask,1],   s=8, alpha=0.9,  label=\"unknown\")\n","plt.title(\"Embedding 2D (UMAP): known (gray) vs unknown (red)\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"CW0Byy4Pjze8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import umap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","Xn = l2norm(X_vis)  # ì½”ì‚¬ì¸ì— ë§ê²Œ ì •ê·œí™”(ê¶Œì¥)\n","\n","reducer = umap.UMAP(metric=\"cosine\", n_neighbors=15, min_dist=0.1, random_state=42)\n","Z = reducer.fit_transform(Xn)\n","\n","known_mask = (y_vis != -1)\n","unk_mask = (y_vis == -1)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[known_mask,0], Z[known_mask,1], s=6, alpha=0.25, color=\"gray\", label=\"known\")\n","plt.scatter(Z[unk_mask,0],   Z[unk_mask,1],   s=10, alpha=0.9,  color=\"red\",  label=\"unknown\")\n","plt.title(\"Embedding 2D (UMAP-cosine): known (gray) vs unknown (red)\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"FE-r0fP0j1FG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.8 Top-K íŠ¸ë¦¬ì•„ì§€ ë°ëª¨"],"metadata":{"id":"OhBoRb5SvPTy"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","ref_n = l2norm(ref_emb).astype(np.float32)\n","unk_n = l2norm(unk_emb).astype(np.float32)\n","\n","def topk_retrieval(unk_n, ref_n, k=5, chunk=512):\n","    topk_idx_all, topk_sim_all = [], []\n","    ref_t = torch.tensor(ref_n)  # (Nref, D)\n","    for i in range(0, len(unk_n), chunk):\n","        u = torch.tensor(unk_n[i:i+chunk])   # (chunk, D)\n","        sim = u @ ref_t.T                    # (chunk, Nref)\n","        topk_sim, topk_idx = torch.topk(sim, k=k, dim=1)\n","        topk_idx_all.append(topk_idx.numpy())\n","        topk_sim_all.append(topk_sim.numpy())\n","    return np.vstack(topk_idx_all), np.vstack(topk_sim_all)\n","\n","K = 5\n","topk_idx, topk_sim = topk_retrieval(unk_n, ref_n, k=K, chunk=512)\n","print(topk_idx.shape, topk_sim.shape)  # (N_unknown, K)"],"metadata":{"id":"kPPPgafAj29L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.9 íŠ¸ë¦¬ì•„ì§€ ìš”ì•½ í•œ ì¤„ (ë°œí‘œìš©)"],"metadata":{"id":"YlMhv_dPxAEF"}},{"cell_type":"code","source":["from collections import Counter\n","import numpy as np\n","\n","def triage_summary(unk_i, K=5):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[unk_i][:K]]\n","    cnt = Counter(labels)\n","    top_label, top_count = cnt.most_common(1)[0]\n","    purity = top_count / K\n","    uniq = len(cnt)\n","\n","    if purity >= 0.8:\n","        msg = f\"Top-{K} ì¤‘ {top_label} {top_count}/{K} â†’ '{top_label}' ê³„ì—´ ê°€ëŠ¥ì„± ë†’ìŒ\"\n","    elif uniq >= 4:\n","        msg = f\"Top-{K} ë¼ë²¨ ë‹¤ì–‘({dict(cnt)}) â†’ ì• ë§¤ ì¼€ì´ìŠ¤(ì¶”ê°€ í™•ì¸/ì¬ì¸¡ì • ê¶Œì¥)\"\n","    else:\n","        msg = f\"Top-{K} í˜¼ì¬({dict(cnt)}) â†’ ìœ ì‚¬ íŒ¨í„´ í›„ë³´ ë³µìˆ˜\"\n","    return labels, msg"],"metadata":{"id":"30ZX_CKQwCId"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.10 ë°ëª¨ í™”ë©´ ì¶œë ¥ (Unknown + Top-K)"],"metadata":{"id":"U5Si9noixFRq"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def show_triage_case(unk_i, K=5):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    unk_wm = unk_row[\"waferMap\"]\n","\n","    labels, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_wm)\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(msg, y=1.05, fontsize=12)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ì˜ˆì‹œ 3ê°œ í™•ì¸\n","for i in [0, 1, 2]:\n","    show_triage_case(i, K=5)"],"metadata":{"id":"xH8AG1o9xDHn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.11 ë°ëª¨ ê²°ê³¼ ì €ì¥ (ì´ë¯¸ì§€/ìš”ì•½)"],"metadata":{"id":"AJN79lGpxORR"}},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt\n","\n","OUT_DIR = \"assets/triage\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def save_triage_case(unk_i, K=5):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    labels, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(msg, y=1.05, fontsize=12)\n","    plt.tight_layout()\n","\n","    fname = f\"triage_unk{unk_i:04d}_true-{unk_row['label']}.png\"\n","    path = os.path.join(OUT_DIR, fname)\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path, msg\n","\n","# 6ê°œë§Œ ì €ì¥\n","picked = [0, 1, 2, 3, 4, 5]\n","for i in picked:\n","    p, m = save_triage_case(i, K=5)\n","    print(p, \"|\", m)"],"metadata":{"id":"t_u-292hxH8H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.12 (ì„ íƒ) OOD ì ìˆ˜ë¡œ ë°ëª¨ í›„ë³´ ìë™ ì„ ë³„\n","\n","ì´ë¯¸ unknownì— ëŒ€í•œ MSP/Energy ë°°ì—´ì„ ê°–ê³  ìˆìœ¼ë©´ ì´ ì…€ì€ ê±´ë„ˆë›°ì–´ë„ ë¨."],"metadata":{"id":"_TslrDbfyisd"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","# ì „ì œ: model(or loaded_model), device, test_unknown_df, WaferMapDataset(í˜¹ì€ ë„ˆê°€ ì“°ëŠ” Dataset)ì´ ì¡´ì¬\n","model_use = loaded_model if \"loaded_model\" in globals() else model_use if \"model_use\" in globals() else model\n","model_use = model_use.to(device).eval()\n","\n","# unknown loader (ìˆœì„œ ë³´ì¡´ ìœ„í•´ shuffle=False)\n","unk_score_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","@torch.no_grad()\n","def compute_msp_energy(model, loader):\n","    msps = []\n","    energy_raw = []  # Energy = -logsumexp(logits). OODì¼ìˆ˜ë¡ ê°’ì´ ëœ ìŒìˆ˜(=ë” í¼)ë¡œ ê°€ëŠ” ê²½í–¥\n","    for batch in loader:\n","        # loaderê°€ xë§Œ ì£¼ëŠ” ê²½ìš° / (x,idx) ì£¼ëŠ” ê²½ìš°ë¥¼ ëª¨ë‘ ì²˜ë¦¬\n","        x = batch[0] if isinstance(batch, (list, tuple)) else batch\n","        x = x.to(device)\n","        logits = model(x)\n","\n","        prob = F.softmax(logits, dim=1)\n","        msp = prob.max(dim=1).values\n","\n","        e = -torch.logsumexp(logits, dim=1)  # energy_raw\n","        msps.append(msp.cpu().numpy())\n","        energy_raw.append(e.cpu().numpy())\n","\n","    msps = np.concatenate(msps)\n","    energy_raw = np.concatenate(energy_raw)\n","    return msps, energy_raw\n","\n","msp_u, energy_u = compute_msp_energy(model_use, unk_score_loader)\n","print(\"scores:\", msp_u.shape, energy_u.shape, \"len(df)=\", len(test_unknown_df))"],"metadata":{"id":"g62OkjfeyEGE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.13 ë°ëª¨ í›„ë³´ ìë™ ì„ íƒ ê¸°ì¤€\n","\n","*   (A) unknownìŠ¤ëŸ¬ìš´ ìƒ˜í”Œ: MSP ë‚®ê³ , Energy_rawëŠ” í°(ëœ ìŒìˆ˜) ìƒ˜í”Œ\n","*   (B) ìœ„í—˜ ìƒ˜í”Œ(ê³¼ì‹ ): MSP ë†’ì€ë°ë„ ì‹¤ì œë¡  unknownì¸ ìƒ˜í”Œ (ê³¼ì‹  ì˜¤ë¶„ë¥˜ ìœ„í—˜ ê°•ì¡°ìš©)"],"metadata":{"id":"g18vtuw_yU3o"}},{"cell_type":"code","source":["N_DEMO = 8  # ì €ì¥í•  ì¼€ì´ìŠ¤ ê°œìˆ˜\n","\n","# A) unknown-likely: MSP ë‚®ì€ ìˆœ + Energy_raw í° ìˆœì„ rankë¡œ í•©ì¹¨\n","rank_msp = np.argsort(msp_u)                 # ë‚®ì„ìˆ˜ë¡ unknown\n","rank_e   = np.argsort(-energy_u)             # í´ìˆ˜ë¡ unknown (ëœ ìŒìˆ˜)\n","rank_sum = np.empty_like(rank_msp)\n","rank_sum[rank_msp] = np.arange(len(rank_msp))\n","rank_sum += np.arange(len(rank_e))[np.argsort(rank_e)]  # ê°„ë‹¨ í•©ì‚°\n","\n","demo_unknownlike = np.argsort(rank_sum)[:N_DEMO]\n","\n","# B) overconfident unknown: MSP ë†’ì€ ìˆœ\n","demo_overconf = np.argsort(-msp_u)[:min(N_DEMO, 5)]\n","\n","print(\"demo_unknownlike:\", demo_unknownlike)\n","print(\"demo_overconf:\", demo_overconf)"],"metadata":{"id":"AyPv3fdjxQl0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.14 íŠ¸ë¦¬ì•„ì§€ ê²°ê³¼ ì €ì¥ (ê·¸ë¦¼ + CSV ìš”ì•½)"],"metadata":{"id":"hcSKfSHdyRS_"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","OUT_DIR = \"assets/triage\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def triage_summary(unk_i, K=5):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[unk_i][:K]]\n","    cnt = Counter(labels)\n","    top_label, top_count = cnt.most_common(1)[0]\n","    purity = top_count / K\n","    uniq = len(cnt)\n","\n","    if purity >= 0.8:\n","        msg = f\"Top-{K}: {top_label} {top_count}/{K} â†’ '{top_label}' ê³„ì—´ ê°€ëŠ¥ì„± ë†’ìŒ\"\n","    elif uniq >= 4:\n","        msg = f\"Top-{K} ë¼ë²¨ ë‹¤ì–‘({dict(cnt)}) â†’ ì• ë§¤ ì¼€ì´ìŠ¤(ì¶”ê°€ í™•ì¸/ì¬ì¸¡ì • ê¶Œì¥)\"\n","    else:\n","        msg = f\"Top-{K} í˜¼ì¬({dict(cnt)}) â†’ í›„ë³´ ë³µìˆ˜\"\n","    return labels, purity, msg\n","\n","def save_triage_case(unk_i, K=5, extra_note=\"\"):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    labels, purity, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    title = msg + (f\" | {extra_note}\" if extra_note else \"\")\n","    plt.suptitle(title, y=1.05, fontsize=11)\n","    plt.tight_layout()\n","\n","    fname = f\"triage_unk{unk_i:04d}_true-{unk_row['label']}.png\"\n","    path = os.path.join(OUT_DIR, fname)\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","\n","    return {\n","        \"unk_i\": int(unk_i),\n","        \"true_label\": unk_row[\"label\"],\n","        \"topk_labels\": \"|\".join(labels),\n","        \"purity\": float(purity),\n","        \"note\": title,\n","        \"img_path\": path\n","    }\n","\n","def save_demo_set(indices, tag, K=5):\n","    rows = []\n","    for i in indices:\n","        extra = f\"{tag}\"\n","        rows.append(save_triage_case(int(i), K=K, extra_note=extra))\n","    return rows\n","\n","# demo_unknownlike / demo_overconfê°€ ì—†ìœ¼ë©´(ìœ„ ì…€ ìŠ¤í‚µí–ˆìœ¼ë©´) ì§ì ‘ indicesë¥¼ ë„£ì–´ë„ ë¨\n","K = 5\n","rows_all = []\n","if \"demo_unknownlike\" in globals():\n","    rows_all += save_demo_set(demo_unknownlike, \"OOD-unknownlike\", K=K)\n","if \"demo_overconf\" in globals():\n","    rows_all += save_demo_set(demo_overconf, \"OOD-overconfident\", K=K)\n","\n","df_sum = pd.DataFrame(rows_all)\n","\n","# OOD ì ìˆ˜ë„ ê°™ì´ ì €ì¥(ìˆìœ¼ë©´)\n","if \"msp_u\" in globals():\n","    df_sum[\"msp\"] = df_sum[\"unk_i\"].apply(lambda i: float(msp_u[i]))\n","if \"energy_u\" in globals():\n","    df_sum[\"energy_raw\"] = df_sum[\"unk_i\"].apply(lambda i: float(energy_u[i]))\n","\n","csv_path = os.path.join(OUT_DIR, \"triage_summary.csv\")\n","df_sum.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","\n","print(\"âœ… saved images to:\", OUT_DIR)\n","print(\"âœ… saved summary csv:\", csv_path)\n","df_sum.head()"],"metadata":{"id":"5FFJXSmvyCJk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.15 Unknown â†’ Unknown ìœ ì‚¬ì‚¬ë¡€ Top-K (Nearest Neighbors)\n","\n","ì§€ê¸ˆê¹Œì§€ëŠ” **Unknown â†’ Known(ë ˆí¼ëŸ°ìŠ¤) Top-K**ë¡œ,\n","Unknownì´ â€œê¸°ì¡´ì— ì•Œë ¤ì§„ ê²°í•¨ ì¤‘ ë¬´ì—‡ê³¼ ë¹„ìŠ·í•œì§€â€ë¥¼ ë³´ì—¬ì£¼ëŠ” íŠ¸ë¦¬ì•„ì§€ì˜€ìŠµë‹ˆë‹¤.\n","\n","ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” **Unknownë¼ë¦¬(Unknown â†’ Unknown) ìœ ì‚¬ì‚¬ë¡€ Top-K**ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n","\n","- ëª©ì : unknownì´ â€œ1íšŒì„±â€ì¸ì§€, â€œë¹„ìŠ·í•œ íŒ¨í„´ì´ ë°˜ë³µ(ì¬ë°œ)ë˜ëŠ”ì§€â€ ë¹ ë¥´ê²Œ í™•ì¸\n","- ì…ë ¥: `unk_emb`, `test_unknown_df`\n","- ì¶œë ¥: query unknown 1ì¥ + ê°€ì¥ ìœ ì‚¬í•œ unknown Kì¥(ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\n","\n","> ì‹œì—°/ì‘í’ˆ í†¤ì„ ì‚´ë¦¬ë ¤ë©´ `true label` í‘œì‹œëŠ” ìˆ¨ê¸°ê³ (ì˜µì…˜), ëª¨ì–‘ ê¸°ë°˜ìœ¼ë¡œë§Œ íŒë‹¨í•˜ê²Œ êµ¬ì„±í•©ë‹ˆë‹¤."],"metadata":{"id":"ibqI3wqYa-Rc"}},{"cell_type":"markdown","source":["#### 10.15.1 unknown â†’ unknown â€œê°€ì¥ ë¹„ìŠ·í•œ ìƒ˜í”Œ Top-Kâ€ (Nearest Neighbors)"],"metadata":{"id":"DHdKbQL5bS-l"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import NearestNeighbors\n","import os\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","unk_n = l2norm(unk_emb).astype(np.float32)\n","\n","# cosine distance ê¸°ë°˜ ìµœê·¼ì ‘ ì´ì›ƒ\n","K_NN = 6  # ìê¸° ìì‹  í¬í•¨í•´ì„œ 6ê°œ -> ë‚˜ì¤‘ì— self ì œì™¸í•˜ë©´ 5ê°œ\n","nn = NearestNeighbors(n_neighbors=K_NN, metric=\"cosine\")\n","nn.fit(unk_n)\n","\n","dist, idx = nn.kneighbors(unk_n)  # dist ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬(ê°€ê¹Œì›€), idx: (N_unk, K_NN)\n","# cosine similarityë¡œ ë³´ê³  ì‹¶ìœ¼ë©´ sim = 1 - dist\n","sim = 1.0 - dist\n","\n","print(\"idx shape:\", idx.shape, \"sim shape:\", sim.shape)\n"],"metadata":{"id":"O4FKWKWybGqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.15.2 unknown ìœ ì‚¬ì‚¬ë¡€ í™”ë©´ ì¶œë ¥\n","\n","ë°œí‘œ/ë°ëª¨ì—ì„  show_true_label=Falseë¡œ ìˆ¨ê¸°ë©´ â€œì§„ì§œ unknown íŠ¸ë¦¬ì•„ì§€â€ ëŠë‚Œì´ ë” ì‚´ìŒ"],"metadata":{"id":"SQJgI_3hb8y7"}},{"cell_type":"code","source":["def show_unknown_neighbors(unk_i, K_show=5, show_true_label=True):\n","    # ì²« ë²ˆì§¸ ì´ì›ƒì€ ìê¸° ìì‹ ì¼ ê°€ëŠ¥ì„±ì´ í¼ -> ì œì™¸\n","    neigh = idx[unk_i]\n","    neigh_sim = sim[unk_i]\n","\n","    # self ì œì™¸(ë™ì¼ ì¸ë±ìŠ¤)\n","    pairs = [(j, s) for j, s in zip(neigh, neigh_sim) if j != unk_i]\n","    pairs = pairs[:K_show]\n","\n","    plt.figure(figsize=(3*(K_show+1), 3))\n","    row = test_unknown_df.iloc[unk_i]\n","    plt.subplot(1, K_show+1, 1)\n","    plt.imshow(row[\"waferMap\"])\n","    title = \"UNKNOWN(query)\"\n","    if show_true_label and \"label\" in row:\n","        title += f\"\\n(true={row['label']})\"\n","    plt.title(title)\n","    plt.axis(\"off\")\n","\n","    for t, (j, s) in enumerate(pairs):\n","        r = test_unknown_df.iloc[int(j)]\n","        plt.subplot(1, K_show+1, t+2)\n","        plt.imshow(r[\"waferMap\"])\n","        title = f\"unk#{int(j)}\\ncos={float(s):.3f}\"\n","        if show_true_label and \"label\" in r:\n","            title += f\"\\n(true={r['label']})\"\n","        plt.title(title)\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ì˜ˆì‹œ\n","for i in [0, 1, 2]:\n","    show_unknown_neighbors(i, K_show=5, show_true_label=True)\n"],"metadata":{"id":"kU07-RWJyKj2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.15.3 unknown í´ëŸ¬ìŠ¤í„°ë§ (DBSCAN: â€œë¹„ìŠ·í•œ ì• ë“¤ë¼ë¦¬ ìë™ ê·¸ë£¹í•‘â€)\n","\n","KMeansëŠ” â€œêµ°ì§‘ ê°œìˆ˜ Kë¥¼ ë¯¸ë¦¬ ì •í•´ì•¼â€ í•´ì„œ MVP-2ì—ëŠ” ëœ ì§ê´€ì ì´ê³ ,  \n","DBSCANì€ â€œë°€ë„ ê¸°ë°˜â€ì´ë¼ ì‹ ê·œ íŒ¨í„´ í›„ë³´êµ° ë§Œë“¤ ë•Œ ìŠ¤í† ë¦¬ê°€ ì¢‹ìŒ."],"metadata":{"id":"SqI8qHnBcHlj"}},{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","from collections import Counter\n","\n","# cosine distance ê¸°ì¤€ epsëŠ” ë°ì´í„°ë§ˆë‹¤ ë‹¬ë¼ì„œ 0.15~0.35 ì •ë„ë¥¼ ë¨¼ì € ì‹œë„\n","eps = 0.25\n","min_samples = 10\n","\n","db = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\")\n","unk_cluster = db.fit_predict(unk_n)  # -1ì€ noise(ì–´ëŠ êµ°ì§‘ì—ë„ ì•ˆ ë“¤ì–´ê°)\n","\n","cnt = Counter(unk_cluster)\n","print(\"cluster counts:\", cnt)\n","print(\"num clusters (excluding -1):\", len([k for k in cnt.keys() if k != -1]))"],"metadata":{"id":"CYjGt1wycnzO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["epsë¥¼ 3ê°œë§Œ ë¹ ë¥´ê²Œ ìŠ¤ìœ•í•´ì„œ â€œë„ˆë¬´ ë‹¤ -1â€ì¸ì§€ í™•ì¸"],"metadata":{"id":"hpWwZXTgcrSi"}},{"cell_type":"code","source":["for eps_try in [0.20, 0.25, 0.30]:\n","    db = DBSCAN(eps=eps_try, min_samples=min_samples, metric=\"cosine\")\n","    cl = db.fit_predict(unk_n)\n","    c = Counter(cl)\n","    ncl = len([k for k in c.keys() if k != -1])\n","    print(f\"eps={eps_try:.2f} | clusters={ncl} | noise={c.get(-1,0)} / {len(cl)}\")"],"metadata":{"id":"ZQ6pxL8tcBPs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.15.4 êµ°ì§‘ë³„ ëŒ€í‘œ ìƒ˜í”Œ + ìœ ì‚¬ ìƒ˜í”Œ ì €ì¥(í¬ìŠ¤í„°/ìŠ¬ë¼ì´ë“œ ë°”ë¡œ ì‚¬ìš©)"],"metadata":{"id":"5STsHzLQcvfy"}},{"cell_type":"markdown","source":["êµ°ì§‘ ëŒ€í‘œ(centroidì— ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œ) ì°¾ê¸°"],"metadata":{"id":"uGAtgS-Yc1R8"}},{"cell_type":"code","source":["import numpy as np\n","\n","def cluster_representatives(emb, cluster_ids):\n","    reps = {}\n","    for cid in sorted(set(cluster_ids)):\n","        if cid == -1:\n","            continue\n","        members = np.where(cluster_ids == cid)[0]\n","        if len(members) == 0:\n","            continue\n","        # centroid\n","        c = emb[members].mean(axis=0, keepdims=True)\n","        c = l2norm(c)[0]\n","        # centroidì™€ cosine similarity ìµœëŒ€ì¸ ìƒ˜í”Œ\n","        sims = emb[members] @ c\n","        rep = members[np.argmax(sims)]\n","        reps[cid] = int(rep)\n","    return reps\n","\n","reps = cluster_representatives(unk_n, unk_cluster)\n","print(\"representatives:\", reps)"],"metadata":{"id":"K1GOx7EWctms"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["êµ°ì§‘ ëŒ€í‘œ + ê°™ì€ êµ°ì§‘ Top-K ì´ì›ƒì„ í•œ ì¥ìœ¼ë¡œ ì €ì¥"],"metadata":{"id":"iDD7MaT2c7ee"}},{"cell_type":"code","source":["OUT_DIR = \"assets/triage_unknown\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def save_cluster_panel(cid, rep_i, K_show=5, show_true_label=True):\n","    # rep_iì˜ ì´ì›ƒ ì¤‘ ê°™ì€ êµ°ì§‘ë§Œ ì¶”ë¦¼\n","    neigh = idx[rep_i]\n","    neigh_sim = sim[rep_i]\n","    pairs = []\n","    for j, s in zip(neigh, neigh_sim):\n","        j = int(j)\n","        if j == rep_i:\n","            continue\n","        if unk_cluster[j] == cid:\n","            pairs.append((j, float(s)))\n","        if len(pairs) >= K_show:\n","            break\n","\n","    plt.figure(figsize=(3*(K_show+1), 3))\n","    rep_row = test_unknown_df.iloc[rep_i]\n","    plt.subplot(1, K_show+1, 1)\n","    plt.imshow(rep_row[\"waferMap\"])\n","    title = f\"cluster {cid}\\nrep unk#{rep_i}\"\n","    if show_true_label and \"label\" in rep_row:\n","        title += f\"\\n(true={rep_row['label']})\"\n","    plt.title(title)\n","    plt.axis(\"off\")\n","\n","    for t, (j, s) in enumerate(pairs):\n","        r = test_unknown_df.iloc[j]\n","        plt.subplot(1, K_show+1, t+2)\n","        plt.imshow(r[\"waferMap\"])\n","        title = f\"unk#{j}\\ncos={s:.3f}\"\n","        if show_true_label and \"label\" in r:\n","            title += f\"\\n(true={r['label']})\"\n","        plt.title(title)\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    path = os.path.join(OUT_DIR, f\"unknown_cluster{cid}_rep{rep_i}.png\")\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path\n","\n","saved = []\n","for cid, rep_i in list(reps.items())[:8]:  # ìµœëŒ€ 8ê°œ êµ°ì§‘ë§Œ ì €ì¥(ì¡°ì ˆ ê°€ëŠ¥)\n","    saved.append(save_cluster_panel(cid, rep_i, K_show=5, show_true_label=True))\n","\n","print(\"saved:\", len(saved), \"files in\", OUT_DIR)"],"metadata":{"id":"EPPTK7cIc3bU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ìš”ì•½ CSV ì €ì¥ (êµ°ì§‘ í¬ê¸°/ëŒ€í‘œ/ë¼ë²¨ ë¶„í¬)"],"metadata":{"id":"u8usA4CRdCGE"}},{"cell_type":"code","source":["import pandas as pd\n","from collections import Counter\n","\n","rows = []\n","for cid in sorted(set(unk_cluster)):\n","    members = np.where(unk_cluster == cid)[0]\n","    if len(members) == 0:\n","        continue\n","    row = {\"cluster_id\": int(cid), \"count\": int(len(members))}\n","    if cid != -1 and cid in reps:\n","        row[\"rep_unk_i\"] = reps[cid]\n","    # ê°œë°œ ì¤‘ì—ëŠ” true label ë¶„í¬ë„ ê°™ì´ ê¸°ë¡(ìµœì¢… ë°ëª¨ì—ì„  ìˆ¨ê²¨ë„ ë¨)\n","    if \"label\" in test_unknown_df.columns:\n","        labels = test_unknown_df.iloc[members][\"label\"].tolist()\n","        row[\"label_dist\"] = dict(Counter(labels))\n","    rows.append(row)\n","\n","df_cl = pd.DataFrame(rows).sort_values([\"cluster_id\"])\n","csv_path = os.path.join(OUT_DIR, \"unknown_clusters_summary.csv\")\n","df_cl.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","csv_path, df_cl.head()"],"metadata":{"id":"68z-9mhVc9wU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 10.16 Top-K ê¸°ë°˜ â€˜í›„ë³´êµ°â€™ í´ëŸ¬ìŠ¤í„°ë§"],"metadata":{"id":"moWsMIhSe9yJ"}},{"cell_type":"markdown","source":["#### 10.16.1 unknownì„ â€œTop-K ë¼ë²¨ ë¶„í¬ ë²¡í„°â€ë¡œ ë³€í™˜\n","\n","ì˜ˆ: known í´ë˜ìŠ¤ê°€ 7ê°œë©´ unknown í•˜ë‚˜ë¥¼ 7ì°¨ì› ë²¡í„°ë¡œ ë§Œë“¦\n","(Top-Kì—ì„œ Locê°€ 3ê°œë©´ Loc ì°¨ì›ì— 3/5 ê°™ì€ ê°’)"],"metadata":{"id":"mD7zERNkfebY"}},{"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","\n","known_labels = sorted(ref_df[\"label\"].unique())\n","label_to_j = {c:j for j,c in enumerate(known_labels)}\n","K = topk_idx.shape[1]\n","\n","def topk_label_vector(i):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[i]]\n","    cnt = Counter(labels)\n","    v = np.zeros(len(known_labels), dtype=np.float32)\n","    for lab, n in cnt.items():\n","        v[label_to_j[lab]] = n / K\n","    return v, cnt, labels\n","\n","X_triage = np.stack([topk_label_vector(i)[0] for i in range(len(test_unknown_df))], axis=0)\n","print(\"X_triage shape:\", X_triage.shape)  # (N_unknown, num_known_classes)"],"metadata":{"id":"-EXBGtu0dEWF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.16.2 KMeansë¡œ â€œTop-K íŒ¨í„´ ê·¸ë£¹â€ ë§Œë“¤ê¸°"],"metadata":{"id":"UrJej2k8fNWl"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from collections import Counter\n","\n","n_clusters = 6\n","km = KMeans(n_clusters=n_clusters, random_state=42, n_init=\"auto\")\n","triage_cluster = km.fit_predict(X_triage)\n","\n","print(\"cluster counts:\", Counter(triage_cluster))"],"metadata":{"id":"S8HnxjQNfKX9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.16.3 êµ°ì§‘ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë§ë¡œ ìš”ì•½"],"metadata":{"id":"qoxS4cwNfXiT"}},{"cell_type":"markdown","source":["ê° êµ°ì§‘ì—ì„œ â€œTop-Kê°€ ì£¼ë¡œ ì–´ëŠ ë¼ë²¨ë¡œ ì ë¦¬ëŠ”ì§€â€ë¥¼ ìš”ì•½í•´ì¤Œ.\n","\n","ì˜ˆì‹œ ì¶œë ¥ í•´ì„:  \n","Loc 0.62, Edge-Loc 0.21 â€¦  \n","â†’ â€œì´ ê·¸ë£¹ì€ Top-Kê°€ Loc ìª½ìœ¼ë¡œ ê°•í•˜ê²Œ ëª°ë¦¼â€"],"metadata":{"id":"ElUUu2s8fpHI"}},{"cell_type":"code","source":["def summarize_cluster(cid, topn=3):\n","    members = np.where(triage_cluster == cid)[0]\n","    mean_v = X_triage[members].mean(axis=0)  # í‰ê·  ë¶„í¬\n","    top = mean_v.argsort()[::-1][:topn]\n","    return [(known_labels[j], float(mean_v[j])) for j in top], len(members)\n","\n","for cid in range(n_clusters):\n","    top, n = summarize_cluster(cid, topn=3)\n","    print(f\"[cluster {cid}] n={n} | top:\", top)"],"metadata":{"id":"3DgtLWF-fVKs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.16.4 êµ°ì§‘ ëŒ€í‘œ unknown ë½‘ê³ , â€œTop-K íŒ¨ë„â€ ìë™ ì €ì¥\n","ëŒ€í‘œëŠ” â€œêµ°ì§‘ í‰ê·  ë¶„í¬(mean_v)ì™€ ê°€ì¥ ê°€ê¹Œìš´ unknownâ€ìœ¼ë¡œ ì„ íƒ."],"metadata":{"id":"2Tt4OofBf1K2"}},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt\n","\n","OUT_DIR = \"assets/triage_clusters\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def pick_representative(cid):\n","    members = np.where(triage_cluster == cid)[0]\n","    mean_v = X_triage[members].mean(axis=0, keepdims=True)\n","    # cosine similarityë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë©¤ë²„ ì„ íƒ\n","    A = members\n","    num = (X_triage[A] @ mean_v.T).squeeze()\n","    den = (np.linalg.norm(X_triage[A], axis=1) * np.linalg.norm(mean_v) + 1e-12)\n","    cos = num / den\n","    return int(A[np.argmax(cos)])\n","\n","def save_topk_panel(unk_i, K=5, title_prefix=\"\"):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(title_prefix, y=1.05, fontsize=11)\n","    plt.tight_layout()\n","    path = os.path.join(OUT_DIR, f\"clusterPanel_unk{unk_i:04d}.png\")\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path\n","\n","saved = []\n","for cid in range(n_clusters):\n","    rep = pick_representative(cid)\n","    top, n = summarize_cluster(cid, topn=3)\n","    title = f\"Cluster {cid} (n={n}) | top={top}\"\n","    saved.append(save_topk_panel(rep, K=K, title_prefix=title))\n","\n","print(\"saved panels:\", len(saved), \"in\", OUT_DIR)"],"metadata":{"id":"M85DNdknfuk0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10.16.5 ìš”ì•½ CSV ì €ì¥"],"metadata":{"id":"19pCtx9Rf8rD"}},{"cell_type":"code","source":["import pandas as pd\n","from collections import Counter\n","\n","rows = []\n","for cid in range(n_clusters):\n","    members = np.where(triage_cluster == cid)[0]\n","    rep = pick_representative(cid)\n","    top, n = summarize_cluster(cid, topn=5)\n","    rows.append({\n","        \"cluster_id\": cid,\n","        \"count\": n,\n","        \"rep_unk_i\": rep,\n","        \"top_known_mix\": top\n","    })\n","\n","df_clusters = pd.DataFrame(rows)\n","csv_path = os.path.join(OUT_DIR, \"triage_clusters_summary.csv\")\n","df_clusters.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","csv_path, df_clusters"],"metadata":{"id":"jEutiU9wf6kN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k5lrsRQUgBK0"},"execution_count":null,"outputs":[]}]}