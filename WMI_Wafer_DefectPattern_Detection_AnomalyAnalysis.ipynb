{"cells":[{"cell_type":"markdown","metadata":{"id":"UIqvq9cFUjPb"},"source":["# Open-set Wafer Map Triage (WM-811K)\n","\n","- **MVP-1(완료)**: Known 분류 + OOD(Unknown 탐지, MSP/Energy) 평가  \n","- **MVP-2(진행중)**: 트리아지(UMAP 시각화 + Top-K 유사사례 검색)\n","\n","> 핵심: Unknown을 “Unknown”으로 거부(reject)하고, 이후 판단을 돕는 트리아지 워크플로우"]},{"cell_type":"markdown","metadata":{"id":"ETatusOj_t7G"},"source":["## 0. 환경 설정\n","- Google Drive 마운트, 경로/시드 설정"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41100,"status":"ok","timestamp":1768026122659,"user":{"displayName":"Myunggyun Choi (think_virus)","userId":"16622592930277680639"},"user_tz":-540},"id":"Jr1KElMF_th2","outputId":"2018c410-e4d1-4c40-e2e1-e17b70173a27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","source":["모델 저장 및 로드를 위해 미리 선언하는 셀"],"metadata":{"id":"l4N5Tpyy68w7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0372b366"},"outputs":[],"source":["import os, json\n","from datetime import datetime\n","import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","RANDOM_STATE = 42\n","CKPT_DIR = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/checkpoints\"\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","def _safe(s: str) -> str:\n","    return (\n","        str(s).replace(\" \", \"\")\n","        .replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n","        .replace(\",\", \"-\").replace(\"[\", \"\").replace(\"]\", \"\")\n","        .replace(\"'\", \"\").replace('\"', \"\")\n","    )\n","\n","def _infer_in_chans_from_state_dict(sd):\n","    if \"conv1.weight\" in sd:\n","        return int(sd[\"conv1.weight\"].shape[1])\n","    return 3\n","\n","def _infer_input_mode(in_chans: int):\n","    if in_chans == 4:\n","        return \"coords4\"\n","    if in_chans == 3:\n","        return \"repeat3\"\n","    return f\"in{in_chans}\"\n","\n","def build_resnet18(num_classes: int, in_chans: int = 3):\n","    model = models.resnet18(weights=None)\n","    if in_chans != 3:\n","        model.conv1 = nn.Conv2d(in_chans, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    return model\n","\n","def save_mvp_checkpoint(\n","    model,\n","    class_to_idx,\n","    unknown_classes,\n","    resize=64,\n","    arch=\"resnet18\",\n","    optimizer=None,\n","    metrics=None,\n","    tag=None,\n","    extra=None,\n","):\n","    in_chans = int(model.conv1.in_channels) if hasattr(model, \"conv1\") else None\n","    input_mode = _infer_input_mode(in_chans if in_chans is not None else 3)\n","\n","    ckpt = {\n","        \"arch\": arch,\n","        \"resize\": int(resize),\n","        \"unknown_classes\": list(unknown_classes),\n","        \"class_to_idx\": dict(class_to_idx),\n","        \"model_in_chans\": in_chans,\n","        \"input_mode\": input_mode,\n","        \"metrics\": metrics or {},\n","        \"extra\": extra or {},\n","        \"model_state_dict\": model.state_dict(),\n","    }\n","    if optimizer is not None:\n","        ckpt[\"optimizer_state_dict\"] = optimizer.state_dict()\n","\n","    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    tag_s = _safe(tag) if tag else \"ckpt\"\n","    fname = f\"{ts}_{arch}_R{resize}_{input_mode}_K{len(class_to_idx)}_{tag_s}.pt\"\n","    path = os.path.join(CKPT_DIR, fname)\n","    torch.save(ckpt, path)\n","    print(\"✅ Saved:\", path)\n","    return path\n","\n","def load_mvp_checkpoint_auto(path, device=\"cpu\", strict=False):\n","    ckpt = torch.load(path, map_location=device)\n","\n","    class_to_idx = ckpt[\"class_to_idx\"]\n","    known_classes = [None] * len(class_to_idx)\n","    for cls, idx in class_to_idx.items():\n","        known_classes[idx] = cls\n","\n","    sd = ckpt[\"model_state_dict\"]\n","    in_chans = ckpt.get(\"model_in_chans\")\n","    if in_chans is None:\n","        in_chans = _infer_in_chans_from_state_dict(sd)\n","\n","    input_mode = ckpt.get(\"input_mode\") or _infer_input_mode(in_chans)\n","    resize = int(ckpt.get(\"resize\", 64))\n","\n","    arch = ckpt.get(\"arch\", \"resnet18\")\n","    if arch != \"resnet18\":\n","        raise ValueError(f\"Unsupported arch: {arch}\")\n","\n","    model = build_resnet18(num_classes=len(known_classes), in_chans=in_chans)\n","    missing, unexpected = model.load_state_dict(sd, strict=strict)\n","\n","    model = model.to(device).eval()\n","\n","    cfg = {\n","        \"arch\": arch,\n","        \"resize\": resize,\n","        \"in_chans\": in_chans,\n","        \"input_mode\": input_mode,\n","        \"unknown_classes\": ckpt.get(\"unknown_classes\", []),\n","    }\n","\n","    print(\"✅ Loaded:\", path)\n","    print(\" - cfg:\", cfg)\n","    if missing:\n","        print(\" - missing keys:\", missing[:10], \"...\" if len(missing) > 10 else \"\")\n","    if unexpected:\n","        print(\" - unexpected keys:\", unexpected[:10], \"...\" if len(unexpected) > 10 else \"\")\n","\n","    return model, ckpt, known_classes, class_to_idx, cfg"]},{"cell_type":"markdown","metadata":{"id":"yqVRucdizMuf"},"source":["## 1. 데이터 로드 및 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1NhVam2_Fi4"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/data/LSWMD.pkl\")\n","print(df.shape)\n","print(df[\"failureType\"].head())      # 보통 list 형태거나 빈 list\n","print(df[\"trianTestLabel\"].head())   # 기존 train/test 표기가 있을 수 있음(우리는 재분할 권장)"]},{"cell_type":"markdown","metadata":{"id":"fjrCpVOUzPJ5"},"source":["### 1.1 데이터 구조 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMLpGPzlIZCi"},"outputs":[],"source":["print(df.columns)\n","print(df[[\"waferMap\",\"failureType\",\"trianTestLabel\"]].head(3))\n","\n","# waferMap 한 개의 형태 확인\n","wm0 = df[\"waferMap\"].iloc[0]\n","print(type(wm0), getattr(wm0, \"shape\", None))"]},{"cell_type":"markdown","metadata":{"id":"a-5bybsCzeXj"},"source":["### 1.2 라벨 전처리 (failureType → label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xLjOHq7zZ4t"},"outputs":[],"source":["import numpy as np\n","\n","def get_label(x):\n","    if isinstance(x, (list, tuple, np.ndarray)):\n","        return str(x[0][0]) if len(x) > 0 else None\n","    if isinstance(x, str) and x.strip() != \"\":\n","        return x\n","    return None\n","\n","df[\"label\"] = df[\"failureType\"].apply(get_label)\n","\n","print(df[\"label\"].value_counts(dropna=False).head(15))\n","print(\"labeled count:\", df[\"label\"].notna().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeuCIcGvyt8b"},"outputs":[],"source":["print(type(df.iloc[0][\"label\"]))"]},{"cell_type":"markdown","metadata":{"id":"eg4POGB90AVA"},"source":["## 2. Open-set 평가 설계 (클래스 홀드아웃)\n","- Donut과 Scratch를 Unknown(홀드아웃)으로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoVXY6tzzgtM"},"outputs":[],"source":["UNKNOWN_CLASSES = [\"Donut\", \"Scratch\"]\n","EXCLUDE_CLASSES = [\"none\"]\n","\n","labeled = df[df[\"label\"].notna()].copy()\n","labeled = labeled[~labeled[\"label\"].isin(EXCLUDE_CLASSES)].copy()\n","\n","known_df = labeled[~labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","unknown_df = labeled[labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","\n","print(\"labeled:\", len(labeled))\n","print(\"known:\", len(known_df))\n","print(\"unknown:\", len(unknown_df))\n","print(\"known classes:\", sorted(known_df[\"label\"].unique()))\n","print(\"unknown classes:\", sorted(unknown_df[\"label\"].unique()))"]},{"cell_type":"markdown","metadata":{"id":"ETa1JYOssN93"},"source":["## 3. 클래스 이해 및 시각화"]},{"cell_type":"markdown","metadata":{"id":"UCkHAU1bsClI"},"source":["### 3.1 클래스 정의 + 컬러 의미\n","\n","\n","- **Center**: 웨이퍼 **중심(가운데)**에 불량이 몰려 있는 패턴 (가운데 뭉침)\n","- **Donut**: 중심은 비교적 깨끗하고, 그 주변에 **동심원(도넛 링)**처럼 불량이 분포 (원형 띠)\n","- **Edge-Loc (Edge-Local)**: 웨이퍼 **가장자리의 특정 구간**에만 불량이 몰린 패턴 (테두리 한쪽만)\n","- **Edge-Ring**: 웨이퍼 **테두리 전체를 따라 고리(링)**처럼 불량이 나타나는 패턴 (둘레 전체 띠)\n","- **Loc (Local)**: 웨이퍼 내부에서 **중심/테두리가 아닌 임의 위치**에 불량이 뭉친 패턴 (안쪽 어딘가 덩어리)\n","- **Random**: 웨이퍼 전체에 불량이 **듬성듬성, 비교적 고르게 흩어진** 패턴 (여기저기 점)\n","- **Scratch**: **직선/곡선 형태로 길게 이어진** 불량 패턴 (긁힌 자국처럼 선/호)\n","- **Near-full**: 웨이퍼 **거의 전체가 불량으로 채워진** 패턴 (대부분 불량)\n","- **none**: 뚜렷한 결함 패턴이 없거나 결함이 거의 없는 상태 (패턴 없음)\n","---\n","- 보라(가장 어두운 색) = 작은 값 (보통 0) → 웨이퍼 바깥/배경\n","- 파랑(중간 값) = 중간 값 (보통 1) → 정상 die (pass)\n","- 노랑(가장 밝은 색) = 큰 값 (보통 2) → 불량 die (fail)"]},{"cell_type":"markdown","metadata":{"id":"hUVRxPR4hPij"},"source":["### 3.2 클래스별 대표 1장 그리드로 보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gukBRnNsG2m","collapsed":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","labels = sorted(labeled[\"label\"].unique())\n","n = len(labels)\n","\n","cols = 4\n","rows = (n + cols - 1) // cols\n","\n","plt.figure(figsize=(4*cols, 4*rows))\n","for i, lab in enumerate(labels):\n","    wm = labeled[labeled[\"label\"] == lab][\"waferMap\"].iloc[0]  # 첫 샘플\n","    ax = plt.subplot(rows, cols, i+1)\n","    ax.imshow(wm, interpolation=\"nearest\")\n","    ax.set_title(lab)\n","    ax.axis(\"off\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Krj0gzWYsV94"},"source":["### 3.3 특정 Failure Type 랜덤 샘플 보기"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"uUnhzrRLsa0M"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def show_samples(label, n=8, seed=RANDOM_STATE):\n","    sub = labeled[labeled[\"label\"] == label]\n","    if len(sub) == 0:\n","        print(\"No samples for:\", label)\n","        return\n","    sub = sub.sample(n=min(n, len(sub)), random_state=seed)\n","\n","    cols = 4\n","    rows = (len(sub) + cols - 1) // cols\n","    plt.figure(figsize=(4*cols, 4*rows))\n","    for i, wm in enumerate(sub[\"waferMap\"].tolist()):\n","        ax = plt.subplot(rows, cols, i+1)\n","        ax.imshow(wm, interpolation=\"nearest\")\n","        ax.axis(\"off\")\n","    plt.suptitle(f\"{label} (n={len(sub)})\", y=1.02, fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시\n","for label in [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Random\", \"Scratch\", \"Near-full\", \"none\"]:\n","    show_samples(label, n=8, seed=0)"]},{"cell_type":"markdown","metadata":{"id":"EvmhBLFXmgyd"},"source":["## 4. 데이터 분할 (train/val/test_known/test_unknown)\n","\n","- train = 70%\n","- val = 15%\n","- test_known = 15%\n","- test_unknown = unknown_df 전부\n","\n","이 비율은 머신러닝에서 아주 흔한 기본값\n","\n","- train을 충분히 크게 가져가야 학습이 잘 되고\n","- val/test도 너무 작으면 지표가 흔들리니까 적당히 확보하는 균형"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kPjFBtWz7f8"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, temp_df = train_test_split(\n","    known_df, test_size=0.3, random_state=RANDOM_STATE, stratify=known_df[\"label\"] # stratify는 각 split마다 라벨 비율이 원래 데이터랑 비슷하게 유지되도록 나눠주는 옵션\n",")\n","val_df, test_known_df = train_test_split(\n","    temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[\"label\"]\n",")\n","\n","test_unknown_df = unknown_df.copy()\n","\n","print(\"train:\", len(train_df), \"val:\", len(val_df),\n","      \"test_known:\", len(test_known_df), \"test_unknown:\", len(test_unknown_df))"]},{"cell_type":"markdown","metadata":{"id":"rTQ0Plp_mpkJ"},"source":["## 5. Dataset/DataLoader 구성 (전처리/증강)\n","\n","\n","*   waferMap을 64×64로 resize\n","*   1채널을 3채널로 복제해서 ResNet에 넣기 (가장 쉬운 방식)\n","*   회전/반전 증강은 train에만"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDQQDaKPmpBM"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","# ✅ class_to_idx는 \"현재 train_df에서 새로 만들지 말고\"\n","#    분석하려는 ckpt에서 로드한 class_to_idx를 쓰는 게 원칙.\n","#    (단, 지금 학습하는 모드면 아래처럼 train_df 기반 생성 OK)\n","known_classes = sorted(train_df[\"label\"].unique())\n","class_to_idx = {c:i for i,c in enumerate(known_classes)}\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","print(class_to_idx)\n","\n","class WaferMapDataset(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64, input_mode=\"coords4\"):\n","        self.df = df.reset_index(drop=True)\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = resize\n","        self.input_mode = input_mode\n","\n","        # coords4 모드일 때만 좌표 채널 생성\n","        if self.input_mode == \"coords4\":\n","            g = torch.linspace(-1, 1, self.resize)\n","            try:\n","                yy, xx = torch.meshgrid(g, g, indexing=\"ij\")\n","            except TypeError:\n","                yy, xx = torch.meshgrid(g, g)\n","            rr = torch.sqrt(xx**2 + yy**2)\n","            self.coords = torch.stack([xx, yy, rr], dim=0).float()\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        # x: (C,H,W)\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[2])\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[1])\n","        k = int(torch.randint(0, 4, (1,)).item())\n","        x = torch.rot90(x, k, dims=[1,2])\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        wm = row[\"waferMap\"]\n","        x = torch.tensor(wm, dtype=torch.float32).unsqueeze(0)  # (1,H,W)\n","\n","        mx = x.max()\n","        x = x / (mx if mx > 0 else 1.0)\n","\n","        x = F.interpolate(\n","            x.unsqueeze(0),\n","            size=(self.resize, self.resize),\n","            mode=\"nearest\"\n","        ).squeeze(0)  # (1,R,R)\n","\n","        # ✅ 모드에 따라 채널 구성 변경\n","        if self.input_mode == \"coords4\":\n","            x = torch.cat([x, self.coords], dim=0)  # (4,R,R)\n","        elif self.input_mode == \"repeat3\":\n","            x = x.repeat(3, 1, 1)  # (3,R,R)\n","        else:\n","            raise ValueError(f\"Unknown input_mode: {self.input_mode}\")\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        if self.class_to_idx is None:\n","            return x\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return x, y\n","\n","# ✅ 여기서 INPUT_MODE를 모델 cfg에 맞춰 바꿔 끼울 수 있어야 함\n","# (학습 중이면 coords4로 고정해도 되지만, '과거 ckpt 분석'까지 하려면 아래처럼 변수화)\n","INPUT_MODE = \"coords4\"  # <-- 과거 모델 분석 시 \"repeat3\"로 바꾸면 됨\n","\n","train_loader = DataLoader(\n","    WaferMapDataset(train_df, class_to_idx, True, 64, INPUT_MODE),\n","    batch_size=128, shuffle=True, num_workers=2\n",")\n","val_loader = DataLoader(\n","    WaferMapDataset(val_df, class_to_idx, False, 64, INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","test_known_loader = DataLoader(\n","    WaferMapDataset(test_known_df, class_to_idx, False, 64, INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","test_unknown_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64, input_mode=INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")"]},{"cell_type":"markdown","metadata":{"id":"BvA0Nu_WoDyh"},"source":["## 6. Known 분류기 학습 (ResNet18 베이스라인)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cb3m6QkbmjoC"},"outputs":[],"source":["import torchvision.models as models\n","import torch.nn as nn\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = models.resnet18(weights=None)\n","model.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","model.fc = nn.Linear(model.fc.in_features, len(known_classes))\n","model = model.to(device)\n","\n","opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","\n","def run_epoch(loader, train=True, return_preds=False):\n","    model.train(train)\n","    total_loss, correct, total = 0.0, 0, 0\n","    ys, ps = [], []\n","\n","    for x, y in tqdm(loader, disable=not train):\n","        x, y = x.to(device), y.to(device)\n","        logits = model(x)\n","        loss = criterion(logits, y)\n","\n","        if train:\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","        total_loss += loss.item() * x.size(0)\n","        pred = logits.argmax(dim=1)\n","        correct += (pred == y).sum().item()\n","        total += x.size(0)\n","\n","        if return_preds:\n","            ys.append(y.detach().cpu().numpy())\n","            ps.append(pred.detach().cpu().numpy())\n","\n","    if return_preds:\n","        import numpy as np\n","        y_true = np.concatenate(ys)\n","        y_pred = np.concatenate(ps)\n","        return total_loss/total, correct/total, y_true, y_pred\n","\n","    return total_loss/total, correct/total\n","\n","best_val_macro = -1.0\n","best_path = None\n","\n","EPOCHS = 5\n","for epoch in range(1, EPOCHS + 1):\n","    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n","    va_loss, va_acc, yv, pv = run_epoch(val_loader, train=False, return_preds=True)\n","\n","    va_macro = f1_score(yv, pv, average=\"macro\")\n","    print(f\"Epoch {epoch} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n","          f\"val loss {va_loss:.4f} acc {va_acc:.4f} macroF1 {va_macro:.4f}\")\n","\n","    # (선택) best 저장\n","    if va_macro > best_val_macro:\n","        best_val_macro = va_macro\n","        best_path = save_mvp_checkpoint(\n","            model=model,\n","            class_to_idx=class_to_idx,\n","            unknown_classes=UNKNOWN_CLASSES,\n","            resize=64,\n","            arch=\"resnet18\",\n","            optimizer=opt,\n","            metrics={\"epoch\": epoch, \"val_acc\": va_acc, \"val_macro_f1\": va_macro},\n","            tag=f\"best_e{epoch:02d}\"\n","        )\n","\n","# (필수) 학습 끝나면 last 저장\n","last_path = save_mvp_checkpoint(\n","    model=model,\n","    class_to_idx=class_to_idx,\n","    unknown_classes=UNKNOWN_CLASSES,\n","    resize=64,\n","    arch=\"resnet18\",\n","    optimizer=opt,\n","    metrics={\"epoch\": EPOCHS, \"val_acc\": va_acc, \"val_macro_f1\": best_val_macro},\n","    tag=f\"last_e{EPOCHS:02d}\"\n",")\n","\n","print(\"✅ Saved best:\", best_path)\n","print(\"✅ Saved last:\", last_path)"]},{"cell_type":"markdown","metadata":{"id":"ewbcL6n4rW_R"},"source":["## 7. Known 성능 평가 (macro-F1 중심)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzNNV_XwoF7r"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report\n","\n","@torch.no_grad()\n","def predict_known(loader):\n","    model.eval()\n","    ys, ps = [], []\n","    for x, y in loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        pred = logits.argmax(dim=1).cpu().numpy()\n","        ys.append(np.array(y))\n","        ps.append(pred)\n","    y_true = np.concatenate(ys)\n","    y_pred = np.concatenate(ps)\n","    return y_true, y_pred\n","\n","y_true, y_pred = predict_known(test_known_loader)\n","print(\"macro-F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n","print(classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(len(known_classes))]))"]},{"cell_type":"markdown","metadata":{"id":"sDWy2TZP0fJP"},"source":["### 7.1 confusion matrix + “Loc이 어디로 새는지 / Random이 누구를 잡아먹는지 확인\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iB4vMeT0sJo"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from sklearn.metrics import confusion_matrix\n","\n","labels = known_classes  # [\"Center\", \"Edge-Loc\", ...] (이미 정렬돼 있음)\n","n = len(labels)\n","\n","# 1) Confusion matrix (raw + row-normalized)\n","cm = confusion_matrix(y_true, y_pred, labels=list(range(n)))\n","cm_row = cm / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n","\n","plt.figure(figsize=(8, 6))\n","plt.imshow(cm_row, vmin=0, vmax=1)\n","plt.xticks(range(n), labels, rotation=45, ha=\"right\")\n","plt.yticks(range(n), labels)\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix (row-normalized)\")\n","plt.colorbar(fraction=0.046, pad=0.04)\n","plt.tight_layout()\n","plt.show()\n","\n","# 2) 클래스별로 '가장 많이 틀리는 방향' Top-k 출력\n","def top_confusions(cm, labels, k=3):\n","    for i, lab in enumerate(labels):\n","        row = cm[i].copy()\n","        row[i] = 0\n","        total = cm[i].sum()\n","        if total == 0:\n","            continue\n","        top = np.argsort(row)[::-1][:k]\n","        print(f\"\\nTrue {lab} (n={total})\")\n","        for j in top:\n","            if row[j] == 0:\n","                continue\n","            print(f\"  -> Pred {labels[j]}: {row[j]} ({row[j]/total:.1%})\")\n","\n","top_confusions(cm, labels, k=3)\n","\n","# 3) Loc(재현율 낮음) / Random(precision 낮음) 집중 분석\n","loc_idx = class_to_idx[\"Loc\"]\n","rand_idx = class_to_idx[\"Random\"]\n","\n","# Loc 미탐: True=Loc인데 Pred!=Loc\n","loc_miss = np.where((y_true == loc_idx) & (y_pred != loc_idx))[0]\n","print(\"\\n[Loc misses]\")\n","print(\"  count:\", len(loc_miss), \"/\", int((y_true == loc_idx).sum()), f\"= {len(loc_miss)/max(1,(y_true==loc_idx).sum()):.1%}\")\n","\n","miss_to = y_pred[loc_miss]\n","vals, cnts = np.unique(miss_to, return_counts=True)\n","for v, c in sorted(zip(vals, cnts), key=lambda x: -x[1]):\n","    print(f\"  Loc -> {idx_to_class[int(v)]}: {c} ({c/len(loc_miss):.1%})\")\n","\n","# Random 오탐: Pred=Random인데 True!=Random\n","rand_fp = np.where((y_pred == rand_idx) & (y_true != rand_idx))[0]\n","print(\"\\n[Random false positives]\")\n","print(\"  count:\", len(rand_fp), \"/\", int((y_pred == rand_idx).sum()), f\"= {len(rand_fp)/max(1,(y_pred==rand_idx).sum()):.1%}\")\n","\n","fp_from = y_true[rand_fp]\n","vals, cnts = np.unique(fp_from, return_counts=True)\n","for v, c in sorted(zip(vals, cnts), key=lambda x: -x[1]):\n","    print(f\"  True {idx_to_class[int(v)]} -> Random: {c} ({c/len(rand_fp):.1%})\")\n","\n","# 4) 실제 웨이퍼맵으로 눈으로 확인 (Loc miss / Random FP)\n","test_known_df_r = test_known_df.reset_index(drop=True).copy()\n","\n","def show_cases(idxs, title=\"\", n_show=12, cols=4):\n","    idxs = list(idxs)[:n_show]\n","    if len(idxs) == 0:\n","        print(title, \": (none)\")\n","        return\n","    rows = math.ceil(len(idxs)/cols)\n","    plt.figure(figsize=(4*cols, 4*rows))\n","    for i, idx in enumerate(idxs):\n","        row = test_known_df_r.iloc[int(idx)]\n","        wm = row[\"waferMap\"]\n","        true_lab = row[\"label\"]\n","        pred_lab = idx_to_class[int(y_pred[int(idx)])]\n","        ax = plt.subplot(rows, cols, i+1)\n","        ax.imshow(wm, interpolation=\"nearest\")\n","        ax.set_title(f\"T:{true_lab}\\nP:{pred_lab}\", fontsize=10)\n","        ax.axis(\"off\")\n","    plt.suptitle(title, y=1.02, fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","show_cases(loc_miss, title=\"Loc misclassified (True=Loc, Pred!=Loc)\", n_show=12)\n","show_cases(rand_fp, title=\"Random false positives (Pred=Random, True!=Random)\", n_show=12)"]},{"cell_type":"markdown","source":["### 7.1 Random threshold 스윕"],"metadata":{"id":"1z2o1ci8ZFR2"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n","\n","# ===== 0) model / device 확보 (너 노트북 스타일 그대로) =====\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = loaded_model if \"loaded_model\" in globals() else model\n","model = model.to(device).eval()\n","\n","assert \"Random\" in class_to_idx, \"known_classes에 'Random'이 없어. (Random 임계값 스윕 불가)\"\n","rand_idx = class_to_idx[\"Random\"]\n","\n","# ===== 1) 확률(probs), argmax 예측, 정답 얻기 =====\n","@torch.no_grad()\n","def get_probs_and_preds(model, loader, device):\n","    model.eval()\n","    all_probs, all_pred, all_true = [], [], []\n","    for x, y in loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        probs = torch.softmax(logits, dim=1)\n","        all_probs.append(probs.cpu().numpy())\n","        all_pred.append(probs.argmax(dim=1).cpu().numpy())\n","        all_true.append(np.array(y))\n","    probs = np.concatenate(all_probs, axis=0)\n","    y_pred = np.concatenate(all_pred, axis=0)\n","    y_true = np.concatenate(all_true, axis=0)\n","    return probs, y_pred, y_true\n","\n","def apply_random_threshold(probs, y_pred_argmax, rand_idx, t_rand: float):\n","    \"\"\"\n","    argmax가 Random인데 Random 확률이 t_rand 미만이면 2등 클래스로 보냄\n","    \"\"\"\n","    y2 = y_pred_argmax.copy()\n","    rand_mask = (y_pred_argmax == rand_idx) & (probs[:, rand_idx] < t_rand)\n","    if rand_mask.any():\n","        second = np.argsort(probs[rand_mask], axis=1)[:, -2]\n","        y2[rand_mask] = second\n","    return y2, int(rand_mask.sum())\n","\n","def plot_cm_row_norm(y_true, y_pred, labels):\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n","    cm_row = cm / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm_row, vmin=0, vmax=1)\n","    plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n","    plt.yticks(range(len(labels)), labels)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    plt.title(\"Confusion Matrix (row-normalized)\")\n","    plt.colorbar(fraction=0.046, pad=0.04)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ===== 2) VAL에서 t_rand 스윕 =====\n","probs_val, pred_val, y_val = get_probs_and_preds(model, val_loader, device)\n","\n","base_macro = f1_score(y_val, pred_val, average=\"macro\")\n","base_acc = accuracy_score(y_val, pred_val)\n","\n","ts = np.arange(0.50, 0.91, 0.05)  # 필요하면 0.02 간격 등으로 촘촘히 바꿔도 됨\n","rows = []\n","for t in ts:\n","    pred_val2, moved = apply_random_threshold(probs_val, pred_val, rand_idx, float(t))\n","    rows.append({\n","        \"t_rand\": float(t),\n","        \"moved_from_random\": moved,\n","        \"val_acc\": float(accuracy_score(y_val, pred_val2)),\n","        \"val_macro_f1\": float(f1_score(y_val, pred_val2, average=\"macro\")),\n","        \"val_macro_f1_gain\": float(f1_score(y_val, pred_val2, average=\"macro\") - base_macro),\n","    })\n","\n","sweep_df = pd.DataFrame(rows).sort_values(\"val_macro_f1\", ascending=False).reset_index(drop=True)\n","\n","print(f\"[VAL baseline] acc={base_acc:.4f}, macroF1={base_macro:.4f}\")\n","display(sweep_df.head(10))\n","\n","best_t = float(sweep_df.loc[0, \"t_rand\"])\n","print(\"\\n✅ best_t (by val macro-F1):\", best_t)\n","\n","# ===== 3) TEST_KNOWN에 best_t 적용 (전/후 리포트) =====\n","probs_test, pred_test, y_test = get_probs_and_preds(model, test_known_loader, device)\n","\n","print(\"\\n[TEST baseline]\")\n","print(\"macro-F1:\", f1_score(y_test, pred_test, average=\"macro\"))\n","print(classification_report(y_test, pred_test, target_names=[idx_to_class[i] for i in range(len(known_classes))]))\n","\n","pred_test2, moved = apply_random_threshold(probs_test, pred_test, rand_idx, best_t)\n","\n","print(\"\\n[TEST after Random-threshold]\")\n","print(\"moved_from_random:\", moved)\n","print(\"macro-F1:\", f1_score(y_test, pred_test2, average=\"macro\"))\n","print(classification_report(y_test, pred_test2, target_names=[idx_to_class[i] for i in range(len(known_classes))]))\n","\n","# (선택) after CM도 같이 보기\n","plot_cm_row_norm(y_test, pred_test2, [idx_to_class[i] for i in range(len(known_classes))])"],"metadata":{"id":"n0tfSkiwZm5q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jum0FDZJrfWD"},"source":["## 8. OOD(Unknown 탐지) 평가: MSP vs Energy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4FMGusPrUAS"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, average_precision_score\n","\n","@torch.no_grad()\n","def collect_scores(loader, known=True, T=1.0):\n","    model.eval()\n","    msp_list, energy_list = [], []\n","    for batch in loader:\n","        x = batch[0] if known else batch\n","        x = x.to(device)\n","\n","        logits = model(x) / T\n","        prob = torch.softmax(logits, dim=1)\n","        msp = prob.max(dim=1).values                   # 높을수록 known\n","        energy = -T * torch.logsumexp(logits, dim=1)   # 보통 -energy가 높을수록 known로 사용\n","\n","        msp_list.append(msp.cpu().numpy())\n","        energy_list.append(energy.cpu().numpy())\n","\n","    return np.concatenate(msp_list), np.concatenate(energy_list)\n","\n","msp_k, en_k = collect_scores(test_known_loader, known=True)\n","msp_u, en_u = collect_scores(test_unknown_loader, known=False)\n","\n","y = np.concatenate([np.ones_like(msp_k), np.zeros_like(msp_u)])  # known=1, unknown=0\n","\n","score_msp = np.concatenate([msp_k, msp_u])\n","score_energy = np.concatenate([-en_k, -en_u])  # -energy를 known 점수로\n","\n","print(\"AUROC MSP   :\", roc_auc_score(y, score_msp))\n","print(\"AUPR  MSP   :\", average_precision_score(y, score_msp))\n","print(\"AUROC Energy:\", roc_auc_score(y, score_energy))\n","print(\"AUPR  Energy:\", average_precision_score(y, score_energy))"]},{"cell_type":"markdown","metadata":{"id":"9ef8a256"},"source":["## 9. 체크포인트 로드\n","\n","\n","저장된 `state_dict`를 불러와 새로운 모델 인스턴스에 로드합니다. 이때, 모델의 아키텍처는 저장할 때와 동일하게 정의되어 있어야 합니다."]},{"cell_type":"markdown","source":["저장은 필요하면 아래 코드 실행"],"metadata":{"id":"SNw-DIlk5mSw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaKk1QccAxeS"},"outputs":[],"source":["ckpt_path = save_mvp_checkpoint(model, class_to_idx, UNKNOWN_CLASSES, resize=64, arch=\"resnet18\", optimizer=None)"]},{"cell_type":"markdown","source":["### Checkpoint만 로드"],"metadata":{"id":"hg8nN0uX37mW"}},{"cell_type":"code","source":["import os, glob\n","import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","CKPT_PATH = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/checkpoints/20251231-152621_resnet18_r64_holdout-Donut-Scratch_ep05_valF1-0.872_aurocMSP-0.862_aurocEn-0.852.pt\"\n","\n","# CKPT_PATH 지정 안 했으면 최신 ckpt 자동 선택\n","if \"CKPT_PATH\" not in globals() or CKPT_PATH is None:\n","    ckpts = sorted(glob.glob(os.path.join(CKPT_DIR, \"*.pt\")))\n","    if len(ckpts) == 0:\n","        raise FileNotFoundError(\"No checkpoints found in CKPT_DIR\")\n","    CKPT_PATH = ckpts[-1]\n","\n","# 로드(자동 cfg 포함)\n","model, ckpt, known_classes_model, class_to_idx_model, MODEL_CFG = load_mvp_checkpoint_auto(CKPT_PATH, device=device)\n","\n","# 분석용 공통 변수명으로 세팅(이미 있으면 덮어씀)\n","class_to_idx = class_to_idx_model\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","\n","known_classes = [None]*len(class_to_idx)\n","for c,i in class_to_idx.items():\n","    known_classes[i] = c\n","\n","print(\"analysis classes:\", known_classes)\n","\n","print(\"READY ✅ (ckpt loaded)\")\n","print(\" - CKPT_PATH:\", CKPT_PATH)\n","print(\" - MODEL_CFG:\", MODEL_CFG)"],"metadata":{"id":"I0BdyQta4A_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 데이터/라벨/스플릿"],"metadata":{"id":"zUrrIim04AUl"}},{"cell_type":"code","source":["print(ckpt.get(\"unknown_classes\"))\n","print(known_classes)"],"metadata":{"id":"rf4xrb5hT4uE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis/data/LSWMD.pkl\"\n","\n","UNKNOWN_CLASSES = ckpt.get(\"unknown_classes\", [\"Donut\", \"Scratch\"])\n","EXCLUDE_CLASSES = [] if (\"none\" in ckpt.get(\"class_to_idx\", {})) else [\"none\"]\n","print(\"UNKNOWN_CLASSES:\", UNKNOWN_CLASSES)\n","print(\"EXCLUDE_CLASSES:\", EXCLUDE_CLASSES)\n","\n","def _to_label(x):\n","    if x is None:\n","        return None\n","    if isinstance(x, float) and np.isnan(x):\n","        return None\n","\n","    # ndarray/list/tuple 안의 첫 원소를 scalar string까지 벗김\n","    for _ in range(5):\n","        if isinstance(x, np.ndarray):\n","            if x.size == 0:\n","                return None\n","            x = x.ravel()[0]\n","            continue\n","        if isinstance(x, (list, tuple)):\n","            if len(x) == 0:\n","                return None\n","            x = x[0]\n","            continue\n","        break\n","\n","    if isinstance(x, np.generic):\n","        x = x.item()\n","\n","    if isinstance(x, str):\n","        x = x.strip()\n","        return x if x != \"\" else None\n","\n","    return str(x)\n","\n","# df 로드/label 생성 (skip)\n","if \"df\" not in globals() or df is None:\n","    print(\"Download origin data\")\n","    df = pd.read_pickle(DATA_PATH)\n","\n","if \"label\" not in df.columns:\n","    df[\"label\"] = df[\"failureType\"].apply(_to_label)\n","\n","# splits 생성 (skip)\n","need_split = not all(k in globals() for k in [\"train_df\",\"val_df\",\"test_known_df\",\"test_unknown_df\"])\n","if need_split:\n","    labeled = df[df[\"label\"].notna()].copy()\n","    labeled = labeled[~labeled[\"label\"].isin(EXCLUDE_CLASSES)].copy()\n","\n","    known_all = labeled[~labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","    unknown_df = labeled[labeled[\"label\"].isin(UNKNOWN_CLASSES)].copy()\n","\n","    # stratify fallback\n","    try:\n","        train_df, temp_df = train_test_split(\n","            known_all, test_size=0.3, random_state=RANDOM_STATE, stratify=known_all[\"label\"]\n","        )\n","        val_df, test_known_df = train_test_split(\n","            temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[\"label\"]\n","        )\n","    except ValueError as e:\n","        print(\"[Warn] Stratified split failed -> fallback:\", e)\n","        train_df, temp_df = train_test_split(known_all, test_size=0.3, random_state=RANDOM_STATE, shuffle=True)\n","        val_df, test_known_df = train_test_split(temp_df, test_size=0.5, random_state=RANDOM_STATE, shuffle=True)\n","\n","    test_unknown_df = unknown_df.copy()\n","\n","print(\"READY ✅ (data/split)\")\n","print(\" - train/val/test_known/test_unknown:\", len(train_df), len(val_df), len(test_known_df), len(test_unknown_df))"],"metadata":{"id":"y7eeMsYX4UAx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCR7aztMgr-T"},"source":["## 10. 트리아지(MVP-2): 임베딩 기반 유사사례/시각화"]},{"cell_type":"markdown","metadata":{"id":"d0NANDMyhTAv"},"source":["### 10.1 트리아지용 Dataset (이미지 + 라벨 + row index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QT6jB4HAgxcF"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","\n","class WaferMapDatasetWithIdx(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64, input_mode=\"coords4\"):\n","        self.df = df.reset_index(drop=True).copy()\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = resize\n","        self.input_mode = input_mode\n","\n","        # coords4 모드일 때만 좌표 채널 생성\n","        if self.input_mode == \"coords4\":\n","            g = torch.linspace(-1, 1, self.resize)\n","            try:\n","                yy, xx = torch.meshgrid(g, g, indexing=\"ij\")\n","            except TypeError:\n","                yy, xx = torch.meshgrid(g, g)\n","            rr = torch.sqrt(xx**2 + yy**2)\n","            self.coords = torch.stack([xx, yy, rr], dim=0).float()\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[2])  # 좌우\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[1])  # 상하\n","        k = int(torch.randint(0, 4, (1,)).item())\n","        x = torch.rot90(x, k, dims=[1, 2])\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        wm = row[\"waferMap\"]\n","        x = torch.tensor(wm, dtype=torch.float32).unsqueeze(0)  # (1,H,W)\n","\n","        mx = x.max()\n","        x = x / (mx if mx > 0 else 1.0)\n","\n","        x = F.interpolate(x.unsqueeze(0), size=(self.resize, self.resize), mode=\"nearest\").squeeze(0)  # (1,R,R)\n","\n","        # ✅ 모드에 따라 채널 맞추기\n","        if self.input_mode == \"coords4\":\n","            x = torch.cat([x, self.coords], dim=0)  # (4,R,R)\n","        elif self.input_mode == \"repeat3\":\n","            x = x.repeat(3, 1, 1)                   # (3,R,R)\n","        else:\n","            raise ValueError(f\"Unknown input_mode: {self.input_mode}\")\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        if self.class_to_idx is None:\n","            return x, idx\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return x, y, idx"]},{"cell_type":"markdown","source":["[5. Dataset/DataLoader 구성 (전처리/증강)](https://colab.research.google.com/drive/1gs1u8PboIWySUJ-siTfmclQ26GcwqYCu#scrollTo=MDQQDaKPmpBM&line=4&uniqifier=1)에 학습된 모델을 불러와서 진행할 경우 정리된 class 호출 후, 진행"],"metadata":{"id":"t6LYKYvdTAk-"}},{"cell_type":"code","source":["class WaferMapDataset(Dataset):\n","    def __init__(self, df, class_to_idx=None, is_train=False, resize=64, input_mode=\"coords4\"):\n","        self.df = df.reset_index(drop=True)\n","        self.class_to_idx = class_to_idx\n","        self.is_train = is_train\n","        self.resize = resize\n","        self.input_mode = input_mode\n","\n","        # coords4 모드일 때만 좌표 채널 생성\n","        if self.input_mode == \"coords4\":\n","            g = torch.linspace(-1, 1, self.resize)\n","            try:\n","                yy, xx = torch.meshgrid(g, g, indexing=\"ij\")\n","            except TypeError:\n","                yy, xx = torch.meshgrid(g, g)\n","            rr = torch.sqrt(xx**2 + yy**2)\n","            self.coords = torch.stack([xx, yy, rr], dim=0).float()\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _augment(self, x):\n","        # x: (C,H,W)\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[2])\n","        if torch.rand(1).item() < 0.5:\n","            x = torch.flip(x, dims=[1])\n","        k = int(torch.randint(0, 4, (1,)).item())\n","        x = torch.rot90(x, k, dims=[1,2])\n","        return x\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        wm = row[\"waferMap\"]\n","        x = torch.tensor(wm, dtype=torch.float32).unsqueeze(0)  # (1,H,W)\n","\n","        mx = x.max()\n","        x = x / (mx if mx > 0 else 1.0)\n","\n","        x = F.interpolate(\n","            x.unsqueeze(0),\n","            size=(self.resize, self.resize),\n","            mode=\"nearest\"\n","        ).squeeze(0)  # (1,R,R)\n","\n","        # ✅ 모드에 따라 채널 구성 변경\n","        if self.input_mode == \"coords4\":\n","            x = torch.cat([x, self.coords], dim=0)  # (4,R,R)\n","        elif self.input_mode == \"repeat3\":\n","            x = x.repeat(3, 1, 1)  # (3,R,R)\n","        else:\n","            raise ValueError(f\"Unknown input_mode: {self.input_mode}\")\n","\n","        if self.is_train:\n","            x = self._augment(x)\n","\n","        if self.class_to_idx is None:\n","            return x\n","\n","        y = self.class_to_idx[row[\"label\"]]\n","        return x, y"],"metadata":{"id":"l-ZLxVsGS1mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","import torch\n","\n","# -------------------------\n","# ✅ RESIZE / INPUT_MODE fallback\n","# -------------------------\n","DEFAULT_RESIZE = 64  # 네 기본값\n","\n","# RESIZE\n","if \"MODEL_CFG\" in globals() and isinstance(MODEL_CFG, dict) and (\"resize\" in MODEL_CFG):\n","    RESIZE = int(MODEL_CFG[\"resize\"])\n","elif \"RESIZE\" in globals():\n","    RESIZE = int(RESIZE)\n","else:\n","    RESIZE = DEFAULT_RESIZE\n","\n","# model 잡기 (loaded_model 우선)\n","model_use = loaded_model if \"loaded_model\" in globals() else model\n","\n","# INPUT_MODE\n","if \"MODEL_CFG\" in globals() and isinstance(MODEL_CFG, dict) and (\"input_mode\" in MODEL_CFG):\n","    INPUT_MODE = MODEL_CFG[\"input_mode\"]\n","else:\n","    # ✅ 모델 conv1 채널로 자동 결정\n","    in_ch = model_use.conv1.in_channels if hasattr(model_use, \"conv1\") else 3\n","    INPUT_MODE = \"coords4\" if in_ch == 4 else \"repeat3\"\n","\n","def _filter_by_mapping(df_, class_to_idx):\n","    return df_[df_[\"label\"].isin(class_to_idx.keys())].copy()\n","\n","# 이미 있으면 skip (설정이 바뀌면 다시 만들기 위해 cfg 저장)\n","if \"__LOADERS_CFG__\" not in globals():\n","    __LOADERS_CFG__ = None\n","\n","cfg_now = (RESIZE, INPUT_MODE, tuple(sorted(class_to_idx.keys())))\n","if __LOADERS_CFG__ != cfg_now:\n","    train_loader = DataLoader(\n","        WaferMapDataset(_filter_by_mapping(train_df, class_to_idx), class_to_idx, True, RESIZE, INPUT_MODE),\n","        batch_size=128, shuffle=True, num_workers=2\n","    )\n","    val_loader = DataLoader(\n","        WaferMapDataset(_filter_by_mapping(val_df, class_to_idx), class_to_idx, False, RESIZE, INPUT_MODE),\n","        batch_size=256, shuffle=False, num_workers=2\n","    )\n","    test_known_loader = DataLoader(\n","        WaferMapDataset(_filter_by_mapping(test_known_df, class_to_idx), class_to_idx, False, RESIZE, INPUT_MODE),\n","        batch_size=256, shuffle=False, num_workers=2\n","    )\n","    __LOADERS_CFG__ = cfg_now\n","else:\n","    print(\"Skip loaders: same __LOADERS_CFG__\")\n","\n","print(\"READY ✅ (loaders)\")\n","print(\" - RESIZE:\", RESIZE, \"| INPUT_MODE:\", INPUT_MODE)\n","print(\" - model conv1 in_ch:\", getattr(model_use.conv1, \"in_channels\", \"N/A\") if hasattr(model_use, \"conv1\") else \"N/A\")"],"metadata":{"id":"Yf7nmIB05eRJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3szZwQwg3YH"},"source":["### 10.2 레퍼런스(known) 풀 샘플링"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uN5aESipg6EC"},"outputs":[],"source":["# ✅ 추천: reference에서는 none을 줄이거나 제외\n","MAX_PER_CLASS = 1500\n","MAX_NONE = 2000\n","\n","ref_parts = []\n","for c in known_classes:\n","    sub = train_df[train_df[\"label\"] == c]\n","    if c == \"none\":\n","        sub = sub.sample(n=min(len(sub), MAX_NONE), random_state=RANDOM_STATE)\n","    else:\n","        sub = sub.sample(n=min(len(sub), MAX_PER_CLASS), random_state=RANDOM_STATE)\n","    ref_parts.append(sub)\n","\n","ref_df = pd.concat(ref_parts).sample(frac=1.0, random_state=RANDOM_STATE).reset_index(drop=True)\n","print(\"ref_df size:\", len(ref_df))\n","print(ref_df[\"label\"].value_counts().head())"]},{"cell_type":"markdown","metadata":{"id":"iKotJqQ8hmus"},"source":["### 10.3 임베딩 추출 모델 (fc 직전 특징)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0A6_865Nho8o"},"outputs":[],"source":["import torch.nn as nn\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# model은 너가 학습한 모델(또는 loaded_model) 사용\n","model = loaded_model if \"loaded_model\" in globals() else model\n","model = model.to(device).eval()\n","\n","# fc 제거 → 임베딩 추출기\n","embed_model = nn.Sequential(*list(model.children())[:-1]).to(device).eval()\n","\n","@torch.no_grad()\n","def collect_embeddings_ref(loader):\n","    embs, labels, idxs = [], [], []\n","    for x, y, idx in loader:\n","        x = x.to(device)\n","        e = embed_model(x).squeeze(-1).squeeze(-1)  # (N,512,1,1) -> (N,512)\n","        embs.append(e.cpu())\n","        labels.append(torch.tensor(y))\n","        idxs.append(torch.tensor(idx))\n","    return torch.cat(embs, 0).numpy(), torch.cat(labels, 0).numpy(), torch.cat(idxs, 0).numpy()\n","\n","@torch.no_grad()\n","def collect_embeddings_unknown(loader):\n","    embs, idxs = [], []\n","    for x, idx in loader:\n","        x = x.to(device)\n","        e = embed_model(x).squeeze(-1).squeeze(-1)\n","        embs.append(e.cpu())\n","        idxs.append(torch.tensor(idx))\n","    return torch.cat(embs, 0).numpy(), torch.cat(idxs, 0).numpy()"]},{"cell_type":"markdown","metadata":{"id":"F4UgUGpBhruv"},"source":["### 10.4 임베딩 추출 (ref/unknown)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDpeeC4egy9s"},"outputs":[],"source":["# ✅ 모델 입력 채널에 맞춰 자동으로 결정\n","INPUT_MODE = \"coords4\" if model.conv1.in_channels == 4 else \"repeat3\"\n","print(\"INPUT_MODE for loaders:\", INPUT_MODE)\n","\n","# reference(known)\n","ref_loader = DataLoader(\n","    WaferMapDatasetWithIdx(ref_df, class_to_idx=class_to_idx, is_train=False, resize=64, input_mode=INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","# unknown(test_unknown_df)\n","unk_loader = DataLoader(\n","    WaferMapDatasetWithIdx(test_unknown_df, class_to_idx=None, is_train=False, resize=64, input_mode=INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","# embed_model은 현재 model에서 다시 생성(안전)\n","import torch.nn as nn\n","embed_model = nn.Sequential(*list(model.children())[:-1]).to(device).eval()\n","\n","ref_emb, ref_y, ref_local_idx = collect_embeddings_ref(ref_loader)\n","unk_emb, unk_local_idx = collect_embeddings_unknown(unk_loader)\n","\n","print(\"ref_emb:\", ref_emb.shape, \"unk_emb:\", unk_emb.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"gyPJJR5Ci6bk"},"source":["### 10.5 Unknown → 유사사례 Top-K 검색 (코사인 유사도)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmoNPrpqhvA8"},"outputs":[],"source":["import numpy as np\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","ref_n = l2norm(ref_emb)\n","unk_n = l2norm(unk_emb)\n","\n","# Top-K retrieval\n","K = 5\n","# (unk x ref) similarity가 커질 수 있으니 unk를 배치로 처리\n","def topk_retrieval(unk_n, ref_n, k=5, chunk=512):\n","    topk_idx_all, topk_sim_all = [], []\n","    ref_t = torch.tensor(ref_n, dtype=torch.float32)\n","    for i in range(0, len(unk_n), chunk):\n","        u = torch.tensor(unk_n[i:i+chunk], dtype=torch.float32)\n","        sim = u @ ref_t.T  # cosine similarity\n","        topk_sim, topk_idx = torch.topk(sim, k=k, dim=1)\n","        topk_idx_all.append(topk_idx.numpy())\n","        topk_sim_all.append(topk_sim.numpy())\n","    return np.vstack(topk_idx_all), np.vstack(topk_sim_all)\n","\n","topk_idx, topk_sim = topk_retrieval(unk_n, ref_n, k=K, chunk=512)\n","print(topk_idx.shape, topk_sim.shape)  # (num_unknown, K)"]},{"cell_type":"markdown","metadata":{"id":"l2AgTxlci--V"},"source":["### 10.6 Top-K 결과 시각화 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5E5hzrmGi8tT"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def show_triage_case(unk_i, K=5):\n","    # unknown 샘플\n","    unk_row = test_unknown_df.iloc[int(unk_local_idx[unk_i])]\n","    unk_wm = unk_row[\"waferMap\"]\n","\n","    # ref 샘플들\n","    ref_indices = topk_idx[unk_i][:K]\n","    ref_sims = topk_sim[unk_i][:K]\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    # unknown\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_wm)\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rloc = int(ref_local_idx[ref_indices[j]])  # ref_df의 로컬 인덱스\n","        rrow = ref_df.iloc[rloc]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={ref_sims[j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시로 3개만 보기\n","for i in [0, 1, 2]:\n","    show_triage_case(i, K=5)"]},{"cell_type":"markdown","metadata":{"id":"mm2w_a0ejGSW"},"source":["### 10.7 2D 시각화 (UMAP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0_s_zQ9jDMb"},"outputs":[],"source":["!pip -q install umap-learn\n","\n","import umap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 시각화는 너무 많으면 느리니 샘플링\n","N_REF_VIS = min(5000, len(ref_emb))\n","N_UNK_VIS = min(2000, len(unk_emb))\n","\n","rng = np.random.RandomState(RANDOM_STATE)\n","ref_vis_idx = rng.choice(len(ref_emb), size=N_REF_VIS, replace=False)\n","unk_vis_idx = rng.choice(len(unk_emb), size=N_UNK_VIS, replace=False)\n","\n","X_vis = np.vstack([ref_emb[ref_vis_idx], unk_emb[unk_vis_idx]])\n","y_vis = np.concatenate([ref_y[ref_vis_idx], -1*np.ones(N_UNK_VIS, dtype=int)])  # unknown=-1\n","\n","reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=RANDOM_STATE)\n","Z = reducer.fit_transform(X_vis)\n","\n","plt.figure(figsize=(8,6))\n","\n","# ✅ unknown 먼저\n","mask_unk = (y_vis == -1)\n","plt.scatter(Z[mask_unk, 0], Z[mask_unk, 1], s=6, label=\"Unknown\", alpha=0.9)\n","\n","# ✅ known 클래스별 범례\n","for k in sorted(np.unique(y_vis)):\n","    if k == -1:\n","        continue\n","    mask = (y_vis == k)\n","    name = idx_to_class.get(int(k), f\"Class {int(k)}\")  # idx_to_class 없으면 숫자 표시\n","    plt.scatter(Z[mask, 0], Z[mask, 1], s=6, label=name, alpha=0.9)\n","\n","plt.title(\"Embedding 2D (UMAP): known vs unknown\")\n","plt.legend(markerscale=3, bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IaJdjzCljI2r"},"outputs":[],"source":["import numpy as np\n","print(\"known points:\", np.sum(y_vis != -1))\n","print(\"unknown points:\", np.sum(y_vis == -1))\n","print(\"unique labels (incl -1):\", np.unique(y_vis)[:20])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CW0Byy4Pjze8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","known_mask = (y_vis != -1)\n","unk_mask = (y_vis == -1)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[known_mask,0], Z[known_mask,1], s=6, alpha=0.25, label=\"known\")\n","plt.scatter(Z[unk_mask,0],   Z[unk_mask,1],   s=8, alpha=0.9,  label=\"unknown\")\n","plt.title(\"Embedding 2D (UMAP): known (gray) vs unknown (red)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FE-r0fP0j1FG"},"outputs":[],"source":["import umap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","Xn = l2norm(X_vis)  # 코사인에 맞게 정규화(권장)\n","\n","reducer = umap.UMAP(metric=\"cosine\", n_neighbors=15, min_dist=0.1, random_state=RANDOM_STATE)\n","Z = reducer.fit_transform(Xn)\n","\n","known_mask = (y_vis != -1)\n","unk_mask = (y_vis == -1)\n","\n","plt.figure(figsize=(8,6))\n","plt.scatter(Z[known_mask,0], Z[known_mask,1], s=6, alpha=0.25, color=\"gray\", label=\"known\")\n","plt.scatter(Z[unk_mask,0],   Z[unk_mask,1],   s=10, alpha=0.9,  color=\"red\",  label=\"unknown\")\n","plt.title(\"Embedding 2D (UMAP-cosine): known (gray) vs unknown (red)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"OhBoRb5SvPTy"},"source":["### 10.8 Top-K 트리아지 데모"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPPPgafAj29L"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","ref_n = l2norm(ref_emb).astype(np.float32)\n","unk_n = l2norm(unk_emb).astype(np.float32)\n","\n","def topk_retrieval(unk_n, ref_n, k=5, chunk=512):\n","    topk_idx_all, topk_sim_all = [], []\n","    ref_t = torch.tensor(ref_n)  # (Nref, D)\n","    for i in range(0, len(unk_n), chunk):\n","        u = torch.tensor(unk_n[i:i+chunk])   # (chunk, D)\n","        sim = u @ ref_t.T                    # (chunk, Nref)\n","        topk_sim, topk_idx = torch.topk(sim, k=k, dim=1)\n","        topk_idx_all.append(topk_idx.numpy())\n","        topk_sim_all.append(topk_sim.numpy())\n","    return np.vstack(topk_idx_all), np.vstack(topk_sim_all)\n","\n","K = 5\n","topk_idx, topk_sim = topk_retrieval(unk_n, ref_n, k=K, chunk=512)\n","print(topk_idx.shape, topk_sim.shape)  # (N_unknown, K)"]},{"cell_type":"markdown","metadata":{"id":"YlMhv_dPxAEF"},"source":["### 10.9 트리아지 요약 한 줄 (발표용)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30ZX_CKQwCId"},"outputs":[],"source":["from collections import Counter\n","import numpy as np\n","\n","def triage_summary(unk_i, K=5):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[unk_i][:K]]\n","    cnt = Counter(labels)\n","    top_label, top_count = cnt.most_common(1)[0]\n","    purity = top_count / K\n","    uniq = len(cnt)\n","\n","    if purity >= 0.8:\n","        msg = f\"Top-{K} 중 {top_label} {top_count}/{K} → '{top_label}' 계열 가능성 높음\"\n","    elif uniq >= 4:\n","        msg = f\"Top-{K} 라벨 다양({dict(cnt)}) → 애매 케이스(추가 확인/재측정 권장)\"\n","    else:\n","        msg = f\"Top-{K} 혼재({dict(cnt)}) → 유사 패턴 후보 복수\"\n","    return labels, msg"]},{"cell_type":"markdown","metadata":{"id":"U5Si9noixFRq"},"source":["### 10.10 데모 화면 출력 (Unknown + Top-K)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xH8AG1o9xDHn"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def show_triage_case(unk_i, K=5):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    unk_wm = unk_row[\"waferMap\"]\n","\n","    labels, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_wm)\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(msg, y=1.05, fontsize=12)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시 3개 확인\n","for i in [0, 1, 2]:\n","    show_triage_case(i, K=5)"]},{"cell_type":"markdown","metadata":{"id":"AJN79lGpxORR"},"source":["### 10.11 데모 결과 저장 (이미지/요약)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_u-292hxH8H"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","\n","OUT_DIR = \"assets/triage\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def save_triage_case(unk_i, K=5):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    labels, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(msg, y=1.05, fontsize=12)\n","    plt.tight_layout()\n","\n","    fname = f\"triage_unk{unk_i:04d}_true-{unk_row['label']}.png\"\n","    path = os.path.join(OUT_DIR, fname)\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path, msg\n","\n","# 6개만 저장\n","picked = [0, 1, 2, 3, 4, 5]\n","for i in picked:\n","    p, m = save_triage_case(i, K=5)\n","    print(p, \"|\", m)"]},{"cell_type":"markdown","metadata":{"id":"_TslrDbfyisd"},"source":["### 10.12 (선택) OOD 점수로 데모 후보 자동 선별\n","\n","이미 unknown에 대한 MSP/Energy 배열을 갖고 있으면 이 셀은 건너뛰어도 됨."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g62OkjfeyEGE"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","# 전제: model(or loaded_model), device, test_unknown_df, WaferMapDataset(혹은 너가 쓰는 Dataset)이 존재\n","model_use = loaded_model if \"loaded_model\" in globals() else model_use if \"model_use\" in globals() else model\n","model_use = model_use.to(device).eval()\n","\n","INPUT_MODE = \"coords4\" if model_use.conv1.in_channels == 4 else \"repeat3\"\n","print(\"model in_ch:\", model_use.conv1.in_channels, \"=> INPUT_MODE:\", INPUT_MODE)\n","\n","# unknown loader (순서 보존 위해 shuffle=False)\n","unk_score_loader = DataLoader(\n","    WaferMapDataset(test_unknown_df, class_to_idx=None, is_train=False, resize=64, input_mode=INPUT_MODE),\n","    batch_size=256, shuffle=False, num_workers=2\n",")\n","\n","@torch.no_grad()\n","def compute_msp_energy(model, loader):\n","    msps = []\n","    energy_raw = []  # Energy = -logsumexp(logits). OOD일수록 값이 덜 음수(=더 큼)로 가는 경향\n","    for batch in loader:\n","        # loader가 x만 주는 경우 / (x,idx) 주는 경우를 모두 처리\n","        x = batch[0] if isinstance(batch, (list, tuple)) else batch\n","        x = x.to(device)\n","        logits = model(x)\n","\n","        prob = F.softmax(logits, dim=1)\n","        msp = prob.max(dim=1).values\n","\n","        e = -torch.logsumexp(logits, dim=1)  # energy_raw\n","        msps.append(msp.cpu().numpy())\n","        energy_raw.append(e.cpu().numpy())\n","\n","    msps = np.concatenate(msps)\n","    energy_raw = np.concatenate(energy_raw)\n","    return msps, energy_raw\n","\n","msp_u, energy_u = compute_msp_energy(model_use, unk_score_loader)\n","print(\"scores:\", msp_u.shape, energy_u.shape, \"len(df)=\", len(test_unknown_df))"]},{"cell_type":"markdown","metadata":{"id":"g18vtuw_yU3o"},"source":["### 10.13 데모 후보 자동 선택 기준\n","\n","*   (A) unknown스러운 샘플: MSP 낮고, Energy_raw는 큰(덜 음수) 샘플\n","*   (B) 위험 샘플(과신): MSP 높은데도 실제론 unknown인 샘플 (과신 오분류 위험 강조용)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyPv3fdjxQl0"},"outputs":[],"source":["N_DEMO = 8  # 저장할 케이스 개수\n","\n","# A) unknown-likely: MSP 낮은 순 + Energy_raw 큰 순을 rank로 합침\n","rank_msp = np.argsort(msp_u)                 # 낮을수록 unknown\n","rank_e   = np.argsort(-energy_u)             # 클수록 unknown (덜 음수)\n","rank_sum = np.empty_like(rank_msp)\n","rank_sum[rank_msp] = np.arange(len(rank_msp))\n","rank_sum += np.arange(len(rank_e))[np.argsort(rank_e)]  # 간단 합산\n","\n","demo_unknownlike = np.argsort(rank_sum)[:N_DEMO]\n","\n","# B) overconfident unknown: MSP 높은 순\n","demo_overconf = np.argsort(-msp_u)[:min(N_DEMO, 5)]\n","\n","print(\"demo_unknownlike:\", demo_unknownlike)\n","print(\"demo_overconf:\", demo_overconf)"]},{"cell_type":"markdown","metadata":{"id":"hcSKfSHdyRS_"},"source":["### 10.14 트리아지 결과 저장 (그림 + CSV 요약)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FFJXSmvyCJk"},"outputs":[],"source":["import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","OUT_DIR = \"assets/triage\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def triage_summary(unk_i, K=5):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[unk_i][:K]]\n","    cnt = Counter(labels)\n","    top_label, top_count = cnt.most_common(1)[0]\n","    purity = top_count / K\n","    uniq = len(cnt)\n","\n","    if purity >= 0.8:\n","        msg = f\"Top-{K}: {top_label} {top_count}/{K} → '{top_label}' 계열 가능성 높음\"\n","    elif uniq >= 4:\n","        msg = f\"Top-{K} 라벨 다양({dict(cnt)}) → 애매 케이스(추가 확인/재측정 권장)\"\n","    else:\n","        msg = f\"Top-{K} 혼재({dict(cnt)}) → 후보 복수\"\n","    return labels, purity, msg\n","\n","def save_triage_case(unk_i, K=5, extra_note=\"\"):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","    labels, purity, msg = triage_summary(unk_i, K)\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    title = msg + (f\" | {extra_note}\" if extra_note else \"\")\n","    plt.suptitle(title, y=1.05, fontsize=11)\n","    plt.tight_layout()\n","\n","    fname = f\"triage_unk{unk_i:04d}_true-{unk_row['label']}.png\"\n","    path = os.path.join(OUT_DIR, fname)\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","\n","    return {\n","        \"unk_i\": int(unk_i),\n","        \"true_label\": unk_row[\"label\"],\n","        \"topk_labels\": \"|\".join(labels),\n","        \"purity\": float(purity),\n","        \"note\": title,\n","        \"img_path\": path\n","    }\n","\n","def save_demo_set(indices, tag, K=5):\n","    rows = []\n","    for i in indices:\n","        extra = f\"{tag}\"\n","        rows.append(save_triage_case(int(i), K=K, extra_note=extra))\n","    return rows\n","\n","# demo_unknownlike / demo_overconf가 없으면(위 셀 스킵했으면) 직접 indices를 넣어도 됨\n","K = 5\n","rows_all = []\n","if \"demo_unknownlike\" in globals():\n","    rows_all += save_demo_set(demo_unknownlike, \"OOD-unknownlike\", K=K)\n","if \"demo_overconf\" in globals():\n","    rows_all += save_demo_set(demo_overconf, \"OOD-overconfident\", K=K)\n","\n","df_sum = pd.DataFrame(rows_all)\n","\n","# OOD 점수도 같이 저장(있으면)\n","if \"msp_u\" in globals():\n","    df_sum[\"msp\"] = df_sum[\"unk_i\"].apply(lambda i: float(msp_u[i]))\n","if \"energy_u\" in globals():\n","    df_sum[\"energy_raw\"] = df_sum[\"unk_i\"].apply(lambda i: float(energy_u[i]))\n","\n","csv_path = os.path.join(OUT_DIR, \"triage_summary.csv\")\n","df_sum.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","\n","print(\"✅ saved images to:\", OUT_DIR)\n","print(\"✅ saved summary csv:\", csv_path)\n","df_sum.head()"]},{"cell_type":"markdown","metadata":{"id":"ibqI3wqYa-Rc"},"source":["### 10.15 Unknown → Unknown 유사사례 Top-K (Nearest Neighbors)\n","\n","지금까지는 **Unknown → Known(레퍼런스) Top-K**로,\n","Unknown이 “기존에 알려진 결함 중 무엇과 비슷한지”를 보여주는 트리아지였습니다.\n","\n","다음 단계에서는 **Unknown끼리(Unknown → Unknown) 유사사례 Top-K**를 추가합니다.\n","\n","- 목적: unknown이 “1회성”인지, “비슷한 패턴이 반복(재발)되는지” 빠르게 확인\n","- 입력: `unk_emb`, `test_unknown_df`\n","- 출력: query unknown 1장 + 가장 유사한 unknown K장(코사인 유사도)\n","\n","> 시연/작품 톤을 살리려면 `true label` 표시는 숨기고(옵션), 모양 기반으로만 판단하게 구성합니다."]},{"cell_type":"markdown","metadata":{"id":"DHdKbQL5bS-l"},"source":["#### 10.15.1 unknown → unknown “가장 비슷한 샘플 Top-K” (Nearest Neighbors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O4FKWKWybGqN"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import NearestNeighbors\n","import os\n","\n","def l2norm(a):\n","    return a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n","\n","unk_n = l2norm(unk_emb).astype(np.float32)\n","\n","# cosine distance 기반 최근접 이웃\n","K_NN = 6  # 자기 자신 포함해서 6개 -> 나중에 self 제외하면 5개\n","nn = NearestNeighbors(n_neighbors=K_NN, metric=\"cosine\")\n","nn.fit(unk_n)\n","\n","dist, idx = nn.kneighbors(unk_n)  # dist 낮을수록 유사(가까움), idx: (N_unk, K_NN)\n","# cosine similarity로 보고 싶으면 sim = 1 - dist\n","sim = 1.0 - dist\n","\n","print(\"idx shape:\", idx.shape, \"sim shape:\", sim.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"SQJgI_3hb8y7"},"source":["#### 10.15.2 unknown 유사사례 화면 출력\n","\n","발표/데모에선 show_true_label=False로 숨기면 “진짜 unknown 트리아지” 느낌이 더 살음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kU07-RWJyKj2"},"outputs":[],"source":["def show_unknown_neighbors(unk_i, K_show=5, show_true_label=True):\n","    # 첫 번째 이웃은 자기 자신일 가능성이 큼 -> 제외\n","    neigh = idx[unk_i]\n","    neigh_sim = sim[unk_i]\n","\n","    # self 제외(동일 인덱스)\n","    pairs = [(j, s) for j, s in zip(neigh, neigh_sim) if j != unk_i]\n","    pairs = pairs[:K_show]\n","\n","    plt.figure(figsize=(3*(K_show+1), 3))\n","    row = test_unknown_df.iloc[unk_i]\n","    plt.subplot(1, K_show+1, 1)\n","    plt.imshow(row[\"waferMap\"])\n","    title = \"UNKNOWN(query)\"\n","    if show_true_label and \"label\" in row:\n","        title += f\"\\n(true={row['label']})\"\n","    plt.title(title)\n","    plt.axis(\"off\")\n","\n","    for t, (j, s) in enumerate(pairs):\n","        r = test_unknown_df.iloc[int(j)]\n","        plt.subplot(1, K_show+1, t+2)\n","        plt.imshow(r[\"waferMap\"])\n","        title = f\"unk#{int(j)}\\ncos={float(s):.3f}\"\n","        if show_true_label and \"label\" in r:\n","            title += f\"\\n(true={r['label']})\"\n","        plt.title(title)\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# 예시\n","for i in [0, 1, 2]:\n","    show_unknown_neighbors(i, K_show=5, show_true_label=True)\n"]},{"cell_type":"markdown","metadata":{"id":"SqI8qHnBcHlj"},"source":["#### 10.15.3 unknown 클러스터링 (DBSCAN: “비슷한 애들끼리 자동 그룹핑”)\n","\n","KMeans는 “군집 개수 K를 미리 정해야” 해서 MVP-2에는 덜 직관적이고,  \n","DBSCAN은 “밀도 기반”이라 신규 패턴 후보군 만들 때 스토리가 좋음."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYjGt1wycnzO"},"outputs":[],"source":["from sklearn.cluster import DBSCAN\n","from collections import Counter\n","\n","# cosine distance 기준 eps는 데이터마다 달라서 0.15~0.35 정도를 먼저 시도\n","eps = 0.25\n","min_samples = 10\n","\n","db = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\")\n","unk_cluster = db.fit_predict(unk_n)  # -1은 noise(어느 군집에도 안 들어감)\n","\n","cnt = Counter(unk_cluster)\n","print(\"cluster counts:\", cnt)\n","print(\"num clusters (excluding -1):\", len([k for k in cnt.keys() if k != -1]))"]},{"cell_type":"markdown","metadata":{"id":"hpWwZXTgcrSi"},"source":["eps를 3개만 빠르게 스윕해서 “너무 다 -1”인지 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQ6pxL8tcBPs"},"outputs":[],"source":["for eps_try in [0.20, 0.25, 0.30]:\n","    db = DBSCAN(eps=eps_try, min_samples=min_samples, metric=\"cosine\")\n","    cl = db.fit_predict(unk_n)\n","    c = Counter(cl)\n","    ncl = len([k for k in c.keys() if k != -1])\n","    print(f\"eps={eps_try:.2f} | clusters={ncl} | noise={c.get(-1,0)} / {len(cl)}\")"]},{"cell_type":"markdown","metadata":{"id":"5STsHzLQcvfy"},"source":["#### 10.15.4 군집별 대표 샘플 + 유사 샘플 저장(포스터/슬라이드 바로 사용)"]},{"cell_type":"markdown","metadata":{"id":"uGAtgS-Yc1R8"},"source":["군집 대표(centroid에 가장 가까운 샘플) 찾기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1GOx7EWctms"},"outputs":[],"source":["import numpy as np\n","\n","def cluster_representatives(emb, cluster_ids):\n","    reps = {}\n","    for cid in sorted(set(cluster_ids)):\n","        if cid == -1:\n","            continue\n","        members = np.where(cluster_ids == cid)[0]\n","        if len(members) == 0:\n","            continue\n","        # centroid\n","        c = emb[members].mean(axis=0, keepdims=True)\n","        c = l2norm(c)[0]\n","        # centroid와 cosine similarity 최대인 샘플\n","        sims = emb[members] @ c\n","        rep = members[np.argmax(sims)]\n","        reps[cid] = int(rep)\n","    return reps\n","\n","reps = cluster_representatives(unk_n, unk_cluster)\n","print(\"representatives:\", reps)"]},{"cell_type":"markdown","metadata":{"id":"iDD7MaT2c7ee"},"source":["군집 대표 + 같은 군집 Top-K 이웃을 한 장으로 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPPTK7cIc3bU"},"outputs":[],"source":["OUT_DIR = \"assets/triage_unknown\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def save_cluster_panel(cid, rep_i, K_show=5, show_true_label=True):\n","    # rep_i의 이웃 중 같은 군집만 추림\n","    neigh = idx[rep_i]\n","    neigh_sim = sim[rep_i]\n","    pairs = []\n","    for j, s in zip(neigh, neigh_sim):\n","        j = int(j)\n","        if j == rep_i:\n","            continue\n","        if unk_cluster[j] == cid:\n","            pairs.append((j, float(s)))\n","        if len(pairs) >= K_show:\n","            break\n","\n","    plt.figure(figsize=(3*(K_show+1), 3))\n","    rep_row = test_unknown_df.iloc[rep_i]\n","    plt.subplot(1, K_show+1, 1)\n","    plt.imshow(rep_row[\"waferMap\"])\n","    title = f\"cluster {cid}\\nrep unk#{rep_i}\"\n","    if show_true_label and \"label\" in rep_row:\n","        title += f\"\\n(true={rep_row['label']})\"\n","    plt.title(title)\n","    plt.axis(\"off\")\n","\n","    for t, (j, s) in enumerate(pairs):\n","        r = test_unknown_df.iloc[j]\n","        plt.subplot(1, K_show+1, t+2)\n","        plt.imshow(r[\"waferMap\"])\n","        title = f\"unk#{j}\\ncos={s:.3f}\"\n","        if show_true_label and \"label\" in r:\n","            title += f\"\\n(true={r['label']})\"\n","        plt.title(title)\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    path = os.path.join(OUT_DIR, f\"unknown_cluster{cid}_rep{rep_i}.png\")\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path\n","\n","saved = []\n","for cid, rep_i in list(reps.items())[:8]:  # 최대 8개 군집만 저장(조절 가능)\n","    saved.append(save_cluster_panel(cid, rep_i, K_show=5, show_true_label=True))\n","\n","print(\"saved:\", len(saved), \"files in\", OUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"u8usA4CRdCGE"},"source":["요약 CSV 저장 (군집 크기/대표/라벨 분포)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68z-9mhVc9wU"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter\n","\n","rows = []\n","for cid in sorted(set(unk_cluster)):\n","    members = np.where(unk_cluster == cid)[0]\n","    if len(members) == 0:\n","        continue\n","    row = {\"cluster_id\": int(cid), \"count\": int(len(members))}\n","    if cid != -1 and cid in reps:\n","        row[\"rep_unk_i\"] = reps[cid]\n","    # 개발 중에는 true label 분포도 같이 기록(최종 데모에선 숨겨도 됨)\n","    if \"label\" in test_unknown_df.columns:\n","        labels = test_unknown_df.iloc[members][\"label\"].tolist()\n","        row[\"label_dist\"] = dict(Counter(labels))\n","    rows.append(row)\n","\n","df_cl = pd.DataFrame(rows).sort_values([\"cluster_id\"])\n","csv_path = os.path.join(OUT_DIR, \"unknown_clusters_summary.csv\")\n","df_cl.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","csv_path, df_cl.head()"]},{"cell_type":"markdown","metadata":{"id":"moWsMIhSe9yJ"},"source":["### 10.16 Top-K 기반 ‘후보군’ 클러스터링"]},{"cell_type":"markdown","metadata":{"id":"mD7zERNkfebY"},"source":["#### 10.16.1 unknown을 “Top-K 라벨 분포 벡터”로 변환\n","\n","예: known 클래스가 7개면 unknown 하나를 7차원 벡터로 만듦\n","(Top-K에서 Loc가 3개면 Loc 차원에 3/5 같은 값)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EXBGtu0dEWF"},"outputs":[],"source":["import numpy as np\n","from collections import Counter\n","\n","known_labels = sorted(ref_df[\"label\"].unique())\n","label_to_j = {c:j for j,c in enumerate(known_labels)}\n","K = topk_idx.shape[1]\n","\n","def topk_label_vector(i):\n","    labels = [ref_df.iloc[j][\"label\"] for j in topk_idx[i]]\n","    cnt = Counter(labels)\n","    v = np.zeros(len(known_labels), dtype=np.float32)\n","    for lab, n in cnt.items():\n","        v[label_to_j[lab]] = n / K\n","    return v, cnt, labels\n","\n","X_triage = np.stack([topk_label_vector(i)[0] for i in range(len(test_unknown_df))], axis=0)\n","print(\"X_triage shape:\", X_triage.shape)  # (N_unknown, num_known_classes)"]},{"cell_type":"markdown","metadata":{"id":"UrJej2k8fNWl"},"source":["#### 10.16.2 KMeans로 “Top-K 패턴 그룹” 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8HnxjQNfKX9"},"outputs":[],"source":["from sklearn.cluster import KMeans\n","from collections import Counter\n","\n","n_clusters = 6\n","km = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=\"auto\")\n","triage_cluster = km.fit_predict(X_triage)\n","\n","print(\"cluster counts:\", Counter(triage_cluster))"]},{"cell_type":"markdown","metadata":{"id":"qoxS4cwNfXiT"},"source":["#### 10.16.3 군집을 사람이 읽기 쉬운 말로 요약"]},{"cell_type":"markdown","metadata":{"id":"ElUUu2s8fpHI"},"source":["각 군집에서 “Top-K가 주로 어느 라벨로 쏠리는지”를 요약해줌.\n","\n","예시 출력 해석:  \n","Loc 0.62, Edge-Loc 0.21 …  \n","→ “이 그룹은 Top-K가 Loc 쪽으로 강하게 몰림”"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DgtLWF-fVKs"},"outputs":[],"source":["def summarize_cluster(cid, topn=3):\n","    members = np.where(triage_cluster == cid)[0]\n","    mean_v = X_triage[members].mean(axis=0)  # 평균 분포\n","    top = mean_v.argsort()[::-1][:topn]\n","    return [(known_labels[j], float(mean_v[j])) for j in top], len(members)\n","\n","for cid in range(n_clusters):\n","    top, n = summarize_cluster(cid, topn=3)\n","    print(f\"[cluster {cid}] n={n} | top:\", top)"]},{"cell_type":"markdown","metadata":{"id":"2Tt4OofBf1K2"},"source":["#### 10.16.4 군집 대표 unknown 뽑고, “Top-K 패널” 자동 저장\n","대표는 “군집 평균 분포(mean_v)와 가장 가까운 unknown”으로 선택."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M85DNdknfuk0"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","\n","OUT_DIR = \"assets/triage_clusters\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def pick_representative(cid):\n","    members = np.where(triage_cluster == cid)[0]\n","    mean_v = X_triage[members].mean(axis=0, keepdims=True)\n","    # cosine similarity로 가장 가까운 멤버 선택\n","    A = members\n","    num = (X_triage[A] @ mean_v.T).squeeze()\n","    den = (np.linalg.norm(X_triage[A], axis=1) * np.linalg.norm(mean_v) + 1e-12)\n","    cos = num / den\n","    return int(A[np.argmax(cos)])\n","\n","def save_topk_panel(unk_i, K=5, title_prefix=\"\"):\n","    unk_row = test_unknown_df.iloc[unk_i]\n","\n","    plt.figure(figsize=(3*(K+1), 3))\n","    plt.subplot(1, K+1, 1)\n","    plt.imshow(unk_row[\"waferMap\"])\n","    plt.title(f\"UNKNOWN\\n(true={unk_row['label']})\")\n","    plt.axis(\"off\")\n","\n","    for j in range(K):\n","        rrow = ref_df.iloc[topk_idx[unk_i][j]]\n","        plt.subplot(1, K+1, j+2)\n","        plt.imshow(rrow[\"waferMap\"])\n","        plt.title(f\"{rrow['label']}\\ncos={topk_sim[unk_i][j]:.3f}\")\n","        plt.axis(\"off\")\n","\n","    plt.suptitle(title_prefix, y=1.05, fontsize=11)\n","    plt.tight_layout()\n","    path = os.path.join(OUT_DIR, f\"clusterPanel_unk{unk_i:04d}.png\")\n","    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","    return path\n","\n","saved = []\n","for cid in range(n_clusters):\n","    rep = pick_representative(cid)\n","    top, n = summarize_cluster(cid, topn=3)\n","    title = f\"Cluster {cid} (n={n}) | top={top}\"\n","    saved.append(save_topk_panel(rep, K=K, title_prefix=title))\n","\n","print(\"saved panels:\", len(saved), \"in\", OUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"19pCtx9Rf8rD"},"source":["#### 10.16.5 요약 CSV 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEutiU9wf6kN"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter\n","\n","rows = []\n","for cid in range(n_clusters):\n","    members = np.where(triage_cluster == cid)[0]\n","    rep = pick_representative(cid)\n","    top, n = summarize_cluster(cid, topn=5)\n","    rows.append({\n","        \"cluster_id\": cid,\n","        \"count\": n,\n","        \"rep_unk_i\": rep,\n","        \"top_known_mix\": top\n","    })\n","\n","df_clusters = pd.DataFrame(rows)\n","csv_path = os.path.join(OUT_DIR, \"triage_clusters_summary.csv\")\n","df_clusters.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n","csv_path, df_clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5lrsRQUgBK0"},"outputs":[],"source":["# =========================\n","# AUTO-SAVE: reports/plots/meta (1 cell)\n","# =========================\n","import os, json, subprocess, datetime\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n","\n","# ---- 0) 기본 경로/이름 ----\n","PROJECT_DIR = \"/content/drive/MyDrive/Colab Notebooks/WMI_Wafer_DefectPattern_Detection_AnomalyAnalysis\"\n","OUT_ROOT = os.path.join(PROJECT_DIR, \"reports\")\n","\n","def _safe(s: str) -> str:\n","    s = str(s)\n","    bad = [' ', '/', '\\\\', ':', '[', ']', '{', '}', '(', ')', ',', '\"', \"'\"]\n","    for b in bad:\n","        s = s.replace(b, \"_\")\n","    return s\n","\n","# run_id: CKPT 기준으로 만들고, 없으면 timestamp\n","ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","ckpt_name = _safe(os.path.basename(CKPT_PATH)) if \"CKPT_PATH\" in globals() else f\"no_ckpt_{ts}\"\n","run_id = ckpt_name.replace(\".pt\",\"\").replace(\".pth\",\"\").replace(\".ckpt\",\"\")\n","OUT_DIR = os.path.join(OUT_ROOT, run_id)\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","print(\"✅ OUT_DIR:\", OUT_DIR)\n","\n","# ---- 1) git/환경 정보 ----\n","def get_git_hash():\n","    try:\n","        return subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n","    except Exception:\n","        return None\n","\n","def save_json(path, obj):\n","    with open(path, \"w\") as f:\n","        json.dump(obj, f, indent=2, ensure_ascii=False)\n","\n","def save_txt(path, text):\n","    with open(path, \"w\") as f:\n","        f.write(text)\n","\n","# ---- 2) 메타 저장(runmeta.json) ----\n","meta = {\n","    \"timestamp\": ts,\n","    \"ckpt_path\": CKPT_PATH if \"CKPT_PATH\" in globals() else None,\n","    \"git_hash\": get_git_hash(),\n","    \"random_state\": int(RANDOM_STATE) if \"RANDOM_STATE\" in globals() else None,\n","    \"model_cfg\": MODEL_CFG if \"MODEL_CFG\" in globals() else None,\n","    \"torch\": torch.__version__,\n","}\n","\n","# class mapping 저장(있으면)\n","if \"class_to_idx\" in globals():\n","    meta[\"class_to_idx\"] = dict(class_to_idx)\n","if \"known_classes\" in globals():\n","    meta[\"known_classes\"] = list(known_classes)\n","\n","save_json(os.path.join(OUT_DIR, \"runmeta.json\"), meta)\n","print(\"✅ saved runmeta.json\")\n","\n","# ---- 3) TEST_KNOWN 평가 + 리포트/CM 저장 (loader/model이 있으면 자동 수행) ----\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# model 잡기 (loaded_model 우선)\n","model_use = None\n","if \"loaded_model\" in globals():\n","    model_use = loaded_model\n","elif \"model\" in globals():\n","    model_use = model\n","\n","if model_use is not None:\n","    model_use = model_use.to(device).eval()\n","\n","def plot_cm_row_norm(cm, labels, title, out_png):\n","    cm_row = cm / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm_row, vmin=0, vmax=1)\n","    plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n","    plt.yticks(range(len(labels)), labels)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    plt.title(title)\n","    plt.colorbar(fraction=0.046, pad=0.04)\n","    plt.tight_layout()\n","    plt.savefig(out_png, dpi=200)\n","    plt.close()\n","\n","@torch.no_grad()\n","def predict_loader(model, loader):\n","    ys, ps = [], []\n","    for batch in loader:\n","        # (x,y) 형태를 가정\n","        x, y = batch\n","        x = x.to(device)\n","        logits = model(x)\n","        pred = logits.argmax(dim=1).cpu().numpy()\n","        ys.append(np.array(y))\n","        ps.append(pred)\n","    return np.concatenate(ys), np.concatenate(ps)\n","\n","if model_use is not None and \"test_known_loader\" in globals() and \"idx_to_class\" in globals() and \"known_classes\" in globals():\n","    try:\n","        y_true, y_pred = predict_loader(model_use, test_known_loader)\n","        labels = [idx_to_class[i] for i in range(len(known_classes))]\n","\n","        acc = accuracy_score(y_true, y_pred)\n","        macro = f1_score(y_true, y_pred, average=\"macro\")\n","        rep = classification_report(y_true, y_pred, target_names=labels)\n","\n","        save_txt(os.path.join(OUT_DIR, \"test_report.txt\"),\n","                 f\"[TEST]\\nacc={acc:.4f}, macroF1={macro:.4f}\\n\\n{rep}\\n\")\n","        print(\"✅ saved test_report.txt\")\n","\n","        cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n","        plot_cm_row_norm(cm, labels, \"Confusion Matrix (row-normalized)\", os.path.join(OUT_DIR, \"test_cm_row_norm.png\"))\n","        print(\"✅ saved test_cm_row_norm.png\")\n","    except Exception as e:\n","        print(\"⚠️ skip TEST report/cm:\", repr(e))\n","else:\n","    print(\"⚠️ skip TEST report/cm (need model + test_known_loader + idx_to_class + known_classes)\")\n","\n","# ---- 4) UMAP 저장 (ref_emb/unk_emb/ref_y가 있으면) ----\n","def save_umap_known_unknown(ref_emb, ref_y, unk_emb, random_state, out_dir):\n","    try:\n","        import umap\n","    except Exception:\n","        # colab에서만 동작(로컬이면 알아서 설치)\n","        import sys\n","        !pip -q install umap-learn\n","        import umap\n","\n","    N_REF_VIS = min(5000, len(ref_emb))\n","    N_UNK_VIS = min(2000, len(unk_emb))\n","\n","    rng = np.random.RandomState(random_state if random_state is not None else 42)\n","    ref_vis_idx = rng.choice(len(ref_emb), size=N_REF_VIS, replace=False)\n","    unk_vis_idx = rng.choice(len(unk_emb), size=N_UNK_VIS, replace=False)\n","\n","    X_vis = np.vstack([ref_emb[ref_vis_idx], unk_emb[unk_vis_idx]])\n","    y_vis = np.concatenate([ref_y[ref_vis_idx], -1*np.ones(N_UNK_VIS, dtype=int)])  # unknown=-1\n","\n","    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=(random_state if random_state is not None else 42))\n","    Z = reducer.fit_transform(X_vis)\n","\n","    # arrays 저장\n","    np.save(os.path.join(out_dir, \"umap_Z.npy\"), Z)\n","    np.save(os.path.join(out_dir, \"umap_y.npy\"), y_vis)\n","\n","    # plot 저장 (클래스별 legend)\n","    plt.figure(figsize=(8,6))\n","\n","    mask_unk = (y_vis == -1)\n","    plt.scatter(Z[mask_unk,0], Z[mask_unk,1], s=6, label=\"Unknown\", alpha=0.9)\n","\n","    for k in sorted(np.unique(y_vis)):\n","        if k == -1:\n","            continue\n","        m = (y_vis == k)\n","        name = idx_to_class.get(int(k), f\"Class {int(k)}\") if \"idx_to_class\" in globals() else f\"Class {int(k)}\"\n","        plt.scatter(Z[m,0], Z[m,1], s=6, label=name, alpha=0.9)\n","\n","    plt.title(\"Embedding 2D (UMAP): known vs unknown\")\n","    plt.legend(markerscale=3, bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(out_dir, \"umap_known_unknown.png\"), dpi=200)\n","    plt.close()\n","    print(\"✅ saved umap_known_unknown.png + umap_Z.npy + umap_y.npy\")\n","\n","# UMAP 실행 조건\n","if all(k in globals() for k in [\"ref_emb\", \"ref_y\", \"unk_emb\"]):\n","    try:\n","        save_umap_known_unknown(ref_emb, ref_y, unk_emb, RANDOM_STATE if \"RANDOM_STATE\" in globals() else 42, OUT_DIR)\n","    except Exception as e:\n","        print(\"⚠️ skip UMAP:\", repr(e))\n","else:\n","    print(\"⚠️ skip UMAP (need ref_emb, ref_y, unk_emb)\")\n","\n","# ---- 5) (선택) 임베딩 저장 ----\n","def try_save_npy(name, arr):\n","    try:\n","        np.save(os.path.join(OUT_DIR, f\"{name}.npy\"), arr)\n","        print(f\"✅ saved {name}.npy\", getattr(arr, \"shape\", None))\n","    except Exception as e:\n","        print(f\"⚠️ skip save {name}:\", repr(e))\n","\n","if \"ref_emb\" in globals(): try_save_npy(\"ref_emb\", ref_emb)\n","if \"ref_y\"   in globals(): try_save_npy(\"ref_y\", ref_y)\n","if \"unk_emb\" in globals(): try_save_npy(\"unk_emb\", unk_emb)\n","\n","print(\"DONE ✅\")"]},{"cell_type":"code","source":[],"metadata":{"id":"DhmoWzb_h5Rc"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}